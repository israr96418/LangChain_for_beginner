{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage, FunctionMessage\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temperature ---> parameter of openai with the help of the parameter(temperature) we can control the output/creativity of LLM\n",
    "\n",
    "llm = OpenAI(openai_api_key=\"\", temperature=0)\n",
    "# llm = OpenAI(openai_api_key=\"\", temperature=0)\n",
    "chat_model = ChatOpenAI(openai_api_key= \"\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\\\\\hi!\");\\n    var0.endXPath();\\n    var0.startRelationalExpr();\\n    var0.startXPath();\\n    var0.endEqualityExpr(10);\\n    var0.endCommentNodeStep();\\n    var0.endRelativeLocationPath();\\n    var0.endNameStep();\\n    var0.endRelativeLocationPath();\\n    var0.endNameStep();\\n    var0.endRelationalExpr(10);\\n    var0.endNameStep();\\n    var0.endRelationalExpr(1);\\n    var0.endRelationalExpr(10);\\n    var0.endRelationalExpr(10);\\n    var0.endRelationalExpr(10);\\n    var0.endRelationalExpr(10);\\n    var0.endRelationalExpr(10);\\n    var0.endRelationalExpr(10);\\n    var0.endRelationalExpr(10);\\n    var0.endRelationalExpr(10);\\n    var0.endRelationalExpr(10);\\n    var0.endRelational'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"hi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model.predict(\"Hi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"suggest me a company name that manufacturing colorful socks!\"\n",
    "print(llm.predict(text))\n",
    "print(end=\"\\n\")\n",
    "print(chat_model.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='\\n\\nSocktastic!'\n",
      "\n",
      "content='1. ChromaSock\\n2. RainbowThreads\\n3. ColorfulSoles\\n4. VibrantSocks\\n5. SpectrumSock Co.\\n6. Kaleidosock\\n7. ChromaticThreads\\n8. ColorPopSocks\\n9. PrismSock Manufacturing\\n10. TechnicolorToes'\n"
     ]
    }
   ],
   "source": [
    "text = \"suggest me a company name that manufacturing colorful socks!\"\n",
    "message = [HumanMessage(content=text)]\n",
    "\n",
    "print(llm.predict_messages(message))\n",
    "print(end=\"\\n\")\n",
    "print(chat_model.predict_messages(message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PromptTemplate**: Good practice is that don,t pass user input directly to LLM, usually we will add user input to a large piece of text, called prompttemplate, that provide additional content on a specific task at the end\n",
    "\n",
    "In the previous example, the text we passed to the model contained instructions to generate a company name. For our application, it'd be great if the user only had to provide the description of a company/product, without having to worry about giving the model instructions.\n",
    "PromptTemplates help with exactly this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Suggestion me a goog company name tha create a cricket bat?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"Suggestion me a goog company name tha create a {product}?\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"product\"]\n",
    ")\n",
    "\n",
    "prompt.format(product = \"cricket bat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PromptTemplate can also used to produce a list of messages , in this case prompttemplate not only contains infomration about the content , but also each message (its, role , its position in the list)\n",
    "\n",
    "chatprompttemplate is a list of chatmessage template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='you are helpful assisment that translates English into Urdu'),\n",
       " HumanMessage(content='I love python programming language')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "template =\"you are helpful assisment that translates {input_language} into {output_language}\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "\n",
    "chat_prompt.format_messages(input_language=\"English\", output_language=\"Urdu\", text=\"I love python programming language\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OutputParser**: convert the raw response from LLM into a formate that can be used downstream. There are few main types of Output parser\n",
    "1: convert text from LLM ----> structure information(e.g json)\n",
    "2: convert a chatmessages into just a string\n",
    "3: convert the extra information returned from a call besides the message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeperatedListOutPutParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM into a comma separated list\"\"\"\n",
    "    def parse(self, text: str):\n",
    "        return text.strip().split(\", \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', 'how r u', 'hope you will be fine and good health']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CommaSeperatedListOutPutParser().parse(\"Hi, how r u, hope you will be fine and good health\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combine LLM, PromptTemplate, OutputParse**: Now we combine all these things into a single chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dell XPS 13',\n",
       " 'MacBook Pro',\n",
       " 'HP Spectre x360',\n",
       " 'Lenovo ThinkPad X1 Carbon',\n",
       " 'Asus ZenBook Pro']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CommaSeperatedListOutPutParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM into a comma separated list\"\"\"\n",
    "    def parse(self, text: str):\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "template = \"\"\"You are a helpful assistant who generates comma separated lists.\n",
    "A user will pass in a category, and you should generate 5 objects in that category in a comma separated list.\n",
    "ONLY return a comma separated list, and nothing more. \"\"\"\n",
    "\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "\n",
    "chain = chat_prompt | chat_model | CommaSeperatedListOutPutParser()\n",
    "chain.invoke({\"text\": \"type of laptop\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***LangChain Expression Language(LCEL)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LCEL is a declarative way to easily compose chain together. there are several benefits to writing chain to gether in this manner\n",
    "\n",
    "***Async , Batch, and Streaming support***:Any chain constructed in this way will automatically have full asyn , batch and streaming support\n",
    "**Fallbacks** The non-determinism of LLMs makes it important to be able to handle errors gracefully. With LCEL you can easily attach fallbacks to any chain.\n",
    "**Parallelism** Since LLM applications involve (sometimes long) API calls, it often becomes important to run things in parallel. With LCEL syntax, any components that can be run in parallel automatically are.\n",
    "**Seamless LangSmith Tracing Integration** As your chains get more and more complex, it becomes increasingly important to understand what exactly is happening at every step. With LCEL, all steps are automatically logged to LangSmith for maximal observability and debuggability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Interface***: In an effort to make it as easy as possible to create custom chains, we've implemented a \"Runnable\" protocol that most components implement. This is a standard interface with a few different methods, which makes it easy to define custom chains as well as making it possible to invoke them in a standard way. The standard interface exposed includes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**stream**: stream back chunks of the response <br>\n",
    "**invoke**: call the chain on an input <br>\n",
    "**batch**: call the chain on a list of inputs <br>\n",
    "\n",
    "These also have corresponding async methods: <br>\n",
    "\n",
    "**astream**: stream back chunks of the response async <br>\n",
    "**ainvoke**: call the chain on an input async <br>\n",
    "**abatch**: call the chain on a list of inputs async <br>\n",
    "**astream_log**: stream back intermediate steps as they happen, in addition to the final response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_chat = ChatPromptTemplate.from_template(\"Tell me a joke aboute {topics}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_chat | chat_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**input_schema**: an input Pydantic model auto-generated from the structure of the Runnable <br>\n",
    "**output_schema**: an output Pydantic model auto-generated from the structure of the Runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'PromptInput',\n",
       " 'type': 'object',\n",
       " 'properties': {'topics': {'title': 'Topics', 'type': 'string'}}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the input schema of the chain is the input schema of its first part, the prompt\n",
    "# A description of the inputs accepted by a Runnable.\n",
    "#  This is a Pydantic model dynamically generated from the \n",
    "# structure of any Runnable. You can call .schema() on it to obtain a JSONSchema representation.\n",
    "\n",
    "\n",
    "chain.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'ChatOpenAIOutput',\n",
       " 'anyOf': [{'$ref': '#/definitions/HumanMessageChunk'},\n",
       "  {'$ref': '#/definitions/AIMessageChunk'},\n",
       "  {'$ref': '#/definitions/ChatMessageChunk'},\n",
       "  {'$ref': '#/definitions/FunctionMessageChunk'},\n",
       "  {'$ref': '#/definitions/SystemMessageChunk'}],\n",
       " 'definitions': {'HumanMessageChunk': {'title': 'HumanMessageChunk',\n",
       "   'description': 'A Human Message chunk.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content', 'type': 'string'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'human',\n",
       "     'enum': ['human'],\n",
       "     'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'},\n",
       "    'is_chunk': {'title': 'Is Chunk',\n",
       "     'default': True,\n",
       "     'enum': [True],\n",
       "     'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'AIMessageChunk': {'title': 'AIMessageChunk',\n",
       "   'description': 'A Message chunk from an AI.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content', 'type': 'string'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'ai',\n",
       "     'enum': ['ai'],\n",
       "     'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'},\n",
       "    'is_chunk': {'title': 'Is Chunk',\n",
       "     'default': True,\n",
       "     'enum': [True],\n",
       "     'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'ChatMessageChunk': {'title': 'ChatMessageChunk',\n",
       "   'description': 'A Chat Message chunk.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content', 'type': 'string'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'chat',\n",
       "     'enum': ['chat'],\n",
       "     'type': 'string'},\n",
       "    'role': {'title': 'Role', 'type': 'string'},\n",
       "    'is_chunk': {'title': 'Is Chunk',\n",
       "     'default': True,\n",
       "     'enum': [True],\n",
       "     'type': 'boolean'}},\n",
       "   'required': ['content', 'role']},\n",
       "  'FunctionMessageChunk': {'title': 'FunctionMessageChunk',\n",
       "   'description': 'A Function Message chunk.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content', 'type': 'string'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'function',\n",
       "     'enum': ['function'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'is_chunk': {'title': 'Is Chunk',\n",
       "     'default': True,\n",
       "     'enum': [True],\n",
       "     'type': 'boolean'}},\n",
       "   'required': ['content', 'name']},\n",
       "  'SystemMessageChunk': {'title': 'SystemMessageChunk',\n",
       "   'description': 'A System Message chunk.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content', 'type': 'string'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'system',\n",
       "     'enum': ['system'],\n",
       "     'type': 'string'},\n",
       "    'is_chunk': {'title': 'Is Chunk',\n",
       "     'default': True,\n",
       "     'enum': [True],\n",
       "     'type': 'boolean'}},\n",
       "   'required': ['content']}}}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A description of the outputs produced by a Runnable. This is a Pydantic model dynamically generated\n",
    "#  from the structure of any Runnable. You can call .schema()\n",
    "#  on it to obtain a JSONSchema representation.\n",
    "chain.output_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain.schema.messages.AIMessageChunk'>\n",
      "<class 'langchain.schema.messages.AIMessageChunk'>\n",
      "Why<class 'langchain.schema.messages.AIMessageChunk'>\n",
      " don<class 'langchain.schema.messages.AIMessageChunk'>\n",
      "'t<class 'langchain.schema.messages.AIMessageChunk'>\n",
      " bears<class 'langchain.schema.messages.AIMessageChunk'>\n",
      " wear<class 'langchain.schema.messages.AIMessageChunk'>\n",
      " shoes<class 'langchain.schema.messages.AIMessageChunk'>\n",
      "?\n",
      "\n",
      "<class 'langchain.schema.messages.AIMessageChunk'>\n",
      "Because<class 'langchain.schema.messages.AIMessageChunk'>\n",
      " they<class 'langchain.schema.messages.AIMessageChunk'>\n",
      " have<class 'langchain.schema.messages.AIMessageChunk'>\n",
      " bear<class 'langchain.schema.messages.AIMessageChunk'>\n",
      " feet<class 'langchain.schema.messages.AIMessageChunk'>\n",
      "!<class 'langchain.schema.messages.AIMessageChunk'>\n"
     ]
    }
   ],
   "source": [
    "for s in chain.stream({\"topics\":\"bears\"}):    # stream back chunks of the response\n",
    "    print(type(s))\n",
    "    print(s.content , end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did Dunky bring a ladder to the basketball game?\\n\\nBecause he heard the players were always dunking on each other!')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoke call the chain on an inputs\n",
    "chain.invoke({\"topics\":\"Dunky\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content=\"Why don't lions like playing cards in the wild?\\n\\nBecause there are too many cheetahs!\"),\n",
       " AIMessage(content=\"Why don't tigers like fast food?\\n\\nBecause they can't catch it!\")]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch call the chain on list of inputs\n",
    "# we can also used \"max_concurrancy\" parameter to set maximum number of concurrancy request\n",
    "chain.batch([{\"topics\":\"lion\"}, {\"topics\":\"tiger\"}], config={\"max_concurrency\":5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't bears wear shoes?\n",
      "\n",
      "Because they have bear feet!"
     ]
    }
   ],
   "source": [
    "# asyncstream\n",
    "\n",
    "async for s in chain.astream({\"topics\":\"bears\"}):\n",
    "    print(s.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Why don't lions like playing cards in the wild?\\n\\nBecause there are too many cheetahs!\")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#async invoke\n",
    "\n",
    "await chain.ainvoke({\"topics\":\"lions\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object list can't be used in 'await' expression",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb Cell 30\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# async batch call the chain on list of inputs\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# we can also used \"max_concurrancy\" parameter to set maximum number of concurrancy request\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mawait\u001b[39;00m chain\u001b[39m.\u001b[39mbatch([{\u001b[39m\"\u001b[39m\u001b[39mtopics\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39mlion\u001b[39m\u001b[39m\"\u001b[39m}, {\u001b[39m\"\u001b[39m\u001b[39mtopics\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39mtiger\u001b[39m\u001b[39m\"\u001b[39m}], config\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mmax_concurrency\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m5\u001b[39m})\n",
      "\u001b[0;31mTypeError\u001b[0m: object list can't be used in 'await' expression"
     ]
    }
   ],
   "source": [
    "# async batch call the chain on list of inputs\n",
    "# we can also used \"max_concurrancy\" parameter to set maximum number of concurrancy request\n",
    "await chain.batch([{\"topics\":\"lion\"}, {\"topics\":\"tiger\"}], config={\"max_concurrency\":5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**parallelism**:\n",
    "Lets take a look at how langchain expression language support parallel request as much as possible . \n",
    "e.g when using a Runnableparallel it execute each element in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableParallel\n",
    "chat1 = ChatPromptTemplate.from_template(\"tell me a joke about {topics}?\")\n",
    "chat2 = ChatPromptTemplate.from_template(\"write a short (2 line) poem about {topics}?\")\n",
    "combined = RunnableParallel(joke = chat1, poem = chat2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='tell me a joke about pakistan?')])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat1.invoke({\"topics\":\"pakistan\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='write a short (2 line) poem about lion?')])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat2.invoke({\"topics\":\"lion\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': ChatPromptValue(messages=[HumanMessage(content='tell me a joke about AIMessage?')]),\n",
       " 'poem': ChatPromptValue(messages=[HumanMessage(content='write a short (2 line) poem about AIMessage?')])}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.invoke({\"topics\":\"AIMessage\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bind runtime args**:\n",
    "Sometimes we want to invoke a Runnable within a Runnable sequence with constant arguments that are not part of the output of the preceding Runnable in the sequence, and which are not part of the user input. We can use Runnable.bind() to easily pass these arguments in.\n",
    "\n",
    "Suppose we have a simple prompt + model sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EQUATION: x^3 + 7 = 12\n",
      "\n",
      "SOLUTION:\n",
      "Subtracting 7 from both sides of the equation, we get:\n",
      "x^3 = 12 - 7\n",
      "x^3 = 5\n",
      "\n",
      "Taking the cube root of both sides, we get:\n",
      "x = ∛5\n",
      "\n",
      "Therefore, the solution to the equation x^3 + 7 = 12 is x = ∛5.\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough   # runnable that pass through input\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "    (\"system\",\"Write out the following equation using algebraic symbols then solve it. Use the format\\n\\nEQUATION:...\\nSOLUTION:...\\n\\n\"),\n",
    "    (\"human\", \"{equation_statment}\"),\n",
    "]\n",
    ")\n",
    "runnable = {\"equation_statment\": RunnablePassthrough()} | prompt | chat_model | StrOutputParser()\n",
    "\n",
    "print(runnable.invoke(\"x raised to the third plus seven equals 12\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EQUATION: x^3 + 7 = 12\n",
      "\n",
      "SOLUTION:\n",
      "Subtracting 7 from both sides of the equation, we get:\n",
      "x^3 = 12 - 7\n",
      "x^3 = 5\n",
      "\n",
      "Taking the cube root of both sides, we get:\n",
      "x = ∛5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "    (\"system\",\"Write out the following equation using algebraic symbols then solve it. Use the format\\n\\nEQUATION:...\\nSOLUTION:...\\n\\n\"),\n",
    "    (\"human\", \"{equation_statment}\"),\n",
    "]\n",
    ")\n",
    "runnable = (\n",
    "    {\"equation_statment\": RunnablePassthrough()}\n",
    "    | prompt | \n",
    "    chat_model.bind(stop=\"Therefore, the solution to the equation\") | \n",
    "    StrOutputParser()\n",
    ")\n",
    "\n",
    "print(runnable.invoke(\"x raised to the third plus seven equals 12\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add Fallbacks**:\n",
    "There are many possible way of failure of LLM application, whether that may be issue in LLM API's , poor model output <br>\n",
    "issue with other integration etc Fallback help us gracefully handle and isolate these issue\n",
    "\n",
    "Crucially, fallback can be applied not only on the LLM level but on the whole runnable level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatAnthropic\n",
    "from unittest.mock import patch\n",
    "from openai.error import RateLimitError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let mock out what happens if we hit RateLimitError in OpenAI\n",
    "chatopenai_llm = ChatOpenAI(max_retries=0, openai_api_key=\"\")   # Note that we set max_retires = 0 to avoid retrying on Ratelimited error\n",
    "anthropic_llm = ChatAnthropic(anthropic_api_key=\"\")\n",
    "llm = chatopenai_llm.with_fallbacks([anthropic_llm])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit error\n"
     ]
    }
   ],
   "source": [
    "# Let's use just the OpenAI LLm first, to show that we run into an error\n",
    "with patch(\"openai.ChatCompletion.create\", side_effect = RateLimitError()):\n",
    "    try:\n",
    "        print(chatopenai_llm.invoke(\"why did chicken cross the road\"))\n",
    "    except:\n",
    "        print(\"hit error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit error\n"
     ]
    }
   ],
   "source": [
    "# Now let's try with fallbacks to Anthropic\n",
    "with patch('openai.ChatCompletion.create', side_effect=RateLimitError()):\n",
    "    try:\n",
    "         print(llm.invoke(\"Why did the the chicken cross the road?\"))\n",
    "    except:\n",
    "        print(\"Hit error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use fallbacks with our LLM as we would a normal LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit error\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are a nice assistant who always include complement in your response\"),\n",
    "    (\"human\", \"Why did the {animal} cross the road\")\n",
    "])\n",
    "\n",
    "chain = chat_model | llm\n",
    "with patch(\"openai.ChatCompletion.create\", side_effect = RateLimitError()):\n",
    "    try:\n",
    "        print(chain.invoke({\"animal\":\"kangroo\"}))\n",
    "    except:\n",
    "        print(\"hit error\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit error\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You're a nice assistant who always includes a compliment in your response\"),\n",
    "        (\"human\", \"Why did the {animal} cross the road\"),\n",
    "    ]\n",
    ")\n",
    "chain = prompt | llm\n",
    "with patch('openai.ChatCompletion.create', side_effect=RateLimitError()):\n",
    "    try:\n",
    "         print(chain.invoke({\"animal\": \"kangaroo\"}))\n",
    "    except:\n",
    "        print(\"Hit error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**specifying error to handle**:\n",
    "we can also used fallback for specific error handling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit error\n"
     ]
    }
   ],
   "source": [
    "fallback_specific = chatopenai_llm.with_fallbacks([anthropic_llm], exceptions_to_handle=(KeyboardInterrupt,))\n",
    "chain = prompt | llm\n",
    "with patch(\"openai.ChatCompletion.create\", side_effect = RateLimitError()):\n",
    "    try:\n",
    "        print(chain.invoke({\"animal\":\"lion\"}))\n",
    "    except:\n",
    "        print(\"hit error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fallbacks for sequences:**\n",
    "we can also used fallback for sequences, that are sequence themselves Here we do that with two different models: ChatOpenAI and then normal OpenAI (which does not use a chat model). Because OpenAI is NOT a chat model, you likely want a different prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first of fall create chain with chatmodel then we create chain with normal openai\n",
    "# we add a string_output_parser here so the output b/w the two are the same type\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You're a nice assistant who always includes a compliment in your response\"),\n",
    "    (\"human\",\"Why did the {animal} cross the road\")\n",
    "])\n",
    "\n",
    "chat_model = ChatOpenAI(openai_api_key=\"\", model_name=\"gpt-fake\")\n",
    "bad_chain = chat_prompt | chat_model | StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create a chain with normal openai model\n",
    "prompt_template = \"\"\"Instructions: You should always include a compliment in your response.\n",
    "\n",
    "Question: Why did the {animal} cross the road?\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "llm = OpenAI(openai_api_key=\"\")\n",
    "good_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nAnswer: I'm not sure why the lion crossed the road, but it certainly seems brave and courageous.\""
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can create a final chain which combines the two\n",
    "chain = bad_chain.with_fallbacks([good_chain])\n",
    "chain.invoke({\"animal\":\"lion\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run Arbitrary function**: we can use arbitrary function in a pipeline <br>\n",
    "**Note**: all inputs to these function need to be a single arguments, if you have function which accept multiple arguments <br>\n",
    "you should write a wrapper that accepts a single input and unpacks it into multiple argumenst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenght_function(text):\n",
    "    print(\"text in lenght function: \", text)\n",
    "    return len(text)\n",
    "\n",
    "def _multiple_lenght_function(text1, text2):\n",
    "    return len(text1) * len(text2)\n",
    "\n",
    "def multiple_lenght_function(_dict):\n",
    "    print(_dict['text1'], _dict['text2'])\n",
    "    return _multiple_lenght_function(_dict['text1'], _dict['text2'] )\n",
    "\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"what is {a} + {b}\")\n",
    "chain1 = prompt | chat_model\n",
    "\n",
    "chain = {\n",
    "    \"a\":itemgetter(\"foo\") | RunnableLambda(lenght_function),\n",
    "    \"b\":{\"text1\": itemgetter(\"foo\"), \"text2\": itemgetter(\"bar\")} | RunnableLambda(multiple_lenght_function)\n",
    "} | prompt | chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text in lenght function:  bar\n",
      "bar gah\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='3 + 9 equals 12.')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"foo\":\"bar\", \"bar\":\"gah\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accepting Runnable Config**:\n",
    "Runnablelambda(arbitrary function) --> optionally accept RunnableConfig, which they can used to pass callbacks, tags and other configuration information\n",
    "to nested run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableConfig\n",
    "from langchain.schema.output_parser import StrOutputParser   # means the result from LLM is string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def parse_or_fix(text: str, config: RunnableConfig):\n",
    "    fixing_chain = (\n",
    "        ChatPromptTemplate.from_template(\"Fix the following text:\\n\\n```text\\n{input}\\n```\\nError: {error}\"\n",
    "            \" Don't narrate, just respond with the fixed data.\")\n",
    "\n",
    "        | chat_model | StrOutputParser()\n",
    "    )\n",
    "    for _ in range(3):\n",
    "        try:\n",
    "            return json.load(text)\n",
    "        except Exception as e:\n",
    "            text = fixing_chain.invoke({\"input\":text, \"error\":e}, config)\n",
    "    return \"Failed to parse \"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 410\n",
      "\tPrompt Tokens: 232\n",
      "\tCompletion Tokens: 178\n",
      "Successful Requests: 3\n",
      "Total Cost (USD): $0.000704\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    RunnableLambda(parse_or_fix).invoke({\"foo\":\"bar\"}, {\"tags\":[\"my-tags\"], \"callbacks\":[cb]})\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use RunnableParallel/RunnableMap**: to execute multiple runnable in parallel and to return the output of these Runnable as a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': AIMessage(content='Why did the lion eat the tightrope walker? \\n\\nBecause he wanted a well-balanced meal!'),\n",
       " 'poem': AIMessage(content='Majestic king roars,\\nGolden mane dances with pride,\\nFearless ruler roams.')}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnableParallel\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "joke = ChatPromptTemplate.from_template(\"tell me 5 word joke about {animal}?\") | chat_model\n",
    "poem = ChatPromptTemplate.from_template(\"write 10 word poem about {animal}?\")| chat_model\n",
    "\n",
    "combined_chain = RunnableParallel(joke = joke, poem = poem)\n",
    "combined_chain.invoke({\"animal\":\"lion\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manipulting output/input:** Maps can be useful for manipulating the output of one runnable to match the input formate of the next Runnable in a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough  # runnable that passes through input\n",
    "from langchain.vectorstores import FAISS   # FAISS vectores database that stores embeding(vecotres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_stores = FAISS.from_texts([\"Hi I m israr dawar , Now I m living in islamabad\"], embedding=OpenAIEmbeddings(openai_api_key=\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver = vector_stores.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Israr is living in Islamabad.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"Answer the quesiton based only the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "retrive_chain = (\n",
    "    {\"context\":retriver, \"question\":RunnablePassthrough()}     #runnable which pass through input \n",
    "    | prompt | chat_model | StrOutputParser()\n",
    ")\n",
    "\n",
    "retrive_chain.invoke(\"where israr is living?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Route b/w multiple runnables:**  allow you to create non-deterministic chain where the output of previous step <br>\n",
    "define the next step, Routing helps provide structure and consistency around interaction with LLM\n",
    "\n",
    "\n",
    "***Two ways to perform routing***:<br>\n",
    "1: Using a RunnableBranch. <br>\n",
    "2: write custom factory function that takes input of a previous step and return a runnable , importantly this should return a runnable and not actually execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'type': 'authentication_error', 'message': 'Invalid API Key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb Cell 69\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y132sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# chat_anthropic =  ChatAnthropic(anthropic_api_key=\"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\")\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y132sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m chain \u001b[39m=\u001b[39m PromptTemplate\u001b[39m.\u001b[39mfrom_template(\u001b[39m\"\"\"\u001b[39m\u001b[39mGiven the user question below, classify it as either being about `LangChain`, `Anthropic`, or `Other`.\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y132sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m                                     \u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y132sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mDo not respond with more than one word.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y132sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m                                     \u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y132sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mClassification:\u001b[39m\u001b[39m\"\"\"\u001b[39m) \u001b[39m|\u001b[39m anthropic_llm \u001b[39m|\u001b[39m StrOutputParser()\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y132sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m chain\u001b[39m.\u001b[39;49minvoke({\u001b[39m\"\u001b[39;49m\u001b[39mquestion\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m\"\u001b[39;49m\u001b[39mhow do i call anthropics\u001b[39;49m\u001b[39m\"\u001b[39;49m})\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/schema/runnable/base.py:1113\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1112\u001b[0m     \u001b[39mfor\u001b[39;00m i, step \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps):\n\u001b[0;32m-> 1113\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m   1114\u001b[0m             \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   1115\u001b[0m             \u001b[39m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   1116\u001b[0m             patch_config(\n\u001b[1;32m   1117\u001b[0m                 config, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mseq:step:\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   1118\u001b[0m             ),\n\u001b[1;32m   1119\u001b[0m         )\n\u001b[1;32m   1120\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/chat_models/base.py:153\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvoke\u001b[39m(\n\u001b[1;32m    141\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    142\u001b[0m     \u001b[39minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    147\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BaseMessageChunk:\n\u001b[1;32m    148\u001b[0m     config \u001b[39m=\u001b[39m config \u001b[39mor\u001b[39;00m {}\n\u001b[1;32m    149\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(\n\u001b[1;32m    150\u001b[0m         BaseMessageChunk,\n\u001b[1;32m    151\u001b[0m         cast(\n\u001b[1;32m    152\u001b[0m             ChatGeneration,\n\u001b[0;32m--> 153\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[1;32m    154\u001b[0m                 [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_input(\u001b[39minput\u001b[39;49m)],\n\u001b[1;32m    155\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    156\u001b[0m                 callbacks\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcallbacks\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    157\u001b[0m                 tags\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mtags\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    158\u001b[0m                 metadata\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    159\u001b[0m                 run_name\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mrun_name\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    160\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    161\u001b[0m             )\u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m],\n\u001b[1;32m    162\u001b[0m         )\u001b[39m.\u001b[39mmessage,\n\u001b[1;32m    163\u001b[0m     )\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/chat_models/base.py:469\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[1;32m    462\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    463\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    467\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    468\u001b[0m     prompt_messages \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_messages() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[0;32m--> 469\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_messages, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/chat_models/base.py:359\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n\u001b[1;32m    358\u001b[0m             run_managers[i]\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 359\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    360\u001b[0m flattened_outputs \u001b[39m=\u001b[39m [\n\u001b[1;32m    361\u001b[0m     LLMResult(generations\u001b[39m=\u001b[39m[res\u001b[39m.\u001b[39mgenerations], llm_output\u001b[39m=\u001b[39mres\u001b[39m.\u001b[39mllm_output)\n\u001b[1;32m    362\u001b[0m     \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results\n\u001b[1;32m    363\u001b[0m ]\n\u001b[1;32m    364\u001b[0m llm_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_combine_llm_outputs([res\u001b[39m.\u001b[39mllm_output \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/chat_models/base.py:349\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[39mfor\u001b[39;00m i, m \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(messages):\n\u001b[1;32m    347\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m         results\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 349\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_with_cache(\n\u001b[1;32m    350\u001b[0m                 m,\n\u001b[1;32m    351\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    352\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[i] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    353\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    354\u001b[0m             )\n\u001b[1;32m    355\u001b[0m         )\n\u001b[1;32m    356\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    357\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/chat_models/base.py:501\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    498\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    499\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mif\u001b[39;00m new_arg_supported:\n\u001b[0;32m--> 501\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    502\u001b[0m         messages, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    503\u001b[0m     )\n\u001b[1;32m    504\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    505\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(messages, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/chat_models/anthropic.py:183\u001b[0m, in \u001b[0;36mChatAnthropic._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[39mif\u001b[39;00m stop:\n\u001b[1;32m    182\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mstop_sequences\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m stop\n\u001b[0;32m--> 183\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcompletions\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    184\u001b[0m completion \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mcompletion\n\u001b[1;32m    185\u001b[0m message \u001b[39m=\u001b[39m AIMessage(content\u001b[39m=\u001b[39mcompletion)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/anthropic/_utils/_utils.py:250\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 250\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/anthropic/resources/completions.py:223\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, max_tokens_to_sample, model, prompt, metadata, stop_sequences, stream, temperature, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39m@required_args\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mmax_tokens_to_sample\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mmax_tokens_to_sample\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    205\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    221\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m \u001b[39m600\u001b[39m,\n\u001b[1;32m    222\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Completion \u001b[39m|\u001b[39m Stream[Completion]:\n\u001b[0;32m--> 223\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[1;32m    224\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/v1/complete\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    225\u001b[0m         body\u001b[39m=\u001b[39;49mmaybe_transform(\n\u001b[1;32m    226\u001b[0m             {\n\u001b[1;32m    227\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_tokens_to_sample\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_tokens_to_sample,\n\u001b[1;32m    228\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m: model,\n\u001b[1;32m    229\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mprompt\u001b[39;49m\u001b[39m\"\u001b[39;49m: prompt,\n\u001b[1;32m    230\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m: metadata,\n\u001b[1;32m    231\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstop_sequences\u001b[39;49m\u001b[39m\"\u001b[39;49m: stop_sequences,\n\u001b[1;32m    232\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream,\n\u001b[1;32m    233\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m\"\u001b[39;49m: temperature,\n\u001b[1;32m    234\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_k\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_k,\n\u001b[1;32m    235\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_p\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_p,\n\u001b[1;32m    236\u001b[0m             },\n\u001b[1;32m    237\u001b[0m             completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParams,\n\u001b[1;32m    238\u001b[0m         ),\n\u001b[1;32m    239\u001b[0m         options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[1;32m    240\u001b[0m             extra_headers\u001b[39m=\u001b[39;49mextra_headers, extra_query\u001b[39m=\u001b[39;49mextra_query, extra_body\u001b[39m=\u001b[39;49mextra_body, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    241\u001b[0m         ),\n\u001b[1;32m    242\u001b[0m         cast_to\u001b[39m=\u001b[39;49mCompletion,\n\u001b[1;32m    243\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    244\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mStream[Completion],\n\u001b[1;32m    245\u001b[0m     )\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/anthropic/_base_client.py:949\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[1;32m    938\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    939\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    947\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m    948\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mfiles, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[0;32m--> 949\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/anthropic/_base_client.py:748\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    740\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    741\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    746\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    747\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m--> 748\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m    749\u001b[0m         cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m    750\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    751\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    752\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m    753\u001b[0m         remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[1;32m    754\u001b[0m     )\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/anthropic/_base_client.py:785\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n\u001b[0;32m--> 785\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_status_error_from_response(request, err\u001b[39m.\u001b[39mresponse) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mTimeoutException \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'type': 'authentication_error', 'message': 'Invalid API Key'}}"
     ]
    }
   ],
   "source": [
    "# Perform routing by using runnablebranch ---> is initialized with a list (condition , runnable) pairs and a defualt runnable ,\n",
    "# it select which branch passing each condition the input is invoked with. it select the first condition to evaluated to True, and runs the\n",
    "# corresponding runnable to that condition with input.\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatAnthropic\n",
    "# chat_anthropic =  ChatAnthropic(anthropic_api_key=\"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\")\n",
    "\n",
    "chain = PromptTemplate.from_template(\"\"\"Given the user question below, classify it as either being about `LangChain`, `Anthropic`, or `Other`.\n",
    "                                     \n",
    "Do not respond with more than one word.\n",
    "                                     \n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "                                     \n",
    "Classification:\"\"\") | anthropic_llm | StrOutputParser()\n",
    "\n",
    "chain.invoke({\"question\":\"how do i call anthropics\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create 3 sub chain\n",
    "langchain_chain = PromptTemplate.from_template(\"\"\"You are an expert in langchain. \\\n",
    "Always answer questions starting with \"As Harrison Chase told me\". \\\n",
    "Respond to the following question:\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\") | ChatAnthropic(anthropic_api_key=\"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\")\n",
    "\n",
    "\n",
    "anthropics_chain = PromptTemplate.from_template(\"\"\"You are an expert in anthropic. \\\n",
    "Always answer questions starting with \"As Dario Amodei told me\". \\\n",
    "Respond to the following question:\n",
    "\n",
    "Question: {question}\n",
    "                                            \n",
    "Answer:\"\"\") | ChatAnthropic(anthropic_api_key=\"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\")\n",
    "\n",
    "\n",
    "general_chain = PromptTemplate.from_template(\"\"\"Respond to the following question:\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\") | ChatAnthropic(anthropic_api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableBranch\n",
    "branch = RunnableBranch(\n",
    "    (lambda x : \"anthropics\" in x[\"topcis\"].lower(), anthropics_chain),\n",
    "    (lambda x : \"langchain\" in x[\"topcis\"].lower(), langchain_chain),\n",
    "    general_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullchain = {\n",
    "    \"topics\" : chain,\n",
    "    \"question\":lambda x : x[\"question\"]\n",
    "} | branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'type': 'authentication_error', 'message': 'Invalid API Key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb Cell 73\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y136sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m fullchain\u001b[39m.\u001b[39;49minvoke({\u001b[39m\"\u001b[39;49m\u001b[39mquestion\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mhow do I use Anthropic?\u001b[39;49m\u001b[39m\"\u001b[39;49m})\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/schema/runnable/base.py:1113\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1112\u001b[0m     \u001b[39mfor\u001b[39;00m i, step \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps):\n\u001b[0;32m-> 1113\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m   1114\u001b[0m             \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   1115\u001b[0m             \u001b[39m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   1116\u001b[0m             patch_config(\n\u001b[1;32m   1117\u001b[0m                 config, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mseq:step:\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   1118\u001b[0m             ),\n\u001b[1;32m   1119\u001b[0m         )\n\u001b[1;32m   1120\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/schema/runnable/base.py:1623\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   1609\u001b[0m     \u001b[39mwith\u001b[39;00m get_executor_for_config(config) \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m   1610\u001b[0m         futures \u001b[39m=\u001b[39m [\n\u001b[1;32m   1611\u001b[0m             executor\u001b[39m.\u001b[39msubmit(\n\u001b[1;32m   1612\u001b[0m                 step\u001b[39m.\u001b[39minvoke,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1621\u001b[0m             \u001b[39mfor\u001b[39;00m key, step \u001b[39min\u001b[39;00m steps\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1622\u001b[0m         ]\n\u001b[0;32m-> 1623\u001b[0m         output \u001b[39m=\u001b[39m {key: future\u001b[39m.\u001b[39mresult() \u001b[39mfor\u001b[39;00m key, future \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   1624\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   1625\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/schema/runnable/base.py:1623\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1609\u001b[0m     \u001b[39mwith\u001b[39;00m get_executor_for_config(config) \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m   1610\u001b[0m         futures \u001b[39m=\u001b[39m [\n\u001b[1;32m   1611\u001b[0m             executor\u001b[39m.\u001b[39msubmit(\n\u001b[1;32m   1612\u001b[0m                 step\u001b[39m.\u001b[39minvoke,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1621\u001b[0m             \u001b[39mfor\u001b[39;00m key, step \u001b[39min\u001b[39;00m steps\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1622\u001b[0m         ]\n\u001b[0;32m-> 1623\u001b[0m         output \u001b[39m=\u001b[39m {key: future\u001b[39m.\u001b[39;49mresult() \u001b[39mfor\u001b[39;00m key, future \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   1624\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   1625\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    457\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 458\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    459\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/schema/runnable/base.py:1113\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1112\u001b[0m     \u001b[39mfor\u001b[39;00m i, step \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps):\n\u001b[0;32m-> 1113\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m   1114\u001b[0m             \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   1115\u001b[0m             \u001b[39m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   1116\u001b[0m             patch_config(\n\u001b[1;32m   1117\u001b[0m                 config, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mseq:step:\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   1118\u001b[0m             ),\n\u001b[1;32m   1119\u001b[0m         )\n\u001b[1;32m   1120\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/chat_models/base.py:153\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvoke\u001b[39m(\n\u001b[1;32m    141\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    142\u001b[0m     \u001b[39minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    147\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BaseMessageChunk:\n\u001b[1;32m    148\u001b[0m     config \u001b[39m=\u001b[39m config \u001b[39mor\u001b[39;00m {}\n\u001b[1;32m    149\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(\n\u001b[1;32m    150\u001b[0m         BaseMessageChunk,\n\u001b[1;32m    151\u001b[0m         cast(\n\u001b[1;32m    152\u001b[0m             ChatGeneration,\n\u001b[0;32m--> 153\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[1;32m    154\u001b[0m                 [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_input(\u001b[39minput\u001b[39;49m)],\n\u001b[1;32m    155\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    156\u001b[0m                 callbacks\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcallbacks\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    157\u001b[0m                 tags\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mtags\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    158\u001b[0m                 metadata\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    159\u001b[0m                 run_name\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mrun_name\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    160\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    161\u001b[0m             )\u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m],\n\u001b[1;32m    162\u001b[0m         )\u001b[39m.\u001b[39mmessage,\n\u001b[1;32m    163\u001b[0m     )\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/chat_models/base.py:469\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[1;32m    462\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    463\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    467\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    468\u001b[0m     prompt_messages \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_messages() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[0;32m--> 469\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_messages, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/chat_models/base.py:359\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n\u001b[1;32m    358\u001b[0m             run_managers[i]\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 359\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    360\u001b[0m flattened_outputs \u001b[39m=\u001b[39m [\n\u001b[1;32m    361\u001b[0m     LLMResult(generations\u001b[39m=\u001b[39m[res\u001b[39m.\u001b[39mgenerations], llm_output\u001b[39m=\u001b[39mres\u001b[39m.\u001b[39mllm_output)\n\u001b[1;32m    362\u001b[0m     \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results\n\u001b[1;32m    363\u001b[0m ]\n\u001b[1;32m    364\u001b[0m llm_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_combine_llm_outputs([res\u001b[39m.\u001b[39mllm_output \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/chat_models/base.py:349\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[39mfor\u001b[39;00m i, m \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(messages):\n\u001b[1;32m    347\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m         results\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 349\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_with_cache(\n\u001b[1;32m    350\u001b[0m                 m,\n\u001b[1;32m    351\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    352\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[i] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    353\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    354\u001b[0m             )\n\u001b[1;32m    355\u001b[0m         )\n\u001b[1;32m    356\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    357\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/chat_models/base.py:501\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    498\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    499\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mif\u001b[39;00m new_arg_supported:\n\u001b[0;32m--> 501\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    502\u001b[0m         messages, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    503\u001b[0m     )\n\u001b[1;32m    504\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    505\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(messages, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/chat_models/anthropic.py:183\u001b[0m, in \u001b[0;36mChatAnthropic._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[39mif\u001b[39;00m stop:\n\u001b[1;32m    182\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mstop_sequences\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m stop\n\u001b[0;32m--> 183\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcompletions\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    184\u001b[0m completion \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mcompletion\n\u001b[1;32m    185\u001b[0m message \u001b[39m=\u001b[39m AIMessage(content\u001b[39m=\u001b[39mcompletion)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/anthropic/_utils/_utils.py:250\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 250\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/anthropic/resources/completions.py:223\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, max_tokens_to_sample, model, prompt, metadata, stop_sequences, stream, temperature, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39m@required_args\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mmax_tokens_to_sample\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mmax_tokens_to_sample\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    205\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    221\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m \u001b[39m600\u001b[39m,\n\u001b[1;32m    222\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Completion \u001b[39m|\u001b[39m Stream[Completion]:\n\u001b[0;32m--> 223\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[1;32m    224\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/v1/complete\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    225\u001b[0m         body\u001b[39m=\u001b[39;49mmaybe_transform(\n\u001b[1;32m    226\u001b[0m             {\n\u001b[1;32m    227\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_tokens_to_sample\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_tokens_to_sample,\n\u001b[1;32m    228\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m: model,\n\u001b[1;32m    229\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mprompt\u001b[39;49m\u001b[39m\"\u001b[39;49m: prompt,\n\u001b[1;32m    230\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m: metadata,\n\u001b[1;32m    231\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstop_sequences\u001b[39;49m\u001b[39m\"\u001b[39;49m: stop_sequences,\n\u001b[1;32m    232\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream,\n\u001b[1;32m    233\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m\"\u001b[39;49m: temperature,\n\u001b[1;32m    234\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_k\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_k,\n\u001b[1;32m    235\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_p\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_p,\n\u001b[1;32m    236\u001b[0m             },\n\u001b[1;32m    237\u001b[0m             completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParams,\n\u001b[1;32m    238\u001b[0m         ),\n\u001b[1;32m    239\u001b[0m         options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[1;32m    240\u001b[0m             extra_headers\u001b[39m=\u001b[39;49mextra_headers, extra_query\u001b[39m=\u001b[39;49mextra_query, extra_body\u001b[39m=\u001b[39;49mextra_body, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    241\u001b[0m         ),\n\u001b[1;32m    242\u001b[0m         cast_to\u001b[39m=\u001b[39;49mCompletion,\n\u001b[1;32m    243\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    244\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mStream[Completion],\n\u001b[1;32m    245\u001b[0m     )\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/anthropic/_base_client.py:949\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[1;32m    938\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    939\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    947\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m    948\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mfiles, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[0;32m--> 949\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/anthropic/_base_client.py:748\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    740\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    741\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    746\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    747\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m--> 748\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m    749\u001b[0m         cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m    750\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    751\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    752\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m    753\u001b[0m         remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[1;32m    754\u001b[0m     )\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/anthropic/_base_client.py:785\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n\u001b[0;32m--> 785\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_status_error_from_response(request, err\u001b[39m.\u001b[39mresponse) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mTimeoutException \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'type': 'authentication_error', 'message': 'Invalid API Key'}}"
     ]
    }
   ],
   "source": [
    "fullchain.invoke({\"question\": \"how do I use Anthropic?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use a custom fucntion**: You can also use a custom function to route b/w  different output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route(info):\n",
    "    if 'anthropics' in info['topics'].lower():\n",
    "        return anthropics_chain\n",
    "    elif 'langchain' in info['topics'].lower():\n",
    "        return langchain_chain\n",
    "    else:\n",
    "        return general_chain\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda\n",
    "fullchain = {\n",
    "    'topics': chain,\n",
    "    'question':lambda x : x['question']\n",
    "} | RunnableLambda(route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'type': 'authentication_error', 'message': 'Invalid API Key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb Cell 77\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y144sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m fullchain\u001b[39m.\u001b[39;49minvoke({\u001b[39m'\u001b[39;49m\u001b[39mquestion\u001b[39;49m\u001b[39m'\u001b[39;49m:\u001b[39m'\u001b[39;49m\u001b[39mhow do i user anthropics\u001b[39;49m\u001b[39m'\u001b[39;49m})\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/schema/runnable/base.py:1113\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1112\u001b[0m     \u001b[39mfor\u001b[39;00m i, step \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps):\n\u001b[0;32m-> 1113\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m   1114\u001b[0m             \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   1115\u001b[0m             \u001b[39m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   1116\u001b[0m             patch_config(\n\u001b[1;32m   1117\u001b[0m                 config, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mseq:step:\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   1118\u001b[0m             ),\n\u001b[1;32m   1119\u001b[0m         )\n\u001b[1;32m   1120\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/schema/runnable/base.py:1623\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   1609\u001b[0m     \u001b[39mwith\u001b[39;00m get_executor_for_config(config) \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m   1610\u001b[0m         futures \u001b[39m=\u001b[39m [\n\u001b[1;32m   1611\u001b[0m             executor\u001b[39m.\u001b[39msubmit(\n\u001b[1;32m   1612\u001b[0m                 step\u001b[39m.\u001b[39minvoke,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1621\u001b[0m             \u001b[39mfor\u001b[39;00m key, step \u001b[39min\u001b[39;00m steps\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1622\u001b[0m         ]\n\u001b[0;32m-> 1623\u001b[0m         output \u001b[39m=\u001b[39m {key: future\u001b[39m.\u001b[39mresult() \u001b[39mfor\u001b[39;00m key, future \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   1624\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   1625\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/schema/runnable/base.py:1623\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1609\u001b[0m     \u001b[39mwith\u001b[39;00m get_executor_for_config(config) \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m   1610\u001b[0m         futures \u001b[39m=\u001b[39m [\n\u001b[1;32m   1611\u001b[0m             executor\u001b[39m.\u001b[39msubmit(\n\u001b[1;32m   1612\u001b[0m                 step\u001b[39m.\u001b[39minvoke,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1621\u001b[0m             \u001b[39mfor\u001b[39;00m key, step \u001b[39min\u001b[39;00m steps\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1622\u001b[0m         ]\n\u001b[0;32m-> 1623\u001b[0m         output \u001b[39m=\u001b[39m {key: future\u001b[39m.\u001b[39;49mresult() \u001b[39mfor\u001b[39;00m key, future \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   1624\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   1625\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    457\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 458\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    459\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/schema/runnable/base.py:1113\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1112\u001b[0m     \u001b[39mfor\u001b[39;00m i, step \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps):\n\u001b[0;32m-> 1113\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m   1114\u001b[0m             \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   1115\u001b[0m             \u001b[39m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   1116\u001b[0m             patch_config(\n\u001b[1;32m   1117\u001b[0m                 config, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mseq:step:\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   1118\u001b[0m             ),\n\u001b[1;32m   1119\u001b[0m         )\n\u001b[1;32m   1120\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/chat_models/base.py:153\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvoke\u001b[39m(\n\u001b[1;32m    141\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    142\u001b[0m     \u001b[39minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    147\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BaseMessageChunk:\n\u001b[1;32m    148\u001b[0m     config \u001b[39m=\u001b[39m config \u001b[39mor\u001b[39;00m {}\n\u001b[1;32m    149\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(\n\u001b[1;32m    150\u001b[0m         BaseMessageChunk,\n\u001b[1;32m    151\u001b[0m         cast(\n\u001b[1;32m    152\u001b[0m             ChatGeneration,\n\u001b[0;32m--> 153\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[1;32m    154\u001b[0m                 [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_input(\u001b[39minput\u001b[39;49m)],\n\u001b[1;32m    155\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    156\u001b[0m                 callbacks\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcallbacks\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    157\u001b[0m                 tags\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mtags\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    158\u001b[0m                 metadata\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    159\u001b[0m                 run_name\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mrun_name\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    160\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    161\u001b[0m             )\u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m],\n\u001b[1;32m    162\u001b[0m         )\u001b[39m.\u001b[39mmessage,\n\u001b[1;32m    163\u001b[0m     )\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/chat_models/base.py:469\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[1;32m    462\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    463\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    467\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    468\u001b[0m     prompt_messages \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_messages() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[0;32m--> 469\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_messages, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/chat_models/base.py:359\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n\u001b[1;32m    358\u001b[0m             run_managers[i]\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 359\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    360\u001b[0m flattened_outputs \u001b[39m=\u001b[39m [\n\u001b[1;32m    361\u001b[0m     LLMResult(generations\u001b[39m=\u001b[39m[res\u001b[39m.\u001b[39mgenerations], llm_output\u001b[39m=\u001b[39mres\u001b[39m.\u001b[39mllm_output)\n\u001b[1;32m    362\u001b[0m     \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results\n\u001b[1;32m    363\u001b[0m ]\n\u001b[1;32m    364\u001b[0m llm_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_combine_llm_outputs([res\u001b[39m.\u001b[39mllm_output \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/chat_models/base.py:349\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[39mfor\u001b[39;00m i, m \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(messages):\n\u001b[1;32m    347\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m         results\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 349\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_with_cache(\n\u001b[1;32m    350\u001b[0m                 m,\n\u001b[1;32m    351\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    352\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[i] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    353\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    354\u001b[0m             )\n\u001b[1;32m    355\u001b[0m         )\n\u001b[1;32m    356\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    357\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/chat_models/base.py:501\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    498\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    499\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mif\u001b[39;00m new_arg_supported:\n\u001b[0;32m--> 501\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    502\u001b[0m         messages, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    503\u001b[0m     )\n\u001b[1;32m    504\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    505\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(messages, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/chat_models/anthropic.py:183\u001b[0m, in \u001b[0;36mChatAnthropic._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[39mif\u001b[39;00m stop:\n\u001b[1;32m    182\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mstop_sequences\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m stop\n\u001b[0;32m--> 183\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcompletions\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    184\u001b[0m completion \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mcompletion\n\u001b[1;32m    185\u001b[0m message \u001b[39m=\u001b[39m AIMessage(content\u001b[39m=\u001b[39mcompletion)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/anthropic/_utils/_utils.py:250\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 250\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/anthropic/resources/completions.py:223\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, max_tokens_to_sample, model, prompt, metadata, stop_sequences, stream, temperature, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39m@required_args\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mmax_tokens_to_sample\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mmax_tokens_to_sample\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    205\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    221\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m \u001b[39m600\u001b[39m,\n\u001b[1;32m    222\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Completion \u001b[39m|\u001b[39m Stream[Completion]:\n\u001b[0;32m--> 223\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[1;32m    224\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/v1/complete\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    225\u001b[0m         body\u001b[39m=\u001b[39;49mmaybe_transform(\n\u001b[1;32m    226\u001b[0m             {\n\u001b[1;32m    227\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_tokens_to_sample\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_tokens_to_sample,\n\u001b[1;32m    228\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m: model,\n\u001b[1;32m    229\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mprompt\u001b[39;49m\u001b[39m\"\u001b[39;49m: prompt,\n\u001b[1;32m    230\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m: metadata,\n\u001b[1;32m    231\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstop_sequences\u001b[39;49m\u001b[39m\"\u001b[39;49m: stop_sequences,\n\u001b[1;32m    232\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream,\n\u001b[1;32m    233\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m\"\u001b[39;49m: temperature,\n\u001b[1;32m    234\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_k\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_k,\n\u001b[1;32m    235\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_p\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_p,\n\u001b[1;32m    236\u001b[0m             },\n\u001b[1;32m    237\u001b[0m             completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParams,\n\u001b[1;32m    238\u001b[0m         ),\n\u001b[1;32m    239\u001b[0m         options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[1;32m    240\u001b[0m             extra_headers\u001b[39m=\u001b[39;49mextra_headers, extra_query\u001b[39m=\u001b[39;49mextra_query, extra_body\u001b[39m=\u001b[39;49mextra_body, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    241\u001b[0m         ),\n\u001b[1;32m    242\u001b[0m         cast_to\u001b[39m=\u001b[39;49mCompletion,\n\u001b[1;32m    243\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    244\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mStream[Completion],\n\u001b[1;32m    245\u001b[0m     )\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/anthropic/_base_client.py:949\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[1;32m    938\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    939\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    947\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m    948\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mfiles, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[0;32m--> 949\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/anthropic/_base_client.py:748\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    740\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    741\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    746\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    747\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m--> 748\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m    749\u001b[0m         cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m    750\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    751\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    752\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m    753\u001b[0m         remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[1;32m    754\u001b[0m     )\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/anthropic/_base_client.py:785\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n\u001b[0;32m--> 785\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_status_error_from_response(request, err\u001b[39m.\u001b[39mresponse) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mTimeoutException \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'type': 'authentication_error', 'message': 'Invalid API Key'}}"
     ]
    }
   ],
   "source": [
    "fullchain.invoke({'question':'how do i user anthropics'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****CookBook****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These examples show how to compose different Runnable (the core LCEL interface) components to achieve various tasks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt + LLM\n",
    "\n",
    "**PromptTemplate/ChatPromptTemplate --> LLM/chat_model --->     OutPutParser** <br>\n",
    "Almost any other chain you build will use this building block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(openai_api_key='')\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a joke about {topics}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Why don't politicians ever get lost?\\n\\nBecause wherever they go, they always find a way to spin it!\")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model\n",
    "chain.invoke({\"topics\":\"politics\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attaching Stop sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model.bind(stop=['\\n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Why don't politicians ever play hide and seek?\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topics\":\"politics\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attaching function call information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'joke', 'arguments': '{\\n  \"setup\": \"Why don\\'t politicians ever swim in the ocean?\",\\n  \"'}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions = [\n",
    "    {\n",
    "      \"name\": \"joke\",\n",
    "      \"description\": \"A joke\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"setup\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The setup for the joke\"\n",
    "          },\n",
    "          \"punchline\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The punchline for the joke\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\"setup\", \"punchline\"]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "\n",
    "\n",
    "chain = prompt | model.bind(stop = ['punchline'], function_call = {'name':\"joke\"}, functions= functions)\n",
    "chain.invoke({\"topics\":\"polictics\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PromptTemplate + LLM  + OutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also add an output parser to easly tranform the raw LLM/ChatModel output into a more workable formate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "chain = prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why don't politicians ever tell each other secrets?\\n\\nBecause they're always running for office!\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topics\":\"polictics\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Outuput Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why don't politicians ever tell each other jokes?\",\n",
       " 'punchline': \"Because they don't want to risk exposing the truth!\"}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When you specify the function to return, you may just want to parse that directly\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "\n",
    "chain = (\n",
    "    prompt | model.bind(function_call = {\"name\":\"joke\"},functions = functions) | JsonOutputFunctionsParser()\n",
    ")\n",
    "\n",
    "chain.invoke({\"topics\":\"politics\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are composing our map with other runnable , we can even use some syntactic sugar and just use a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why don't politicians ever get lost?\",\n",
       " 'punchline': 'Because they always have a great sense of direction... towards the polls!'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "chain = (\n",
    "    {\"topics\": RunnablePassthrough()} | prompt | model.bind(function_call = {\"name\":\"joke\"},functions = functions) \n",
    "    | JsonOutputFunctionsParser(key_name = \"setup\")\n",
    ")\n",
    "\n",
    "chain.invoke(\"polictis\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG: Retrieval Augmeneted generation chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_stores = FAISS.from_texts([\"Hi , this is israr dawar, he is from Germany Berling, where they worked as Data Scientist at Google\"], embedding=OpenAIEmbeddings(openai_api_key=''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_from_vectores_stores = vector_stores.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question base on the following context {context}\n",
    "Question : {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Google'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = (\n",
    "    {\"context\": retrieval_from_vectores_stores, \"question\":RunnablePassthrough()}\n",
    "    | prompt | model | StrOutputParser()\n",
    ")\n",
    "chain.invoke(\"israr dawar worked at ??\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer in the following language: {language}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = {\n",
    "    \"context\": itemgetter(\"question\") | retrieval_from_vectores_stores, \n",
    "    \"question\": itemgetter(\"question\"), \n",
    "    \"language\": itemgetter(\"language\")\n",
    "} | prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Israr Dawar جرمنی برلن سے ہیں۔'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"Israr dawar is from ??\", \"language\":\"Urdu\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversational Retrieval Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easy add in conversational history , this primarly means adding in chat_message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RunnableMap: A runnable that runs a mapping of runnables in parallel, and returns a mapping of their output\n",
    "from langchain.schema.runnable import RunnableMap,RunnablePassthrough\n",
    "from langchain.schema import format_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "ANSWER_PROMPT = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template=\"{page_content}\")\n",
    "def _combine_documents(docs, document_prompt = DEFAULT_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"):\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    return document_separator.join(doc_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "def _format_chat_history(chat_history: List[Tuple]) -> str:\n",
    "    buffer = \"\"\n",
    "    for dialogue_turn in chat_history:\n",
    "        human = \"Human: \" + dialogue_turn[0]\n",
    "        ai = \"Assistant: \" + dialogue_turn[1]\n",
    "        buffer += \"\\n\" + \"\\n\".join([human, ai])\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_inputs = RunnableMap(\n",
    "    standalone_question=RunnablePassthrough.assign(\n",
    "        chat_history=lambda x: _format_chat_history(x['chat_history'])\n",
    "    ) | CONDENSE_QUESTION_PROMPT | model | StrOutputParser(),\n",
    ")\n",
    "_context = {\n",
    "    \"context\": itemgetter(\"standalone_question\") | retrieval_from_vectores_stores | _combine_documents,\n",
    "    \"question\": lambda x: x[\"standalone_question\"]\n",
    "}\n",
    "conversational_qa_chain = _inputs | _context | ANSWER_PROMPT | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Israr Dawar is from Germany, specifically Berlin. He works as a Data Scientist at Google.')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_qa_chain.invoke({\n",
    "    \"question\": \"where is from israr dawar and he is worked at which company and position?\",\n",
    "    \"chat_history\": [],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='He worked at Google.')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_qa_chain.invoke({\n",
    "    \"question\": \"where did he work?\",\n",
    "    \"chat_history\": [(\"where he is from?\", \"israr dawar\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With memory and returing source documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to use memory with the above(conversationalmemorybuffer etc). For memory we need to manage that outside at the memory <br>\n",
    "For returning the retrieve documents, we just need to pass them through all the way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conver_buffer_memory = ConversationBufferMemory(return_messages=True, input_key=\"question\", output_key=\"answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for |: 'method' and 'operator.itemgetter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb Cell 120\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y241sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# First step : to load memory\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y241sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# this add a memory key to the input \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y241sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m load_memory \u001b[39m=\u001b[39m RunnablePassthrough\u001b[39m.\u001b[39massign(\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y241sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     chat_history \u001b[39m=\u001b[39m conver_buffer_memory\u001b[39m.\u001b[39;49mload_memory_variables \u001b[39m|\u001b[39;49m itemgetter(\u001b[39m'\u001b[39;49m\u001b[39mhistory\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y241sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y241sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Now we caculate standalone question\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y241sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m standalone_question \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y241sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mstandalone_question\u001b[39m\u001b[39m\"\u001b[39m :\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y241sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y241sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     }\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y241sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m } \u001b[39m|\u001b[39m CONDENSE_QUESTION_PROMPT \u001b[39m|\u001b[39m model \u001b[39m|\u001b[39m StrOutputParser()\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'method' and 'operator.itemgetter'"
     ]
    }
   ],
   "source": [
    "# First step : to load memory\n",
    "# this add a memory key to the input \n",
    "\n",
    "load_memory = RunnablePassthrough.assign(\n",
    "    chat_history = conver_buffer_memory.load_memory_variables | itemgetter('history'),\n",
    ")\n",
    "\n",
    "\n",
    "# Now we caculate standalone question\n",
    "standalone_question = {\n",
    "    \"standalone_question\" :\n",
    "    {\n",
    "        \"question\" : lambda x : x['question'],\n",
    "        'chat_history': lambda x : _format_chat_history(x['history'])\n",
    "    }\n",
    "} | CONDENSE_QUESTION_PROMPT | model | StrOutputParser()\n",
    "\n",
    "\n",
    "# Now we retrieve the documnets\n",
    "retrieved_documents = {\n",
    "    'docs':itemgetter(\"standalone_question\") | retrieval_from_vectores_stores,\n",
    "    'question':lambda x : x['standalone_question']\n",
    "}\n",
    "\n",
    "# Now we construct the input for the final prompt\n",
    "\n",
    "final_input = {\n",
    "    'context' : lambda x : _combine_documents(x['docs']),\n",
    "    'question' : itemgetter('question')\n",
    "}\n",
    "\n",
    "# And finally we do the part that return the answer\n",
    "answer = {\n",
    "    'answer': final_input | ANSWER_PROMPT | model,\n",
    "    'docs': itemgetter('docs')\n",
    "}\n",
    "\n",
    "# Now we putt all together \n",
    "final_chain = load_memory   | standalone_question | retrieved_documents |answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runnable can easly be used to string together multiple chain\n",
    "\n",
    "prompt1 = ChatPromptTemplate.from_template('what is the city {person} is from ??')\n",
    "prompt2 = ChatPromptTemplate.from_template('what country is the city {city} in ? respond in {language} ??')\n",
    "chain1 = prompt1 | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Virat Kohli is from Delhi, India.'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain1.invoke({\"person\":\"Virat kholi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain2 = {\n",
    "    'city' : chain1,\n",
    "    'language': itemgetter('language')\n",
    "} | prompt2 | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The country that the city of Delhi, India is in is India itself.'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2.invoke({\"person\":\"Virat kholi\", 'language': 'english'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['color'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['color'], template='what is a fruit of color: {color}. Return the name of the fruit and nothing else:'))]\n"
     ]
    }
   ],
   "source": [
    "prompt1 = ChatPromptTemplate.from_template(\"generate a {attribute} color. Return the name of the color and nothing else:\")\n",
    "prompt2 = ChatPromptTemplate.from_template(\"what is a fruit of color: {color}. Return the name of the fruit and nothing else:\")\n",
    "prompt3 = ChatPromptTemplate.from_template(\"what is a country with a flag that has the color: {color}. Return the name of the country and nothing else:\")\n",
    "prompt4 = ChatPromptTemplate.from_template(\"What is the color of {fruit} and the flag of {country}?\")\n",
    "\n",
    "model_parser = model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_generator = {\"attribute\":RunnablePassthrough()} | prompt1 | {'color': model_parser}\n",
    "color_to_fruit = prompt2 | model_parser\n",
    "color_to_country = prompt3 | model_parser\n",
    "question_generation = color_generator | {'fruit': color_to_fruit, 'country': color_to_country} | prompt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='What is the color of Pomegranate and the flag of Armenia?')])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_generation.invoke('red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[HumanMessage(content='What is the color of Apple and the flag of Ireland?')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The color of Apple is silver or gray, while the flag of Ireland is green, white, and orange.')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = question_generation.invoke('green')\n",
    "print(prompt)\n",
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Branching and Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want the output of one component(chain) to be processed by 2 or more other components.<br>\n",
    "RunnableMap-->let you split or fork the chain so multiple compnents(chain) can process the input in parallel <br>\n",
    "Later , other components can join or merge the result to synthesize a final response \n",
    "\n",
    "     Input\n",
    "      / \\\n",
    "     /   \\\n",
    " Branch1 Branch2<br>\n",
    " \n",
    "     \\   /\n",
    "      \\ /\n",
    "      Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "planner:  first=ChatPromptTemplate(input_variables=['input'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Generate an argument about: {input}'))]) middle=[ChatOpenAI(client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, temperature=0.0, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy=''), StrOutputParser()] last={\n",
      "  base_response: RunnablePassthrough()\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "planner =(\n",
    "    ChatPromptTemplate.from_template(\n",
    "        \"Generate an argument about: {input}\"\n",
    "    ) | model | StrOutputParser() | {\"base_response\": RunnablePassthrough()}\n",
    ")\n",
    "print(\"planner: \", planner)\n",
    "argmuents_for = (\n",
    "    ChatPromptTemplate.from_template(\n",
    "        \"List the pros or positive aspects of {base_response}\"\n",
    "    ) | model | StrOutputParser()\n",
    ")\n",
    "\n",
    "argument_against = (\n",
    "    ChatPromptTemplate.from_template(\n",
    "        \"List of cons or negative aspects of {base_response}\"\n",
    "    ) | model | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "final_responder = (\n",
    "    ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"ai\" , \"{original_response}\"),\n",
    "            (\"human\" , \"Pros:\\n{results_1}\\n\\nCons:\\n{results_2}\"),\n",
    "            (\"system\", \"Generate a final response given the critique\")\n",
    "        ]\n",
    "    ) | model | StrOutputParser ()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    planner | {\"results_1\": argmuents_for, \"results_2\":argument_against, \"original_response\":itemgetter(\"base_response\")} | final_responder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'While Scrum has numerous benefits, it is essential to acknowledge the potential cons and evaluate their impact on the specific project or organization. The complexity of implementing Scrum and the need for training and understanding can be addressed through proper education and support. Additionally, the lack of predictability can be managed by establishing clear project goals and regularly reviewing and adapting the project plan. \\n\\nDependency on team collaboration can be mitigated by fostering a culture of trust and open communication within the team. While Scrum places less emphasis on documentation, it is still important to ensure that essential information is captured and shared appropriately. Clear roles and responsibilities can be established through effective communication and regular team discussions. \\n\\nScaling Scrum for larger projects or organizations may require additional coordination and management, but it is possible with proper planning and support. To prevent scope creep, it is crucial to have a well-defined product backlog and prioritize features based on their value and impact. \\n\\nIn conclusion, while Scrum has its challenges, many of these can be addressed through proper implementation, training, and communication. By understanding the potential cons and taking appropriate measures, organizations can leverage the benefits of Scrum and achieve successful project outcomes.'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\":\"scrum\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying a SQL DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['question', 'schema'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question', 'schema'], template=\"Based on the table schema below , write a SQL query that would answer the user's question:\\n{schema}\\n\\nQuestion: {question}\\nSQL Query:\\n\"))])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"Based on the table schema below , write a SQL query that would answer the user's question:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query:\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import SQLDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SQLDatabase.from_uri(\"sqlite:///./Chinook.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schema(_):\n",
    "    return db.get_table_info()\n",
    "\n",
    "def run_query(query):\n",
    "    return db.run(query)\n",
    "\n",
    "sql_response = (\n",
    "    # RunnablePassthrough ---> A runnable that passes through the input\n",
    "    RunnablePassthrough.assign(schema = get_schema) | prompt_template | model.bind(stop=[\"\\nSQLResult\"]) | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT COUNT(*) FROM Artist'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_response.invoke({'question':\"How many Artist are there?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\" Based on the table schema below, question, sql_query , sql_response, write a natural language response\n",
    "{schama}\n",
    "\n",
    "Question: {question}\n",
    "SQL query: {query}\n",
    "SQL response: {response}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sql_prompt = ChatPromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chain = (\n",
    "    RunnablePassthrough.assign(query = sql_response) | \n",
    "    RunnablePassthrough.assign(\n",
    "        schema = get_schema,\n",
    "        response = lambda x : db.run(x['query']),\n",
    "\n",
    "    ) | sql_prompt | model | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(sqlite3.OperationalError) no such table: Artist\n[SQL: SELECT COUNT(*) FROM Artist]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1965\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1964\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1965\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[1;32m   1966\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[1;32m   1967\u001b[0m         )\n\u001b[1;32m   1969\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py:921\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 921\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(statement, parameters)\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: Artist",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb Cell 143\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y303sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m full_chain\u001b[39m.\u001b[39;49minvoke({\u001b[39m\"\u001b[39;49m\u001b[39mquestion\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m\"\u001b[39;49m\u001b[39mHow many Artist are there?\u001b[39;49m\u001b[39m\"\u001b[39;49m})\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/schema/runnable/base.py:1113\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1112\u001b[0m     \u001b[39mfor\u001b[39;00m i, step \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps):\n\u001b[0;32m-> 1113\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m   1114\u001b[0m             \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   1115\u001b[0m             \u001b[39m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   1116\u001b[0m             patch_config(\n\u001b[1;32m   1117\u001b[0m                 config, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mseq:step:\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   1118\u001b[0m             ),\n\u001b[1;32m   1119\u001b[0m         )\n\u001b[1;32m   1120\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/schema/runnable/passthrough.py:179\u001b[0m, in \u001b[0;36mRunnableAssign.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvoke\u001b[39m(\n\u001b[1;32m    169\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    170\u001b[0m     \u001b[39minput\u001b[39m: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m    171\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    172\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    173\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[1;32m    174\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m    175\u001b[0m         \u001b[39minput\u001b[39m, \u001b[39mdict\u001b[39m\n\u001b[1;32m    176\u001b[0m     ), \u001b[39m\"\u001b[39m\u001b[39mThe input to RunnablePassthrough.assign() must be a dict.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    177\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m    178\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m,\n\u001b[0;32m--> 179\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmapper\u001b[39m.\u001b[39;49minvoke(\u001b[39minput\u001b[39;49m, config, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs),\n\u001b[1;32m    180\u001b[0m     }\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/schema/runnable/base.py:1623\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   1609\u001b[0m     \u001b[39mwith\u001b[39;00m get_executor_for_config(config) \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m   1610\u001b[0m         futures \u001b[39m=\u001b[39m [\n\u001b[1;32m   1611\u001b[0m             executor\u001b[39m.\u001b[39msubmit(\n\u001b[1;32m   1612\u001b[0m                 step\u001b[39m.\u001b[39minvoke,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1621\u001b[0m             \u001b[39mfor\u001b[39;00m key, step \u001b[39min\u001b[39;00m steps\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1622\u001b[0m         ]\n\u001b[0;32m-> 1623\u001b[0m         output \u001b[39m=\u001b[39m {key: future\u001b[39m.\u001b[39mresult() \u001b[39mfor\u001b[39;00m key, future \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   1624\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   1625\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/schema/runnable/base.py:1623\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1609\u001b[0m     \u001b[39mwith\u001b[39;00m get_executor_for_config(config) \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m   1610\u001b[0m         futures \u001b[39m=\u001b[39m [\n\u001b[1;32m   1611\u001b[0m             executor\u001b[39m.\u001b[39msubmit(\n\u001b[1;32m   1612\u001b[0m                 step\u001b[39m.\u001b[39minvoke,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1621\u001b[0m             \u001b[39mfor\u001b[39;00m key, step \u001b[39min\u001b[39;00m steps\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1622\u001b[0m         ]\n\u001b[0;32m-> 1623\u001b[0m         output \u001b[39m=\u001b[39m {key: future\u001b[39m.\u001b[39;49mresult() \u001b[39mfor\u001b[39;00m key, future \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   1624\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   1625\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    457\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 458\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    459\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/schema/runnable/base.py:2110\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvoke\u001b[39m(\n\u001b[1;32m   2104\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   2105\u001b[0m     \u001b[39minput\u001b[39m: Input,\n\u001b[1;32m   2106\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2107\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2108\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Output:\n\u001b[1;32m   2109\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfunc\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 2110\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_with_config(\n\u001b[1;32m   2111\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invoke,\n\u001b[1;32m   2112\u001b[0m             \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   2113\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_config(config, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc),\n\u001b[1;32m   2114\u001b[0m         )\n\u001b[1;32m   2115\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2116\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   2117\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2118\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUse `ainvoke` instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2119\u001b[0m         )\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/schema/runnable/base.py:633\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m    626\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    627\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m    628\u001b[0m     \u001b[39minput\u001b[39m,\n\u001b[1;32m    629\u001b[0m     run_type\u001b[39m=\u001b[39mrun_type,\n\u001b[1;32m    630\u001b[0m     name\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_name\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    631\u001b[0m )\n\u001b[1;32m    632\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 633\u001b[0m     output \u001b[39m=\u001b[39m call_func_with_variable_args(\n\u001b[1;32m    634\u001b[0m         func, \u001b[39minput\u001b[39;49m, run_manager, config, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    635\u001b[0m     )\n\u001b[1;32m    636\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    637\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/schema/runnable/config.py:173\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39mif\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    172\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m run_manager\n\u001b[0;32m--> 173\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/schema/runnable/base.py:2044\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[0;34m(self, input, run_manager, config)\u001b[0m\n\u001b[1;32m   2038\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_invoke\u001b[39m(\n\u001b[1;32m   2039\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   2040\u001b[0m     \u001b[39minput\u001b[39m: Input,\n\u001b[1;32m   2041\u001b[0m     run_manager: CallbackManagerForChainRun,\n\u001b[1;32m   2042\u001b[0m     config: RunnableConfig,\n\u001b[1;32m   2043\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Output:\n\u001b[0;32m-> 2044\u001b[0m     output \u001b[39m=\u001b[39m call_func_with_variable_args(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc, \u001b[39minput\u001b[39;49m, run_manager, config)\n\u001b[1;32m   2045\u001b[0m     \u001b[39m# If the output is a runnable, invoke it\u001b[39;00m\n\u001b[1;32m   2046\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/schema/runnable/config.py:173\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39mif\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    172\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m run_manager\n\u001b[0;32m--> 173\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb Cell 143\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y303sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m full_chain \u001b[39m=\u001b[39m (\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y303sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     RunnablePassthrough\u001b[39m.\u001b[39massign(query \u001b[39m=\u001b[39m sql_response) \u001b[39m|\u001b[39m \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y303sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     RunnablePassthrough\u001b[39m.\u001b[39massign(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y303sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m         schema \u001b[39m=\u001b[39m get_schema,\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y303sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m         response\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x : db\u001b[39m.\u001b[39;49mrun(x[\u001b[39m'\u001b[39;49m\u001b[39mquery\u001b[39;49m\u001b[39m'\u001b[39;49m]),\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y303sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y303sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     ) \u001b[39m|\u001b[39m sql_prompt \u001b[39m|\u001b[39m model \u001b[39m|\u001b[39m StrOutputParser()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y303sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m )\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/utilities/sql_database.py:429\u001b[0m, in \u001b[0;36mSQLDatabase.run\u001b[0;34m(self, command, fetch)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\n\u001b[1;32m    420\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    421\u001b[0m     command: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    422\u001b[0m     fetch: Union[Literal[\u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m], Literal[\u001b[39m\"\u001b[39m\u001b[39mone\u001b[39m\u001b[39m\"\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    423\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    424\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Execute a SQL command and return a string representing the results.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \n\u001b[1;32m    426\u001b[0m \u001b[39m    If the statement returns rows, a string of the results is returned.\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \u001b[39m    If the statement returns no rows, an empty string is returned.\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 429\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute(command, fetch)\n\u001b[1;32m    430\u001b[0m     \u001b[39m# Convert columns values to string to avoid issues with sqlalchemy\u001b[39;00m\n\u001b[1;32m    431\u001b[0m     \u001b[39m# truncating text\u001b[39;00m\n\u001b[1;32m    432\u001b[0m     res \u001b[39m=\u001b[39m [\n\u001b[1;32m    433\u001b[0m         \u001b[39mtuple\u001b[39m(truncate_word(c, length\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_string_length) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m r\u001b[39m.\u001b[39mvalues())\n\u001b[1;32m    434\u001b[0m         \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m result\n\u001b[1;32m    435\u001b[0m     ]\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/utilities/sql_database.py:407\u001b[0m, in \u001b[0;36mSQLDatabase._execute\u001b[0;34m(self, command, fetch)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[39melse\u001b[39;00m:  \u001b[39m# postgresql and other compatible dialects\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         connection\u001b[39m.\u001b[39mexec_driver_sql(\u001b[39m\"\u001b[39m\u001b[39mSET search_path TO \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_schema,))\n\u001b[0;32m--> 407\u001b[0m cursor \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mexecute(text(command))\n\u001b[1;32m    408\u001b[0m \u001b[39mif\u001b[39;00m cursor\u001b[39m.\u001b[39mreturns_rows:\n\u001b[1;32m    409\u001b[0m     \u001b[39mif\u001b[39;00m fetch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1412\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1410\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mObjectNotExecutableError(statement) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   1411\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1412\u001b[0m     \u001b[39mreturn\u001b[39;00m meth(\n\u001b[1;32m   1413\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1414\u001b[0m         distilled_parameters,\n\u001b[1;32m   1415\u001b[0m         execution_options \u001b[39mor\u001b[39;49;00m NO_OPTIONS,\n\u001b[1;32m   1416\u001b[0m     )\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:516\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[0;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[39mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m    515\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, Executable)\n\u001b[0;32m--> 516\u001b[0m     \u001b[39mreturn\u001b[39;00m connection\u001b[39m.\u001b[39;49m_execute_clauseelement(\n\u001b[1;32m    517\u001b[0m         \u001b[39mself\u001b[39;49m, distilled_params, execution_options\n\u001b[1;32m    518\u001b[0m     )\n\u001b[1;32m    519\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mObjectNotExecutableError(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1635\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[0;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[1;32m   1623\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[39m=\u001b[39m execution_options\u001b[39m.\u001b[39mget(\n\u001b[1;32m   1624\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcompiled_cache\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_compiled_cache\n\u001b[1;32m   1625\u001b[0m )\n\u001b[1;32m   1627\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39m_compile_w_cache(\n\u001b[1;32m   1628\u001b[0m     dialect\u001b[39m=\u001b[39mdialect,\n\u001b[1;32m   1629\u001b[0m     compiled_cache\u001b[39m=\u001b[39mcompiled_cache,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1633\u001b[0m     linting\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\u001b[39m.\u001b[39mcompiler_linting \u001b[39m|\u001b[39m compiler\u001b[39m.\u001b[39mWARN_LINTING,\n\u001b[1;32m   1634\u001b[0m )\n\u001b[0;32m-> 1635\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_context(\n\u001b[1;32m   1636\u001b[0m     dialect,\n\u001b[1;32m   1637\u001b[0m     dialect\u001b[39m.\u001b[39;49mexecution_ctx_cls\u001b[39m.\u001b[39;49m_init_compiled,\n\u001b[1;32m   1638\u001b[0m     compiled_sql,\n\u001b[1;32m   1639\u001b[0m     distilled_parameters,\n\u001b[1;32m   1640\u001b[0m     execution_options,\n\u001b[1;32m   1641\u001b[0m     compiled_sql,\n\u001b[1;32m   1642\u001b[0m     distilled_parameters,\n\u001b[1;32m   1643\u001b[0m     elem,\n\u001b[1;32m   1644\u001b[0m     extracted_params,\n\u001b[1;32m   1645\u001b[0m     cache_hit\u001b[39m=\u001b[39;49mcache_hit,\n\u001b[1;32m   1646\u001b[0m )\n\u001b[1;32m   1647\u001b[0m \u001b[39mif\u001b[39;00m has_events:\n\u001b[1;32m   1648\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_execute(\n\u001b[1;32m   1649\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   1650\u001b[0m         elem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         ret,\n\u001b[1;32m   1655\u001b[0m     )\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1844\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1839\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exec_insertmany_context(\n\u001b[1;32m   1840\u001b[0m         dialect,\n\u001b[1;32m   1841\u001b[0m         context,\n\u001b[1;32m   1842\u001b[0m     )\n\u001b[1;32m   1843\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1844\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_exec_single_context(\n\u001b[1;32m   1845\u001b[0m         dialect, context, statement, parameters\n\u001b[1;32m   1846\u001b[0m     )\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1984\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1981\u001b[0m     result \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39m_setup_result_proxy()\n\u001b[1;32m   1983\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1984\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_dbapi_exception(\n\u001b[1;32m   1985\u001b[0m         e, str_statement, effective_parameters, cursor, context\n\u001b[1;32m   1986\u001b[0m     )\n\u001b[1;32m   1988\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[1;32m   2337\u001b[0m \u001b[39melif\u001b[39;00m should_wrap:\n\u001b[1;32m   2338\u001b[0m     \u001b[39massert\u001b[39;00m sqlalchemy_exception \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2339\u001b[0m     \u001b[39mraise\u001b[39;00m sqlalchemy_exception\u001b[39m.\u001b[39mwith_traceback(exc_info[\u001b[39m2\u001b[39m]) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m   2340\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2341\u001b[0m     \u001b[39massert\u001b[39;00m exc_info[\u001b[39m1\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1965\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1963\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1964\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1965\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[1;32m   1966\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[1;32m   1967\u001b[0m         )\n\u001b[1;32m   1969\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n\u001b[1;32m   1970\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1971\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   1972\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1976\u001b[0m         context\u001b[39m.\u001b[39mexecutemany,\n\u001b[1;32m   1977\u001b[0m     )\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py:921\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 921\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(statement, parameters)\n",
      "\u001b[0;31mOperationalError\u001b[0m: (sqlite3.OperationalError) no such table: Artist\n[SQL: SELECT COUNT(*) FROM Artist]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "full_chain.invoke({\"question\":\"How many Artist are there?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import XMLAgent, tool, AgentExecutor\n",
    "from langchain.chat_models import ChatAnthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_anthropic = ChatAnthropic(anthropic_api_key=\"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\", model = 'claude-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search(query: str)->str:\n",
    "    \"\"\"Search things about current event\"\"\"\n",
    "    return '32 degree'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_list = [search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['intermediate_steps', 'question', 'tools'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question', 'tools'], template=\"You are a helpful assistant. Help the user answer any questions.\\n\\nYou have access to the following tools:\\n\\n{tools}\\n\\nIn order to use a tool, you can use <tool></tool> and <tool_input></tool_input> tags. You will then get back a response in the form <observation></observation>\\nFor example, if you have a tool called 'search' that could run a google search, in order to search for the weather in SF you would respond:\\n\\n<tool>search</tool><tool_input>weather in SF</tool_input>\\n<observation>64 degrees</observation>\\n\\nWhen you are done, respond with a final answer between <final_answer></final_answer>. For example:\\n\\n<final_answer>The weather in SF is 64 degrees</final_answer>\\n\\nBegin!\\n\\nQuestion: {question}\")), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['intermediate_steps'], template='{intermediate_steps}'))])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get prompt from XMLAgent to use\n",
    "prompt = XMLAgent.get_default_prompt()\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Logic for going from intermediate steps to a string to pass into model\n",
    "# this is pretty tied  to the prompt\n",
    "\n",
    "def convert_intermadiate_steps(intermadiate_steps):\n",
    "    log = ''\n",
    "    for action, observation in intermadiate_steps:\n",
    "        log +=(\n",
    "            f\"<tool>{action.tool}</tool><tool_input>{action.tool_input}\"\n",
    "            f\"</tool_input><observation>{observation}</observation>\"\n",
    "        )\n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement Logic for converting tools to string to go in prompt\n",
    "def convert_tools(tools):\n",
    "    return \"\\n\".join([f\"{tool.name}:{tool.description}\" for tool in tools])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building an agent from a runnable usually involves a few things:\n",
    "\n",
    "Data processing for the intermediate steps. These need to represented in a way that the language model can recognize them. This should be pretty tightly coupled to the instructions in the prompt\n",
    "\n",
    "The prompt itself\n",
    "\n",
    "The model, complete with stop tokens if needed\n",
    "\n",
    "The output parser - should be in sync with how the prompt specifies things to be formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = (\n",
    "    {\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "        \"intermediate_steps\" : lambda x : convert_intermadiate_steps(x['intermediate_steps'])\n",
    "    }\n",
    "    | prompt.partial(tools = convert_tools(tool_list))\n",
    "    | model.bind(stop=[\"</tool_input>\", \"</final_answer>\"])\n",
    "    | XMLAgent.get_default_output_parser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agents, tools=tool_list,  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m<tool>search</tool><tool_input>weather in New York\u001b[0m\u001b[36;1m\u001b[1;3m32 degree\u001b[0m\u001b[32;1m\u001b[1;3m<final_answer>The weather in New York is 32 degrees.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'whats the wheather in new yorks',\n",
       " 'output': 'The weather in New York is 32 degrees.'}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"question\":\"whats the wheather in new yorks\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Memory  --> Memory have different but here we used conversational buffer memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.g you have an arbitray chain ---> here we show how to add memory with this arbitary chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\" , \"you are a helpful chatbot\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),    # MessagesPlaceholder: prompt template that assumes variables is already list of messages\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': []}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "chain = (RunnablePassthrough.assign(memory=memory.load_memory_variables)\n",
    "         | functools.partial(itemgetter('history'))\n",
    "         | prompt\n",
    "         | models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb Cell 164\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y325sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39mHi I m israr dawar from North Wazirstan\u001b[39m\u001b[39m\"\u001b[39m,}\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y325sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m response \u001b[39m=\u001b[39m chain\u001b[39m.\u001b[39;49minvoke(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y325sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m response\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/schema/runnable/base.py:1113\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1112\u001b[0m     \u001b[39mfor\u001b[39;00m i, step \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps):\n\u001b[0;32m-> 1113\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m   1114\u001b[0m             \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   1115\u001b[0m             \u001b[39m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   1116\u001b[0m             patch_config(\n\u001b[1;32m   1117\u001b[0m                 config, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mseq:step:\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   1118\u001b[0m             ),\n\u001b[1;32m   1119\u001b[0m         )\n\u001b[1;32m   1120\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/schema/runnable/base.py:2110\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvoke\u001b[39m(\n\u001b[1;32m   2104\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   2105\u001b[0m     \u001b[39minput\u001b[39m: Input,\n\u001b[1;32m   2106\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2107\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2108\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Output:\n\u001b[1;32m   2109\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfunc\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 2110\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_with_config(\n\u001b[1;32m   2111\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invoke,\n\u001b[1;32m   2112\u001b[0m             \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   2113\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_config(config, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc),\n\u001b[1;32m   2114\u001b[0m         )\n\u001b[1;32m   2115\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2116\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   2117\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2118\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUse `ainvoke` instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2119\u001b[0m         )\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/schema/runnable/base.py:633\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m    626\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    627\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m    628\u001b[0m     \u001b[39minput\u001b[39m,\n\u001b[1;32m    629\u001b[0m     run_type\u001b[39m=\u001b[39mrun_type,\n\u001b[1;32m    630\u001b[0m     name\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_name\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    631\u001b[0m )\n\u001b[1;32m    632\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 633\u001b[0m     output \u001b[39m=\u001b[39m call_func_with_variable_args(\n\u001b[1;32m    634\u001b[0m         func, \u001b[39minput\u001b[39;49m, run_manager, config, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    635\u001b[0m     )\n\u001b[1;32m    636\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    637\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/schema/runnable/config.py:173\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39mif\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    172\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m run_manager\n\u001b[0;32m--> 173\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/schema/runnable/base.py:2044\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[0;34m(self, input, run_manager, config)\u001b[0m\n\u001b[1;32m   2038\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_invoke\u001b[39m(\n\u001b[1;32m   2039\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   2040\u001b[0m     \u001b[39minput\u001b[39m: Input,\n\u001b[1;32m   2041\u001b[0m     run_manager: CallbackManagerForChainRun,\n\u001b[1;32m   2042\u001b[0m     config: RunnableConfig,\n\u001b[1;32m   2043\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Output:\n\u001b[0;32m-> 2044\u001b[0m     output \u001b[39m=\u001b[39m call_func_with_variable_args(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc, \u001b[39minput\u001b[39;49m, run_manager, config)\n\u001b[1;32m   2045\u001b[0m     \u001b[39m# If the output is a runnable, invoke it\u001b[39;00m\n\u001b[1;32m   2046\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/schema/runnable/config.py:173\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39mif\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    172\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m run_manager\n\u001b[0;32m--> 173\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'history'"
     ]
    }
   ],
   "source": [
    "input = {\"input\":\"Hi I m israr dawar from North Wazirstan\",}\n",
    "response = chain.invoke(input)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Moderatin:\n",
    "Means when you build LLM application and you want to add security or safeguard around LLM applicaiton then we used OpenAIModerationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import OpenAIModerationChain\n",
    "\n",
    "moderate = OpenAIModerationChain(openai_api_key=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='repeat after me: {input}'))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"repeat after me: {input}\")\n",
    "])\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1 = prompt | models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry, but I'm unable to assist with that request.\")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain1.invoke({\"input\":\"porn\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type AIMessage is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb Cell 170\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y346sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m moderate_chain \u001b[39m=\u001b[39m chain1 \u001b[39m|\u001b[39m moderate\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y346sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m moderate_chain\u001b[39m.\u001b[39;49minvoke({\u001b[39m\"\u001b[39;49m\u001b[39minput\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m\"\u001b[39;49m\u001b[39myou are stupid\u001b[39;49m\u001b[39m\"\u001b[39;49m})\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/schema/runnable/base.py:1113\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1112\u001b[0m     \u001b[39mfor\u001b[39;00m i, step \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps):\n\u001b[0;32m-> 1113\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m   1114\u001b[0m             \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   1115\u001b[0m             \u001b[39m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   1116\u001b[0m             patch_config(\n\u001b[1;32m   1117\u001b[0m                 config, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mseq:step:\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   1118\u001b[0m             ),\n\u001b[1;32m   1119\u001b[0m         )\n\u001b[1;32m   1120\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/chains/base.py:84\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvoke\u001b[39m(\n\u001b[1;32m     78\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     79\u001b[0m     \u001b[39minput\u001b[39m: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m     80\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     81\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m     82\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[1;32m     83\u001b[0m     config \u001b[39m=\u001b[39m config \u001b[39mor\u001b[39;00m {}\n\u001b[0;32m---> 84\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(\n\u001b[1;32m     85\u001b[0m         \u001b[39minput\u001b[39;49m,\n\u001b[1;32m     86\u001b[0m         callbacks\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcallbacks\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     87\u001b[0m         tags\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mtags\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     88\u001b[0m         metadata\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     89\u001b[0m         run_name\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mrun_name\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     90\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m     91\u001b[0m     )\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/chains/base.py:306\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    305\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 306\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    307\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    308\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    309\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    310\u001b[0m )\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/chains/base.py:300\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    293\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    294\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m    295\u001b[0m     inputs,\n\u001b[1;32m    296\u001b[0m     name\u001b[39m=\u001b[39mrun_name,\n\u001b[1;32m    297\u001b[0m )\n\u001b[1;32m    298\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 300\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    301\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    302\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    303\u001b[0m     )\n\u001b[1;32m    304\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    305\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/chains/moderation.py:93\u001b[0m, in \u001b[0;36mOpenAIModerationChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\n\u001b[1;32m     88\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     89\u001b[0m     inputs: Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m],\n\u001b[1;32m     90\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     91\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m     92\u001b[0m     text \u001b[39m=\u001b[39m inputs[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key]\n\u001b[0;32m---> 93\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(text)\n\u001b[1;32m     94\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_moderate(text, results[\u001b[39m\"\u001b[39m\u001b[39mresults\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m])\n\u001b[1;32m     95\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key: output}\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/openai/api_resources/moderation.py:35\u001b[0m, in \u001b[0;36mModeration.create\u001b[0;34m(cls, input, model, api_key)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m     29\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     api_key: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     33\u001b[0m ):\n\u001b[1;32m     34\u001b[0m     instance, params \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_prepare_create(\u001b[39minput\u001b[39m, model, api_key)\n\u001b[0;32m---> 35\u001b[0m     \u001b[39mreturn\u001b[39;00m instance\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mget_url(), params)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/openai/openai_object.py:179\u001b[0m, in \u001b[0;36mOpenAIObject.request\u001b[0;34m(self, method, url, params, headers, stream, plain_old_data, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    171\u001b[0m     params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve_params\n\u001b[1;32m    172\u001b[0m requestor \u001b[39m=\u001b[39m api_requestor\u001b[39m.\u001b[39mAPIRequestor(\n\u001b[1;32m    173\u001b[0m     key\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key,\n\u001b[1;32m    174\u001b[0m     api_base\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_base_override \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_base(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m     organization\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39morganization,\n\u001b[1;32m    178\u001b[0m )\n\u001b[0;32m--> 179\u001b[0m response, stream, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    180\u001b[0m     method,\n\u001b[1;32m    181\u001b[0m     url,\n\u001b[1;32m    182\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    183\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    184\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    185\u001b[0m     request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    186\u001b[0m     request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    187\u001b[0m )\n\u001b[1;32m    189\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    190\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)  \u001b[39m# must be an iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/openai/api_requestor.py:289\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    279\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    280\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    288\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[1;32m    290\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[1;32m    291\u001b[0m         url,\n\u001b[1;32m    292\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    293\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    294\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    295\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    296\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    297\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    298\u001b[0m     )\n\u001b[1;32m    299\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/openai/api_requestor.py:591\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest_raw\u001b[39m(\n\u001b[1;32m    580\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    581\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    590\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m requests\u001b[39m.\u001b[39mResponse:\n\u001b[0;32m--> 591\u001b[0m     abs_url, headers, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_request_raw(\n\u001b[1;32m    592\u001b[0m         url, supplied_headers, method, params, files, request_id\n\u001b[1;32m    593\u001b[0m     )\n\u001b[1;32m    595\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(_thread_context, \u001b[39m\"\u001b[39m\u001b[39msession\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    596\u001b[0m         _thread_context\u001b[39m.\u001b[39msession \u001b[39m=\u001b[39m _make_session()\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/openai/api_requestor.py:563\u001b[0m, in \u001b[0;36mAPIRequestor._prepare_request_raw\u001b[0;34m(self, url, supplied_headers, method, params, files, request_id)\u001b[0m\n\u001b[1;32m    561\u001b[0m         data \u001b[39m=\u001b[39m params\n\u001b[1;32m    562\u001b[0m     \u001b[39mif\u001b[39;00m params \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m files:\n\u001b[0;32m--> 563\u001b[0m         data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mdumps(params)\u001b[39m.\u001b[39mencode()\n\u001b[1;32m    564\u001b[0m         headers[\u001b[39m\"\u001b[39m\u001b[39mContent-Type\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mapplication/json\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    565\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/__init__.py:231\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[39m# cached encoder\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m skipkeys \u001b[39mand\u001b[39;00m ensure_ascii \u001b[39mand\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     check_circular \u001b[39mand\u001b[39;00m allow_nan \u001b[39mand\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m indent \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m separators \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     default \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m sort_keys \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 231\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_encoder\u001b[39m.\u001b[39;49mencode(obj)\n\u001b[1;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONEncoder\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[39mreturn\u001b[39;00m encode_basestring(o)\n\u001b[1;32m    196\u001b[0m \u001b[39m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterencode(o, _one_shot\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    200\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(chunks, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m    201\u001b[0m     chunks \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(chunks)\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     _iterencode \u001b[39m=\u001b[39m _make_iterencode(\n\u001b[1;32m    254\u001b[0m         markers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault, _encoder, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindent, floatstr,\n\u001b[1;32m    255\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey_separator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_separator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msort_keys,\n\u001b[1;32m    256\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m _iterencode(o, \u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault\u001b[39m(\u001b[39mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mObject of type \u001b[39m\u001b[39m{\u001b[39;00mo\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mis not JSON serializable\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type AIMessage is not JSON serializable"
     ]
    }
   ],
   "source": [
    "moderate_chain = chain1 | moderate\n",
    "moderate_chain.invoke({\"input\":\"you are stupid\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using tools\n",
    "we can use any Tools with runnables easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import DuckDuckGoSearchRun  # tools that queries the DuckDcukGo search apo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import duckduckgo-search python package. Please install it with `pip install duckduckgo-search`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/utilities/duckduckgo_search.py:31\u001b[0m, in \u001b[0;36mDuckDuckGoSearchAPIWrapper.validate_environment\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 31\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mduckduckgo_search\u001b[39;00m \u001b[39mimport\u001b[39;00m DDGS  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'duckduckgo_search'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb Cell 173\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y353sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m duckduck_go_search_engine \u001b[39m=\u001b[39m DuckDuckGoSearchRun()\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/load/serializable.py:97\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     98\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lc_kwargs \u001b[39m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/pydantic/v1/main.py:339\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39mCreate a new model by parsing and validating input data from keyword arguments.\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[39mRaises ValidationError if the input data cannot be parsed to form a valid model.\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[39m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m values, fields_set, validation_error \u001b[39m=\u001b[39m validate_model(__pydantic_self__\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m, data)\n\u001b[1;32m    340\u001b[0m \u001b[39mif\u001b[39;00m validation_error:\n\u001b[1;32m    341\u001b[0m     \u001b[39mraise\u001b[39;00m validation_error\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/pydantic/v1/main.py:1066\u001b[0m, in \u001b[0;36mvalidate_model\u001b[0;34m(model, input_data, cls)\u001b[0m\n\u001b[1;32m   1063\u001b[0m     errors\u001b[39m.\u001b[39mappend(ErrorWrapper(MissingError(), loc\u001b[39m=\u001b[39mfield\u001b[39m.\u001b[39malias))\n\u001b[1;32m   1064\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m-> 1066\u001b[0m value \u001b[39m=\u001b[39m field\u001b[39m.\u001b[39;49mget_default()\n\u001b[1;32m   1068\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m config\u001b[39m.\u001b[39mvalidate_all \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m field\u001b[39m.\u001b[39mvalidate_always:\n\u001b[1;32m   1069\u001b[0m     values[name] \u001b[39m=\u001b[39m value\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/pydantic/v1/fields.py:439\u001b[0m, in \u001b[0;36mModelField.get_default\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_default\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 439\u001b[0m     \u001b[39mreturn\u001b[39;00m smart_deepcopy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault_factory \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdefault_factory()\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/pydantic/v1/main.py:339\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39mCreate a new model by parsing and validating input data from keyword arguments.\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[39mRaises ValidationError if the input data cannot be parsed to form a valid model.\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[39m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m values, fields_set, validation_error \u001b[39m=\u001b[39m validate_model(__pydantic_self__\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m, data)\n\u001b[1;32m    340\u001b[0m \u001b[39mif\u001b[39;00m validation_error:\n\u001b[1;32m    341\u001b[0m     \u001b[39mraise\u001b[39;00m validation_error\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/pydantic/v1/main.py:1102\u001b[0m, in \u001b[0;36mvalidate_model\u001b[0;34m(model, input_data, cls)\u001b[0m\n\u001b[1;32m   1100\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1102\u001b[0m     values \u001b[39m=\u001b[39m validator(cls_, values)\n\u001b[1;32m   1103\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m, \u001b[39mAssertionError\u001b[39;00m) \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m   1104\u001b[0m     errors\u001b[39m.\u001b[39mappend(ErrorWrapper(exc, loc\u001b[39m=\u001b[39mROOT_KEY))\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/utilities/duckduckgo_search.py:33\u001b[0m, in \u001b[0;36mDuckDuckGoSearchAPIWrapper.validate_environment\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mduckduckgo_search\u001b[39;00m \u001b[39mimport\u001b[39;00m DDGS  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m     34\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCould not import duckduckgo-search python package. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     35\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease install it with `pip install duckduckgo-search`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m     )\n\u001b[1;32m     37\u001b[0m \u001b[39mreturn\u001b[39;00m values\n",
      "\u001b[0;31mImportError\u001b[0m: Could not import duckduckgo-search python package. Please install it with `pip install duckduckgo-search`."
     ]
    }
   ],
   "source": [
    "duckduck_go_search_engine = DuckDuckGoSearchRun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckduck_go_tempelate = \"\"\"Turn the following user input into a search query for search engine\n",
    "{input}\"\"\"\n",
    "\n",
    "prompte_temp_duck = ChatPromptTemplate.from_template(duckduck_go_tempelate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckduck_chain = prompte_temp_duck | model | StrOutputParser() | duckduck_go_search_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckduck_chain.invoke({\"input\":\"I did like to figure out what games are tommorrow in cricket world cup\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Docuement loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Document loader deal with some specific access and data type:\n",
    "# 1: website, youtube, etc\n",
    "# 2: pdf, html, json, word, powerpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage, FunctionMessage\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temperature ---> parameter of openai with the help of the parameter(temperature) we can control the output/creativity of LLM\n",
    "\n",
    "llm = OpenAI(openai_api_key=\"\", temperature=0)\n",
    "chat_model = ChatOpenAI(openai_api_key= \"\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Hello,\\n\\nMy name is Israr dawar and I’d love to help you launch your new website. I am a web developer(Backend), who has worked on many different websites. I studied web development for 2 years and have worked with startups to build their web presence over the past 2 years.\\n\\nI’d be happy to tailor it to your needs. I understand you are a new company and I am happy to be flexible to make sure we work with your timeline. Could you tell me more about your target market and audience? If you are unsure, I can brainstorm with you on this point.\\n\\nDo let me know if you have any questions and I am excited to have the possibility to work on this project!\\nTo know about my experience please visit my Github profile https://github.com/israr96418\\nBest regards,\\n\\nIsrar Dawar', metadata={'source': 'webproposal.txt'})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = TextLoader('webproposal.txt')\n",
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CSV file**: a comma seperate value file, is a delimited text file ,that uses a comma to seperate values.\n",
    "Each line of the file is a data record. Each record consists of one or more fields, seperated by comma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "loader = CSVLoader('PlayTennis.csv')\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='outlook: sunny\\ntemp: hot\\nhumidity: high\\nwindy: false\\nplay: no', metadata={'source': 'PlayTennis.csv', 'row': 0}),\n",
       " Document(page_content='outlook: sunny\\ntemp: hot\\nhumidity: high\\nwindy: true\\nplay: no', metadata={'source': 'PlayTennis.csv', 'row': 1}),\n",
       " Document(page_content='outlook: overcast\\ntemp: hot\\nhumidity: high\\nwindy: false\\nplay: yes', metadata={'source': 'PlayTennis.csv', 'row': 2}),\n",
       " Document(page_content='outlook: rainy\\ntemp: mild\\nhumidity: high\\nwindy: false\\nplay: yes', metadata={'source': 'PlayTennis.csv', 'row': 3}),\n",
       " Document(page_content='outlook: rainy\\ntemp: cool\\nhumidity: normal\\nwindy: false\\nplay: yes', metadata={'source': 'PlayTennis.csv', 'row': 4}),\n",
       " Document(page_content='outlook: rainy\\ntemp: cool\\nhumidity: normal\\nwindy: true\\nplay: no', metadata={'source': 'PlayTennis.csv', 'row': 5}),\n",
       " Document(page_content='outlook: overcast\\ntemp: cool\\nhumidity: normal\\nwindy: true\\nplay: yes', metadata={'source': 'PlayTennis.csv', 'row': 6}),\n",
       " Document(page_content='outlook: sunny\\ntemp: mild\\nhumidity: high\\nwindy: false\\nplay: no', metadata={'source': 'PlayTennis.csv', 'row': 7}),\n",
       " Document(page_content='outlook: sunny\\ntemp: cool\\nhumidity: normal\\nwindy: false\\nplay: yes', metadata={'source': 'PlayTennis.csv', 'row': 8}),\n",
       " Document(page_content='outlook: rainy\\ntemp: mild\\nhumidity: normal\\nwindy: false\\nplay: yes', metadata={'source': 'PlayTennis.csv', 'row': 9}),\n",
       " Document(page_content='outlook: sunny\\ntemp: mild\\nhumidity: normal\\nwindy: true\\nplay: yes', metadata={'source': 'PlayTennis.csv', 'row': 10}),\n",
       " Document(page_content='outlook: overcast\\ntemp: mild\\nhumidity: high\\nwindy: true\\nplay: yes', metadata={'source': 'PlayTennis.csv', 'row': 11}),\n",
       " Document(page_content='outlook: overcast\\ntemp: hot\\nhumidity: normal\\nwindy: false\\nplay: yes', metadata={'source': 'PlayTennis.csv', 'row': 12}),\n",
       " Document(page_content='outlook: rainy\\ntemp: mild\\nhumidity: high\\nwindy: true\\nplay: no', metadata={'source': 'PlayTennis.csv', 'row': 13})]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes CSV file are so big(means they contain so much data) we don,t want to print all records and all columns \n",
    "# So we Customizing the CSV --> parsing and loading\n",
    "customize_csv_loader = CSVLoader(file_path='PlayTennis.csv' , csv_args={\n",
    "    'delimiter': ',',\n",
    "    'quotechar': '\"',\n",
    "    'fieldnames' : ['temp',\"play\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error loading PlayTennis.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/document_loaders/csv_loader.py:66\u001b[0m, in \u001b[0;36mCSVLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_path, newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding) \u001b[39mas\u001b[39;00m csvfile:\n\u001b[0;32m---> 66\u001b[0m         docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__read_file(csvfile)\n\u001b[1;32m     67\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mUnicodeDecodeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/document_loaders/csv_loader.py:90\u001b[0m, in \u001b[0;36mCSVLoader.__read_file\u001b[0;34m(self, csvfile)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mfor\u001b[39;00m i, row \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(csv_reader):\n\u001b[0;32m---> 90\u001b[0m     content \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mk\u001b[39m.\u001b[39;49mstrip()\u001b[39m}\u001b[39;49;00m\u001b[39m: \u001b[39;49m\u001b[39m{\u001b[39;49;00mv\u001b[39m.\u001b[39;49mstrip()\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m \u001b[39mfor\u001b[39;49;00m k, v \u001b[39min\u001b[39;49;00m row\u001b[39m.\u001b[39;49mitems())\n\u001b[1;32m     91\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/document_loaders/csv_loader.py:90\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mfor\u001b[39;00m i, row \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(csv_reader):\n\u001b[0;32m---> 90\u001b[0m     content \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m.\u001b[39;49mstrip()\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mv\u001b[39m.\u001b[39mstrip()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m row\u001b[39m.\u001b[39mitems())\n\u001b[1;32m     91\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'strip'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb Cell 189\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y355sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m data_customize_cvsfile \u001b[39m=\u001b[39m customize_csv_loader\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y355sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m data_customize_cvsfile \n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/document_loaders/csv_loader.py:82\u001b[0m, in \u001b[0;36mCSVLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError loading \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m---> 82\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError loading \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[39mreturn\u001b[39;00m docs\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error loading PlayTennis.csv"
     ]
    }
   ],
   "source": [
    "\n",
    "data_customize_cvsfile = customize_csv_loader.load()\n",
    "data_customize_cvsfile \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specify the columns to identify source document**:\n",
    "use the \"**source_column**\" argument to specify a source for the document create for each row. otherwise file path will be used\n",
    "as the source for all documents created from csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very very useful to specify a column to identity source document when using docuemnt loaded from csv file<br>\n",
    "for chain that answer and question using sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = CSVLoader(file_path=\"PlayTennis.csv\", source_column='play_or_not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error loading PlayTennis.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/document_loaders/csv_loader.py:93\u001b[0m, in \u001b[0;36mCSVLoader.__read_file\u001b[0;34m(self, csvfile)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     source \u001b[39m=\u001b[39m (\n\u001b[0;32m---> 93\u001b[0m         row[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msource_column]\n\u001b[1;32m     94\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_column \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_path\n\u001b[1;32m     96\u001b[0m     )\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'play_or_not'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/document_loaders/csv_loader.py:66\u001b[0m, in \u001b[0;36mCSVLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_path, newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding) \u001b[39mas\u001b[39;00m csvfile:\n\u001b[0;32m---> 66\u001b[0m         docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__read_file(csvfile)\n\u001b[1;32m     67\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mUnicodeDecodeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/document_loaders/csv_loader.py:98\u001b[0m, in \u001b[0;36mCSVLoader.__read_file\u001b[0;34m(self, csvfile)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     99\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSource column \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_column\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m not found in CSV file.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m     )\n\u001b[1;32m    101\u001b[0m metadata \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39msource\u001b[39m\u001b[39m\"\u001b[39m: source, \u001b[39m\"\u001b[39m\u001b[39mrow\u001b[39m\u001b[39m\"\u001b[39m: i}\n",
      "\u001b[0;31mValueError\u001b[0m: Source column 'play_or_not' not found in CSV file.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb Cell 192\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y360sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m loaders\u001b[39m.\u001b[39;49mload()\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/document_loaders/csv_loader.py:82\u001b[0m, in \u001b[0;36mCSVLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError loading \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m---> 82\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError loading \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[39mreturn\u001b[39;00m docs\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error loading PlayTennis.csv"
     ]
    }
   ],
   "source": [
    "loaders.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Directory:\n",
    "In this section we study how to load all documents which are present in the directory\n",
    "By default this uses the UnstructureLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected directory, got file: 'dataset/PlayTennis.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb Cell 196\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y362sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Here we can use \"glob\" parameter to control which files to load\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y362sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# Note: Here it does,t load the .rst file or the .html\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y362sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m directory_loder \u001b[39m=\u001b[39m  DirectoryLoader(\u001b[39m'\u001b[39m\u001b[39mdataset/PlayTennis.csv\u001b[39m\u001b[39m'\u001b[39m, glob\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m**/*.md\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y362sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m directory_loder\u001b[39m.\u001b[39;49mload()\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/document_loaders/directory.py:116\u001b[0m, in \u001b[0;36mDirectoryLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDirectory not found: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m p\u001b[39m.\u001b[39mis_dir():\n\u001b[0;32m--> 116\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected directory, got file: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    118\u001b[0m docs: List[Document] \u001b[39m=\u001b[39m []\n\u001b[1;32m    119\u001b[0m items \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(p\u001b[39m.\u001b[39mrglob(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mglob) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecursive \u001b[39melse\u001b[39;00m p\u001b[39m.\u001b[39mglob(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mglob))\n",
      "\u001b[0;31mValueError\u001b[0m: Expected directory, got file: 'dataset/PlayTennis.csv'"
     ]
    }
   ],
   "source": [
    "# Here we can use \"glob\" parameter to control which files to load\n",
    "# Note: Here it does,t load the .rst file or the .html\n",
    "directory_loder =  DirectoryLoader('dataset/PlayTennis.csv', glob='**/*.md')\n",
    "directory_loder.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show progress bar**:\n",
    "by default progress bar does,t show if you want to show progress bar use \"show_progress = True\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_loder =  DirectoryLoader('../Langchain_AI_handbook/dataset/PlayTennis.csv', glob='**/*.csv', show_progress=True)\n",
    "directory_loder.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use Multithreading**:\n",
    "By defualt loading happen in one thread. in order to utilized several threads set the \"use_multithreadin\" flag to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_loder =  DirectoryLoader('../Langchain_AI_handbook/dataset/PlayTennis.csv', glob='**/*.csv', show_progress=True, use_multithreading=True)\n",
    "directory_loder.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change Loader Class**:\n",
    "by default it uses \"unstructureloader\" class. you change this very easily to structureloader class by using \"loader_cls = Textloader\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "directory_loder =  DirectoryLoader('../Langchain_AI_handbook/dataset/PlayTennis.csv', glob='**/*.csv', show_progress=True, use_multithreading=True, loader_cls=TextLoader)\n",
    "directory_loder.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML:\n",
    " here we show to load html documents into a document formate that can be used downstram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredHTMLLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Test your backend', metadata={'source': 'dataset/backend_test.html'})]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_loader = UnstructuredHTMLLoader(\"dataset/backend_test.html\")\n",
    "html_docs = html_loader.load()\n",
    "html_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF\n",
    "Here we cover how to load pdf documents into document formate that we use downstream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use PyPDF to load pdf documents**\n",
    "here we used PyPDF to load pdf documents into array of documents that contain page_content and metadata with page_num <br>\n",
    "to load documents with 'PyPDF' having several advantages<br>\n",
    "1:convert into array of documents<br>\n",
    "2: every documents having page_content, metadata and page_numer<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_loader = PyPDFLoader('ADAM Research paper.pdf')\n",
    "pdf_data = pdf_loader.load()\n",
    "len(pdf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "{'source': 'ADAM Research paper.pdf', 'page': 14}\n",
      "Published as a conference paper at ICLR 2015\n",
      "4 C ONVERGENCE ANALYSIS\n",
      "We analyze the convergence of Adam using the online learning framework proposed in (Zinkevich,\n",
      "2003). Given an arbitrary, unknown sequence of convex cost functions f1(θ),f2(θ),...,fT(θ). At\n",
      "each timet, our goal is to predict the parameter θtand evaluate it on a previously unknown cost\n",
      "functionft. Since the nature of the sequence is unknown in advance, we evaluate our algorithm\n",
      "using the regret, that is the sum of all the previous difference between the online prediction ft(θt)\n",
      "and the best ﬁxed point parameter ft(θ∗)from a feasible setXfor all the previous steps. Concretely,\n",
      "the regret is deﬁned as:\n",
      "R(T) =T∑\n",
      "t=1[ft(θt)−ft(θ∗)] (5)\n",
      "whereθ∗= arg min θ∈X∑T\n",
      "t=1ft(θ). We show Adam has O(√\n",
      "T)regret bound and a proof is given\n",
      "in the appendix. Our result is comparable to the best known bound for this general convex online\n",
      "learning problem. We also use some deﬁnitions simplify our notation, where gt≜∇ft(θt)andgt,i\n",
      "as theithelement. We deﬁne g1:t,i∈Rtas a vector that contains the ithdimension of the gradients\n",
      "over all iterations till t,g1:t,i= [g1,i,g2,i,···,gt,i]. Also, we deﬁne γ≜β2\n",
      "1√β2. Our following\n",
      "theorem holds when the learning rate αtis decaying at a rate of t−1\n",
      "2and ﬁrst moment running\n",
      "average coefﬁcient β1,tdecay exponentially with λ, that is typically close to 1, e.g. 1−10−8.\n",
      "Theorem 4.1. Assume that the function fthas bounded gradients, ∥∇ft(θ)∥2≤G,∥∇ft(θ)∥∞≤\n",
      "G∞for allθ∈Rdand distance between any θtgenerated by Adam is bounded, ∥θn−θm∥2≤D,\n",
      "∥θm−θn∥∞≤D∞for anym,n∈{1,...,T}, andβ1,β2∈[0,1)satisfyβ2\n",
      "1√β2<1. Letαt=α√\n",
      "t\n",
      "andβ1,t=β1λt−1,λ∈(0,1). Adam achieves the following guarantee, for all T≥1.\n",
      "R(T)≤D2\n",
      "2α(1−β1)d∑\n",
      "i=1√\n",
      "TˆvT,i+α(1 +β1)G∞\n",
      "(1−β1)√1−β2(1−γ)2d∑\n",
      "i=1∥g1:T,i∥2+d∑\n",
      "i=1D2\n",
      "∞G∞√1−β2\n",
      "2α(1−β1)(1−λ)2\n",
      "Our Theorem 4.1 implies when the data features are sparse and bounded gradients, the sum-\n",
      "mation term can be much smaller than its upper bound∑d\n",
      "i=1∥g1:T,i∥2<< dG∞√\n",
      "Tand∑d\n",
      "i=1√\n",
      "TˆvT,i<<dG∞√\n",
      "T, in particular if the class of function and data features are in the form of\n",
      "section 1.2 in (Duchi et al., 2011). Their results for the expected value E[∑d\n",
      "i=1∥g1:T,i∥2]also apply\n",
      "to Adam. In particular, the adaptive method, such as Adam and Adagrad, can achieve O(logd√\n",
      "T),\n",
      "an improvement over O(√\n",
      "dT)for the non-adaptive method. Decaying β1,ttowards zero is impor-\n",
      "tant in our theoretical analysis and also matches previous empirical ﬁndings, e.g. (Sutskever et al.,\n",
      "2013) suggests reducing the momentum coefﬁcient in the end of training can improve convergence.\n",
      "Finally, we can show the average regret of Adam converges,\n",
      "Corollary 4.2. Assume that the function fthas bounded gradients, ∥∇ft(θ)∥2≤G,∥∇ft(θ)∥∞≤\n",
      "G∞for allθ∈Rdand distance between any θtgenerated by Adam is bounded, ∥θn−θm∥2≤D,\n",
      "∥θm−θn∥∞≤D∞for anym,n∈{1,...,T}. Adam achieves the following guarantee, for all\n",
      "T≥1.\n",
      "R(T)\n",
      "T=O(1√\n",
      "T)\n",
      "This result can be obtained by using Theorem 4.1 and∑d\n",
      "i=1∥g1:T,i∥2≤dG∞√\n",
      "T. Thus,\n",
      "limT→∞R(T)\n",
      "T= 0.\n",
      "5 R ELATED WORK\n",
      "Optimization methods bearing a direct relation to Adam are RMSProp (Tieleman & Hinton, 2012;\n",
      "Graves, 2013) and AdaGrad (Duchi et al., 2011); these relationships are discussed below. Other\n",
      "stochastic optimization methods include vSGD (Schaul et al., 2012), AdaDelta (Zeiler, 2012) and the\n",
      "natural Newton method from Roux & Fitzgibbon (2010), all setting stepsizes by estimating curvature\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(type(pdf_data))\n",
    "print(pdf_data[14].metadata)\n",
    "print(pdf_data[3].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10: Published as a conference paper at ICLR 2015\n",
      "Roux, Nicolas L and Fitzgibbon, Andrew W. A fast natural newton method. In Proceedings of the 27th\n",
      "International Conference on Machine Learning (ICML-10) , pp. 623–630, 2010.\n",
      "Ruppert, David. Efﬁcient estimations from a slowly convergent robbins-monro proc\n",
      "5: Published as a conference paper at ICLR 2015\n",
      "0 5 10 15 20 25 30 35 40 45\n",
      "iterations over entire dataset0.20.30.40.50.60.7training costMNIST Logistic Regression\n",
      "AdaGrad\n",
      "SGDNesterov\n",
      "Adam\n",
      "0 20 40 60 80 100 120 140 160\n",
      "iterations over entire dataset0.200.250.300.350.400.450.50training costIMDB BoW featu\n"
     ]
    }
   ],
   "source": [
    "faiss_index = FAISS.from_documents(pdf_data, OpenAIEmbeddings(openai_api_key=\"\"))\n",
    "docs = faiss_index.similarity_search(\"How will the community be engaged?\", k=2)\n",
    "for doc in docs:\n",
    "    print(str(doc.metadata[\"page\"]) + \":\", doc.page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'faiss_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb Cell 213\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y422sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m retrieval_from_vectores_stores \u001b[39m=\u001b[39m faiss_index\u001b[39m.\u001b[39mas_retriever()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y422sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m template \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\u001b[39mAnswer the quesiton based only the following context:\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y422sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m{context}\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y422sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mQuestion: \u001b[39m\u001b[39m{question}\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y422sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y422sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m prompt \u001b[39m=\u001b[39m ChatPromptTemplate\u001b[39m.\u001b[39mfrom_template(template)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'faiss_index' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "retrieval_from_vectores_stores = faiss_index.as_retriever()\n",
    "template = \"\"\"Answer the quesiton based only the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "retrive_chain = (\n",
    "    {\"context\":retrieval_from_vectores_stores, \"question\":RunnablePassthrough()}     #runnable which pass through input \n",
    "    | prompt | chat_model | StrOutputParser()\n",
    ")\n",
    "\n",
    "retrive_chain.invoke(\"Tell Adam\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documents Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1: HTMLHeaderTextSpliter ---> structure-aware chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description and Motivation\n",
    "# HTMLHeaderTextSpliter ---> is a structure-aware chunker that split text at the elements \n",
    "# level and add metadata for each header \"relevant\" to any given chunks\n",
    "# It can return chunks element by element or combine elements with the same metadata,\n",
    "# with the objectives of (a): keeping related text grouped (more or less) semantically\n",
    "# (b): preserving context-rich information encoding in document structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import HTMLHeaderTextSplitter\n",
    "html_string = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<body>\n",
    "    <div>\n",
    "        <h1>Foo</h1>\n",
    "        <p>Some intro text about Foo.</p>\n",
    "        <div>\n",
    "            <h2>Bar main section</h2>\n",
    "            <p>Some intro text about Bar.</p>\n",
    "            <h3>Bar subsection 1</h3>\n",
    "            <p>Some text about the first subtopic of Bar.</p>\n",
    "            <h3>Bar subsection 2</h3>\n",
    "            <p>Some text about the second subtopic of Bar.</p>\n",
    "        </div>\n",
    "        <div>\n",
    "            <h2>Baz</h2>\n",
    "            <p>Some text about Baz</p>\n",
    "        </div>\n",
    "        <br>\n",
    "        <p>Some concluding text about Foo</p>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_to_split_on = [\n",
    "    (\"h1\",\"Header 1\"),\n",
    "    (\"h2\",\"Header 2\"),\n",
    "    (\"h3\",\"Header 3\")\n",
    "]\n",
    "\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=header_to_split_on)\n",
    "\n",
    "# if you have html docs in your local dics then used html_splitter.split_text_from_file(<file_path>)\n",
    "html_header_splitts = html_splitter.split_text(html_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Foo'),\n",
       " Document(page_content='Some intro text about Foo.  \\nBar main section Bar subsection 1 Bar subsection 2', metadata={'Header 1': 'Foo'}),\n",
       " Document(page_content='Some intro text about Bar.', metadata={'Header 1': 'Foo', 'Header 2': 'Bar main section'}),\n",
       " Document(page_content='Some text about the first subtopic of Bar.', metadata={'Header 1': 'Foo', 'Header 2': 'Bar main section', 'Header 3': 'Bar subsection 1'}),\n",
       " Document(page_content='Some text about the second subtopic of Bar.', metadata={'Header 1': 'Foo', 'Header 2': 'Bar main section', 'Header 3': 'Bar subsection 2'}),\n",
       " Document(page_content='Baz', metadata={'Header 1': 'Foo'}),\n",
       " Document(page_content='Some text about Baz', metadata={'Header 1': 'Foo', 'Header 2': 'Baz'}),\n",
       " Document(page_content='Some concluding text about Foo', metadata={'Header 1': 'Foo'})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_header_splitts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipelined to another splitter , with html loaded from a web url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Stanford Encyclopedia of Philosophy  \\nMenu  \\nBrowse About Support SEP  \\nTable of Contents What's New Random Entry Chronological Archives  \\nEditorial Information About the SEP Editorial Board How to Cite the SEP Special Characters Advanced Tools Contact  \\nSupport the SEP PDFs for SEP Friends Make a Donation SEPIA for Libraries  \\nEntry Navigation  \\nEntry Contents Bibliography Academic Tools Friends PDF Preview Author and Citation Info Back to Top  \\nKurt Gödel\"),\n",
       " Document(page_content='First published Tue Feb 13, 2007; substantive revision Fri Dec 11, 2015  \\nKurt Friedrich Gödel (b. 1906, d. 1978) was one of the principal founders of the modern, metamathematical era in mathematical logic. He is widely known for his Incompleteness Theorems, which are among the handful of landmark theorems in twentieth century mathematics, but his work touched every field of mathematical logic, if it was not in most cases their original stimulus. In his philosophical work Gödel formulated and defended mathematical Platonism, the view that mathematics is a descriptive science, or alternatively the view that the concept of mathematical truth is objective. On the basis of that viewpoint he laid the foundation for the program of conceptual analysis within set theory (see below). He adhered to Hilbert’s “original rationalistic conception” in mathematics (as he called it);[1] and he was prophetic in anticipating and emphasizing the importance of large cardinals in set theory before their importance became clear.  \\n1. Biographical Sketch 2. Gödel’s Mathematical Work 3. Gödel’s Philosophical Views Bibliography Academic Tools Other Internet Resources Related Entries  \\n2.1 The Completeness Theorem 2.2 The Incompleteness Theorems 2.3 Speed-up Theorems 2.4 Gödel’s Work in Set theory 2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic Supplement Document: Gödel’s Documents  \\n2.1.1 Introduction 2.1.2 Proof of the Completeness Theorem 2.1.3 An Important Consequence of the Completeness Theorem  \\n2.2.1 The First Incompleteness Theorem 2.2.2 The proof of the First Incompleteness Theorem 2.2.3 The Second Incompleteness Theorem Supplementary Document: Did the Incompleteness Theorems Refute Hilbert’s Program?  \\n2.4.1 The consistency of the Continuum Hypothesis and the Axiom of Choice 2.4.2 Gödel’s Proof of the Consistency of the Continuum Hypothesis and the Axiom of Choice with the Axioms of Zermelo-Fraenkel Set Theory 2.4.3 Consequences of Consistency 2.4.4 Gödel’s view of the Axiom of Constructibility  \\n2.5.1 Intuitionistic Propositional Logic is not Finitely-Valued 2.5.2 Classical Arithmetic is Interpretable in Heyting Arithmetic 2.5.3 Intuitionistic Propositional Logic is Interpretable in S4 2.5.4 Heyting Arithmetic is Interpretable into Computable Functionals of Finite Type.  \\n3.1 Gödel’s Rationalism 3.2 Gödel’s Realism Supplementary Document: Gödel’s Turn to Phenomenology Supplementary Document: A Philosophical Argument About the Content of Mathematics  \\nPrimary Sources Secondary Sources  \\nGödel’s Writings The Collected Papers of Kurt Gödel Selected Works of Kurt Gödel  \\n1. Biographical Sketch 2. Gödel’s Mathematical Work 2.1 The Completeness Theorem 2.1.1 Introduction 2.1.2 Proof of the Completeness Theorem 2.1.3 An Important Consequence of the Completeness Theorem 2.2 The Incompleteness Theorems 2.2.1 The First Incompleteness Theorem 2.2.2 The proof of the First Incompleteness Theorem 2.2.3 The Second Incompleteness Theorem 2.3 Speed-up Theorems 2.4 Gödel’s Work in Set theory 2.4.1 The consistency of the Continuum Hypothesis and the Axiom of Choice 2.4.2 Gödel’s Proof of the Consistency of the Continuum Hypothesis and the Axiom of Choice with the Axioms of Zermelo-Fraenkel Set Theory 2.4.3 Consequences of Consistency 2.4.4 Gödel’s view of the Axiom of Constructibility 2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic 2.5.1 Intuitionistic Propositional Logic is not Finitely-Valued 2.5.2 Classical Arithmetic is Interpretable in Heyting Arithmetic 2.5.3 Intuitionistic Propositional Logic is Interpretable in S4 2.5.4 Heyting Arithmetic is Interpretable into Computable Functionals of Finite Type. 3. Gödel’s Philosophical Views 3.1 Gödel’s Rationalism 3.2 Gödel’s Realism', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='Kurt Gödel was born on April 28, 1906 in what was then the Austro-Hungarian city of Brünn, and what is now Brno in the Czech Republic.  \\nGödel’s father Rudolf August was a businessman, and his mother Marianne was a well-educated and cultured woman to whom Gödel remained close throughout his life, as witnessed by the long and wide-ranging correspondence between them. The family was well off, and Gödel’s childhood was an uneventful one, with one important exception; namely, from about the age of four Gödel suffered frequent episodes of poor health, and the health problems he suffered then as well as others of various kinds were to plague him his entire life.  \\nHealth problems notwithstanding, Gödel proved to be an exemplary student at primary school and later the Gymnasium, excelling especially in mathematics, languages and religion. Upon his graduation from the Gymnasium in Brno in 1924 Gödel enrolled in the University of Vienna, attending lectures on physics, his initial field of interest, lectures on philosophy given by Heinrich Gomperz, and lectures on mathematics. Gödel took a number of physics courses during his undergraduate years, as witnessed by his university transcript; this is notable in view of Gödel’s subsequent contributions to relativity in 1947. Philipp Furtwängler, cousin of the great German conductor Wilhelm Furtwängler, was one of his mathematics professors, and indeed Furtwängler’s course on class field theory almost tempted Gödel to pursue his studies in that area. Gödel learned his logic from Rudolph Carnap and from Hans Hahn, eventually graduating under Hahn with a Dr.phil. in mathematics in 1929. The main theorem of his dissertation was the completeness theorem for first order logic (Gödel 1929).[2]  \\nGödel’s university years also marked the beginning of his attendance at meetings of the Vienna Circle, a group around Moritz Schlick that quickly became known as “logical positivists,” a term coined by Feigl and Blumberg in their 1931 “Logical positivism: A new movement in European philosophy” (Feigl and Blumberg 1931). Though Gödel was not himself a logical positivist, those discussions were a crucial formative influence.  \\nThe 1930s were a prodigious decade for Gödel. After publishing his 1929 dissertation in 1930, he published his groundbreaking incompleteness theorems in 1931, on the basis of which he was granted his Habilitation in 1932 and a Privatdozentur at the University of Vienna in 1933.  \\nAmong his mathematical achievements at the decade’s close is the proof of the consistency of both the Axiom of Choice and Cantor’s Continuum Hypothesis with the Zermelo-Fraenkel axioms for set theory, obtained in 1935 and 1937, respectively. Gödel also published a number of significant papers on modal and intuitionistic logic and arithmetic during this period, principal among which is his “On intuitionistic arithmetic and number theory,” (Gödel 1933e), in which he showed that classical first order arithmetic is interpretable in Heyting arithmetic by a simple translation. Other publications of the 1930s include those on the decision problem for the predicate calculus, on the length of proofs, and on differential and projective geometry.  \\nBy the end of the decade both Gödel’s advisor Hans Hahn and Moritz Schlick had died (the latter was assassinated by an ex-student), two events which led to a personal crisis for Gödel. Also, his appointment at the University, that of Privatdozentur, was cancelled, being replaced by the position “Dozentur neuer Ordnung,” granted to candidates only after they had passed a racial test.[3] Gödel’s three trips the United States during that decade triggered an investigation. (See Sigmund 2006.) Finally, Gödel was found fit for military service by the Nazi government in 1939.  \\nAll of these events were decisive in influencing his decision to leave Austria in 1940, when he and his wife Adele emigrated to the United States. This long and difficult episode in their life is recounted by John Dawson in his biography of Gödel called “Logical Dilemmas,” (Dawson 1997) as well as by Solomon Feferman in “Gödel’s Life and Work,” (Feferman 1986) to both of which the reader is referred.  \\nUpon arrival Gödel took up an appointment as an ordinary member at the Institute for Advanced Study; he would become a permanent member of the Institute in 1946 and would be granted his professorship in 1953. (Gödel and his wife were granted American citizenship in April 1948.) He would remain at the Institute until his retirement in 1976. The Gödels never returned to Europe.  \\nGödel’s early years at the Institute were notable for his close friendship with his daily walking partner Albert Einstein, as well as for his turn to philosophy of mathematics, a field on which Gödel began to concentrate almost exclusively from about 1943. The initial period of his subsequent lifelong involvement with philosophy was a fruitful one (in terms of publications): in 1944 he published his first philosophical paper, entitled “On Russell’s Mathematical Logic” (Gödel 1944), and in 1947 he published his second, entitled “What is Cantor’s Continuum Hypothesis?” (Gödel 1947). In 1949 he published his third, entitled “A Remark on the Relationship between Relativity Theory and Idealistic Philosophy.” (Gödel 1949a). The latter paper coincided with results on rotating universes in relativity he had obtained in 1949, which were first published in an article entitled: “An Example of a New Type of Cosmological Solutions of Einstein’s Field Equations of Gravitation.” (Gödel 1949).  \\nAmong Gödel’s other significant philosophical works of the 1940s must be counted his 1941 lecture entitled “In What Sense is Intuitionistic Logic Constructive?” (Gödel *1941) in which the notion: “computable function of finite type” is introduced. A paper based on the ideas in the lecture entitled “Über eine bisher noch nicht benützte Erweiterung des finiten Standpunktes,” was published only in 1958, and the interpretation of Heyting arithmetic into the quantifier free calculus T in it became known as the “Dialectica Interpretation,” after the journal in which the article was published (Gödel 1958). (For the revision of it from 1972, see Gödel 1995.) Finally the decade saw the beginning of Gödel’s intensive study of Leibniz, which, Gödel reports, occupied the period from 1943 to 1946.[4]  \\nThe 1950s saw a deepening of Gödel’s involvement with philosophy: In 1951 Gödel delivered a philosophical lecture at Brown University, usually referred to as the Gibbs Lecture, entitled “Some Basic Theorems on the Foundations of Mathematics and Their Philosophical Implications” (Gödel *1951). From 1953 to 1959 Gödel worked on a submission to the Schilpp volume on Rudolf Carnap entitled “Is Mathematics a Syntax of Language?” (Gödel *1953/9-III, Gödel *1953/9-V). Gödel published neither of these two important manuscripts in his lifetime, although both would appear on two lists which were found in the Gödel Nachlass, entitled “Was ich publizieren könnte.” (In English: “What I could publish.” Both manuscripts eventually appeared in Gödel 1995.) By the decade’s close Gödel developed a serious interest in phenomenology.[5]  \\nGödel’s final years are notable for his circulation of two manuscripts: “Some considerations leading to the probable conclusion that the true power of the continuum is ℵ2,” (Gödel *1970a, *1970b) his attempt to derive the value of the continuum from the so-called scale axioms of Hausdorff, and his “Ontologischer Beweis,” (Gödel *1970) which he entrusted to Dana Scott in 1970 (though it appears to have been written earlier). Taken together, the two manuscripts are the fitting last words of someone who, in a fifty year involvement with mathematics and philosophy, pursued, or more precisely, sought the grounds for pursuing those two subjects under the single heading: “strenge Wissenschaft”—a turn of mind that had been in place from Gödel’s start in 1929, when at the age of twenty-three he opened his doctoral thesis with some philosophical remarks.  \\nGödel died in Princeton on January 14, 1978 at the age of 71. His death certificate records the cause of death as “starvation and inanition, due to personality disorder.” His wife Adele survived him by three years.  \\nFor further biographical material, see Gödel 1987, Kleene 1987, Kreisel 1980, Taussky-Todd 1987 and Yourgrau 2005.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='Below is an examination of some of Gödel’s main contributions in logic and set theory. This treatment of Gödel’s technical work is not exhaustive, omitting discussion of Gödel’s work in physics and his work on the decision problem. These will be treated in the sequel to this entry.  \\nFor a complete chronology of Gödel’s work the reader is referred to that compiled by John Dawson in volume I of Gödel’s Collected Works (Gödel 1986, p. 37).', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work'}),\n",
       " Document(page_content='The completeness question for the first order predicate calculus was stated precisely and in print for the first time in 1928 by Hilbert and Ackermann in their text Grundzüge der theoretischen Logik (Hilbert and Ackermann 1928), a text with which Gödel would have been quite familiar.[6]  \\nThe question Hilbert and Ackermann pose is whether a certain explicitly given axiom system for the first order predicate calculus “…is complete in the sense that from it all logical formulas that are correct for each domain of individuals can be derived…” (van Heijenoort 1967, p. 48).  \\nWe give an outline of Gödel’s own proof in his doctoral thesis (Gödel 1929). An essential difference with earlier efforts (discussed below and elsewhere, e.g. in Zach 1999), is that Gödel defines meticulously all the relevant basic concepts.  \\nA “logical expression” in Gödel’s terminology is a well-formed first order formula without identity. An expression is “refutable” if its negation is provable, “valid” if it is true in every interpretation and “satisfiable” if it is true in some interpretation. The Completeness Theorem is stated as follows:  \\nTheorem 1. Every valid logical expression is provable. Equivalently, every logical expression is either satisfiable or refutable.  \\nGödel’s proof calculus is that of Hilbert and Ackermann’s text. An expression is in normal form if all the quantifiers occur at the beginning. The degree of an expression or formula is the number of alternating blocks of quantifiers at the beginning of the formula, assumed to begin with universal quantifiers. Gödel shows that if the completeness theorem holds for formulas of degree k it must hold for formulas of degree k + 1. Thus the question of completeness reduces to formulas of degree 1. That is, it is to be shown that any normal formula (Q)φ of degree 1 is either satisfiable or refutable, where “(Q)” stands for a (non-empty) block of universal quantifiers followed by a (possibly empty) block of existential ones.  \\nGödel defines a book-keeping device, a well-ordering of all tuples of variables arising from a need to satisfy φ as dictated by (Q). For example, if (Q)φ is ∀x0∃x1ψ(x0, x1), we list the quantifier-free formulas ψ(xn, xn+1). (Or more precisely, finite conjunctions of these in increasing length. See below.) Then in any domain consisting of the values of the different xn, in which each ψ(xn, xn+1) is true, the sentence (Q)φ is clearly true. A crucial lemma claims the provability, for each k, of the formula (Q)φ → (Qk)φk, where the quantifier free formula φk asserts the truth of ψ for all tuples up to the kth tuple of variables arising from (Q), and (Qk)φk is the existential closure of φk. (See the example below where the definition of the φk′s is given.) This lemma is the main step missing from the various earlier attempts at the proof due to Löwenheim and Skolem, and, in the context of the completeness theorem for first order logic, renders the connection between syntax and semantics completely explicit.  \\nLet us consider an example of how a particular formula would be found to be either satisfiable or its negation provable, following Gödel’s method: Consider φ = ∀x0∃x1ψ(x0, x1), where ψ(x0, x1) is quantifier-free. We show that this is either refutable or satisfiable. We make the following definitions:  \\nφ0 is the expression ψ(x0, x1) φ1 is the expression ψ(x0, x1) ∧ ψ(x1, x2) … φn is the expression ψ(x0, x1) ∧ …∧ ψ(xn, xn+1).  \\nThe crucial lemma, referred to above, shows that from φ we can derive for each n, ∃x0…∃xn+1φn.  \\nCase 1: For some n, φn is not satisfiable. Then, Gödel argued, using the already known completeness theorem for propositional logic,[7] that ¬φn is provable, and hence so is ∀x0,…, xn+1¬φn. Thus ¬∃x0…∃xn+1φn is provable and therefore the ¬φ is provable, i.e., φ is refutable in the Hilbert-Ackermann system. (Some partial results about propositional logic in addition to those already mentioned include the semantic completeness of the propositional calculus due to Post (1921), as well as a more general completeness theorem for the same due to Bernays in 1918; the latter appears in Bernays’ unpublished Habilitationsschrift of 1918; see also Bernays 1926.)  \\nCase 2: Each φn is satisfiable. There are only finitely many possible models with universe {x0,…, xn+1}. Gödel orders them as a tree by defining a model M to be below a model M′ if M is a submodel of M′. In this way we obtain a tree which is finitely branching but infinite. By König’s Lemma there is an infinite branch B. (In the proof, Gödel explicitly constructs the branch given by König’s Lemma rather than citing it by name.) The union of the models on B forms a model M with universe {x0, x1,…}. Since M satisfies each φn, the original formula φ holds in M. So φ is satisfiable and we are done.  \\nNote that the model, in the satisfiability case of Gödel’s proof, is always countable. Thus this proof of the Completeness Theorem gives also the Löweheim-Skolem Theorem (see below). Gödel extends the result to countably many formulas and to the case of first order logic with identity. He also proves the independence of the axioms.  \\nIn 1930 Gödel published the paper based on his thesis (Gödel 1930) notable also for the inclusion of the compactness theorem, which is only implicitly stated in the thesis. The theorem as stated by Gödel in Gödel 1930 is as follows: a countably infinite set of quantificational formulas is satisfiable if and only if every finite subset of those formulas is satisfiable. Gödel uses compactness to derive a generalization of the completeness theorem.  \\nThe Compactness Theorem was extended to the case of uncountable vocabularies by Maltsev in 1936 (see Mal’cev 1971), from which the Upward Löwenheim-Skolem theorem immediately follows. The Compactness Theorem would become one of the main tools in the then fledgling subject of model theory.  \\nA theory is said to be categorical if it has only one model up to isomorphism; it is λ-categorical if it has only one model of cardinality λ, up to isomorphism. One of the main consequences of the completeness theorem is that categoricity fails for Peano arithmetic and for Zermelo-Fraenkel set theory.  \\nIn detail, regarding the first order Peano axioms (henceforth PA), the existence of non-standard models of them actually follows from completeness together with compactness. One constructs these models, which contain infinitely large integers, as follows: add a new constant symbol c to the language of arithmetic. Extend PA to a new theory PA* by adding to it the infinite collection of axioms: {c > 0, c > 1, …}, where, e.g., 3 is S(S(S(0))). PA* is finitely consistent (i.e., every finite subset of PA* is consistent) hence consistent, hence by the Completeness Theorem it has a model.  \\nThis simple fact about models of Peano arithmetic was not pointed out by Gödel in any of the publications connected with the Completeness Theorem from that time, and it seems not to have been noticed by the general logic community until much later. Skolem’s definable ultrapower construction from 1933 (see Skolem 1933) gives a direct construction of a non-standard model of True Arithmetic (which extends Peano arithmetic, being the set of arithmetic sentences true in the natural numbers). But Skolem never mentions the fact that the existence of such models follows from the completeness and compactness theorems. Gödel in his review (1934c) of Skolem’s paper also does not mention this fact, rather observing that the failure of categoricity for arithmetic follows from the incompleteness theorem.  \\nAs for set theory, the failure of categoricity was already taken note of by Skolem in 1923, because it follows from the Löwenheim-Skolem Theorem (which Skolem arrived at that year; see Skolem 1923, based on Löwenheim 1915 and Skolem 1920): any first order theory in a countable language that has a model has a countable model.  \\nSkolem’s observation that categoricity fails for set theory because it has countable models is now known as the Skolem paradox.[8]The observation is strongly emphasized in Skolem’s paper, which is accordingly entitled ‘An Observation on the Axiomatic Foundations of Set Theory’ As he wrote in the conclusion of it, he had not pointed out the relativity in set theory already in 1915 because:  \\n… first, I have in the meantime been occupied with other problems; second, I believed that it was so clear that axiomatization in terms of sets was not a satisfactory ultimate foundation of mathematics that mathematicians would, for the most part, not be very much concerned with it. But in recent times I have seen to my surprise that so many mathematicians think that these axioms of set theory provide the ideal foundation for mathematics; therefore it seemed to me that the time had come to publish a critique. (English translation taken from van Heijenoort 1967, p. 300.)  \\nAs an aside, in the proof of the Löwenheim-Skolem theorem, specifically that part of the theorem in which one constructs a model for a satisfiable sentence, Löwenheim and Skolem’s tree construction was more or less the same as appears in Gödel’s thesis. In a 1967 letter to Hao Wang, Gödel takes note of the fact that his completeness proof had almost been obtained by Skolem in 1923. Though van Heijenoort and Dreben (Dreben and van Heijenoort 1986) remark that “Throughout much of the 1920s it was not semantic completeness but the decision problem for quantificational validity, a problem originating from the work of Schröder and Löwenheim, that was the dominant concern in studying quantification theory” (examples of such results would include the decision procedure for the first order monadic predicate calculus due to Behmann, (Behmann 1922)), according to Gödel, the reasons that Skolem did not obtain the complete proof are different and philosophically important, having to do with the then dominant bias against semantics and against infinitary methods:  \\nThe Completeness Theorem, mathematically, is indeed an almost trivial consequence of Skolem 1923. However, the fact is that, at that time, nobody (including Skolem himself) drew this conclusion neither from Skolem 1923 nor, as I did, from similar considerations of his own …This blindness (or prejudice, or whatever you may call it) of logicians is indeed surprising. But I think the explanation is not hard to find. It lies in the widespread lack, at that time, of the required epistemological attitude toward metamathematics and toward non-finitary reasoning. (Gödel 2003b).  \\nThe matter of Skolem’s contribution to the Completeness Theorem has been extensively discussed in van Atten and Kennedy 2009, as well as in van Atten 2005.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='Gödel mentioned the possibility of the unsolvability of a question about the reals already in his 1929 thesis, in arguing against the formalist principle of Hilbert’s, that consistency is a criterion for existence. In fact, giving a finitary proof of the consistency of analysis was a key desideratum of what was then known as the Hilbert program, along with proving its completeness. Accordingly it was Gödel’s turn to these questions, especially the first, which led him to the two incompleteness theorems. (For a discussion of the Hilbert Program the reader is referred to the standard references: Sieg 1990, 1988, 1999; Mancosu 1998, Zach 2003, Tait 1981 and Tait 2002.)  \\nThe First Incompleteness Theorem provides a counterexample to completeness by exhibiting an arithmetic statement which is neither provable nor refutable in Peano arithmetic, though true in the standard model. The Second Incompleteness Theorem shows that the consistency of arithmetic cannot be proved in arithmetic itself. Thus Gödel’s theorems demonstrated the infeasibility of the Hilbert program, if it is to be characterized by those particular desiderata, consistency and completeness.  \\nAs an aside, von Neumann understood the two theorems this way, even before Gödel did. In fact von Neumann went much further in taking the view that they showed the infeasibility of classical mathematics altogether. As he wrote to Carnap in June of 1931:  \\nThus today I am of the opinion that 1. Gödel has shown the unrealizability of Hilbert’s program. 2. There is no more reason to reject intuitionism (if one disregards the aesthetic issue, which in practice will also for me be the decisive factor). Therefore I consider the state of the foundational discussion in Königsberg to be outdated, for Gödel’s fundamental discoveries have brought the question to a completely different level.[9]  \\nAnd the previous fall von Neumann had written to Gödel in even stronger terms:  \\nThus, I think that your result has solved negatively the foundational question: there is no rigorous justification for classical mathematics. (Gödel 2003b, p. 339)  \\nIt would take Gödel himself a few years to see that those aspects of the Hilbert Program had been decisively refuted by his results (Mancosu 2004).  \\nIn his Logical Journey (Wang 1996) Hao Wang published the full text of material Gödel had written (at Wang’s request) about his discovery of the incompleteness theorems. This material had formed the basis of Wang’s “Some Facts about Kurt Gödel,” and was read and approved by Gödel:  \\nIn the summer of 1930 I began to study the consistency problem of classical analysis. It is mysterious why Hilbert wanted to prove directly the consistency of analysis by finitary methods. I saw two distinguishable problems: to prove the consistency of number theory by finitary number theory and to prove the consistency of analysis by number theory … Since the domain of finitary number theory was not well-defined, I began by tackling the second half… I represented real numbers by predicates in number theory… and found that I had to use the concept of truth (for number theory) to verify the axioms of analysis. By an enumeration of symbols, sentences and proofs within the given system, I quickly discovered that the concept of arithmetic truth cannot be defined in arithmetic. If it were possible to define truth in the system itself, we would have something like the liar paradox, showing the system to be inconsistent… Note that this argument can be formalized to show the existence of undecidable propositions without giving any individual instances. (If there were no undecidable propositions, all (and only) true propositions would be provable within the system. But then we would have a contradiction.)… In contrast to truth, provability in a given formal system is an explicit combinatorial property of certain sentences of the system, which is formally specifiable by suitable elementary means…  \\nWe see that Gödel first tried to reduce the consistency problem for analysis to that of arithmetic. This seemed to require a truth definition for arithmetic, which in turn led to paradoxes, such as the Liar paradox (“This sentence is false”) and Berry’s paradox (“The least number not defined by an expression consisting of just fourteen English words”). Gödel then noticed that such paradoxes would not necessarily arise if truth were replaced by provability. But this means that arithmetic truth and arithmetic provability are not co-extensive — whence the First Incompleteness Theorem.  \\nThis account of Gödel’s discovery was told to Hao Wang very much after the fact; but in Gödel’s contemporary correspondence with Bernays and Zermelo, essentially the same description of his path to the theorems is given. (See Gödel 2003a and Gödel 2003b respectively.) From those accounts we see that the undefinability of truth in arithmetic, a result credited to Tarski, was likely obtained in some form by Gödel by 1931. But he neither publicized nor published the result; the biases logicians had expressed at the time concerning the notion of truth, biases which came vehemently to the fore when Tarski announced his results on the undefinability of truth in formal systems 1935, may have served as a deterrent to Gödel’s publication of that theorem.  \\nWe now describe the proof of the two theorems, formulating Gödel’s results in Peano arithmetic. Gödel himself used a system related to that defined in Principia Mathematica, but containing Peano arithmetic. In our presentation of the First and Second Incompleteness Theorems we refer to Peano arithmetic as P, following Gödel’s notation.  \\nBefore proceeding to the details of the formal proof, we define the notion of ω-consistency used by Gödel in the First Incompleteness Theorem: P is ω-consistent if P ⊢ ¬φ(n) for all n implies P ⊬ ∃xφ(x). Naturally this implies consistency and follows from the assumption that the natural numbers satisfy the axioms of Peano arithmetic.  \\nOne of the main technical tools used in the proof is Gödel numbering, a mechanism which assigns natural numbers to terms and formulas of our formal theory P. There are different ways of doing this. The most common is based on the unique representation of natural numbers as products of powers of primes. Each symbol s of number theory is assigned a positive natural number #(s) in a fixed but arbitrary way, e.g.  \\n#(0) = 1 #(=) = 5 #(¬) = 9 #(1) = 2 #(\\u2009(\\u2009) = 6 #(∀) = 10 #(+) = 3 #(\\u2009)\\u2009) = 7 #(vi) = 11 + i #(×) = 4 #(∧) = 8 \\xa0  \\nThe natural number corresponding to a sequence w = < w0,…, wk > of symbols is  \\n⌈w⌉ = 2#(w0) · 3#(w1) · … · pk#(wk),  \\nwhere pk is the k+1st prime. It is called its Gödel number and denoted by ⌈w⌉. In this way we can assign Gödel numbers to formulas, sequences of formulas (once a method for distinguishing when one formula ends and another begins has been adopted), and most notably, proofs.  \\nAn essential point here is that when a formula is construed as a natural number, then the numeral corresponding to that natural number can occur as the argument of a formula, thus enabling the syntax to “refer” to itself, so to speak (i.e., when a numeral is substituted into a formula the Gödel number of which the numeral represents). This will eventually allow Gödel to formalize the Liar paradox (with “provability” in place of “truth”) by substituting into the formula which says, ‘the formula, whose code is x, is unprovable,’ its own natural number code (or more precisely the corresponding numeral).  \\nAnother concept required to carry out the formalization is the concept of numeralwise expressibility of number theoretic predicates. A number-theoretic formula φ(n1, …, nk) is numeralwise expressible in P if for each tuple of natural numbers (n1, …, nk):  \\nN ⊨ φ(n1, …, nk) ⇒ P ⊢ φ(n1, …, nk) N ⊨ ¬φ(n1, …, nk) ⇒ P ⊢ ¬φ(n1, …, nk)  \\nwhere n is the formal term which denotes the natural number n. (In P, this is S(S(…S(0)…), where n is the number of iterations of the successor function applied to the constant symbol 0.) One of the principal goals is to numeralwise express the predicate  \\nPrf(x, y): ‘the sequence with Gödel number x is a proof of the sentence with Gödel number y.’  \\nReaching this goal involves defining forty-five relations, each defined in terms of the preceding ones. These relations are all primitive recursive.[10] Relations needed are, among others, those which assert of a natural number that it codes a sequence, or a formula, or an axiom, or that it is the code, denoted by Sb(ru1…unZ(x1)…Z(xn)), of a formula obtained from a formula with code r by substituting for its free variable ui the xi th numeral for i = 1, …, n. The forty-fifth primitive recursive relation defined is Prf(x, y), and the forty-sixth is  \\nProv(y): ‘the sentence with Gödel number y is provable in P’  \\nwhich without being primitive recursive, is however obtained from Prf(x, y) by existentially quantifying x. (Prov(y) satisfies only the ‘positive’ part of numeralwise expressibility, and not the negative part; but the negative part is not needed.)  \\nIn Theorem V of his paper, Gödel proves that any number theoretic predicate which is primitive recursive is numeralwise expressible in P. Thus since Prf(x, y) and substitution are primitive recursive, these are decided by P when closed terms are substituted for the free variables x and y. This is the heart of the matter as we will see. Another key point about numeralwise expressibility is that although we informally interpret, for example, Prov(Sb(ru1…unZ(x1)…Z(xn))), by: ‘the formula with Gödel number r is provable if the Gödel number for the xi th numeral is substituted in place of the i th variable,’ neither the formal statement within the theory P nor anything we prove about it appeals to such meanings. On the contrary Prov(Sb(ru1…unZ(x1)…Z(xn))), is a meaningless string of logical and arithmetical symbols. As Gödel puts it in his introduction to his theorem V, ‘The fact that can be formulated vaguely by saying that every recursive relation is definable in the system P (if the usual meaning is given to the formulas of this system) is expressed in precise language, without reference to any interpretation of the formulas of P, by the following Theorem (V) (Gödel 1986, p. 171, italics Gödel’s).  \\nGödel in his incompleteness theorems uses a method given in what is called nowadays Gödel’s Fixed Point Theorem. Although Gödel constructs a fixed point in the course of proving the incompleteness theorem, he does not state the fixed point theorem explicitly. The fixed point theorem is as follows:  \\nTheorem 2 (Gödel’s Fixed Point Theorem) If φ(v0) is a formula of number theory, then there is a sentence ψ such that P ⊢ ψ ↔ φ(⌈ψ⌉), where ⌈ψ⌉ is the formal term corresponding to the natural number code of ⌈ψ⌉.  \\nProof: Let σ(x,y,z) be a formula that numeralwise expresses the number theoretic predicate ‘y is the Gödel number of the formula obtained by replacing the variable v0 in the formula whose Gödel number is x by the term z’. Let θ(v0) be the formula ∃v1(φ(v1) ∧ σ(v0, v1, v0)). Let k = ⌈θ(v0)⌉ and ψ = θ(k). Now directly by the construction P ⊢ ψ ↔ φ(⌈ψ⌉).  \\nA sentence is refutable from a theory if its negation is provable. The First Incompleteness Theorem as Gödel stated it is as follows:  \\nTheorem 3 (Gödel’s First Incompleteness Theorem) If P is ω-consistent, then there is a sentence which is neither provable nor refutable from P.  \\nProof: By judicious coding of syntax referred to above, write a formula Prf(x,y)[11] of number theory, representable in P, so that  \\nn codes a proof of φ ⇒ P ⊢ Prf(n, ⌈φ⌉).  \\nand  \\nn does not code a proof of φ ⇒ P ⊢ ¬Prf(n, ⌈φ⌉).  \\nLet Prov(y) denote the formula ∃x Prf(x,y)[12]. By Theorem 2 there is a sentence φ with the property  \\nP ⊢ (φ ↔ ¬Prov(⌈φ⌉)).  \\nThus φ says ‘I am not provable.’ We now observe, if P ⊢ φ, then by (1) there is n such that P ⊢ Prf(n, ⌈φ⌉), hence P ⊢ Prov(⌈φ⌉), hence, by (3) P ⊢ ¬φ, so P is inconsistent. Thus  \\nP ⊬ φ  \\nFurthermore, by (4) and (2), we have P ⊢ ¬Prf(n, ⌈φ⌉) for all natural numbers n. By ω-consistency P ⊬ ∃x Prf(x, ⌈φ⌉). Thus (3) gives P ⊬ ¬φ. We have shown that if P is ω-consistent, then φ is independent of P.  \\nOn concluding the proof of the first theorem, Gödel remarks, “we can readily see that the proof just given is constructive; that is … proved in an intuitionistically unobjectionable manner…” (Gödel 1986, p. 177). This is because, as he points out, all the existential statements are based on his theorem V (giving the numeralwise expressibility of primitive recursive relations), which is intuitionistically unobjectionable.  \\nThe Second Incompleteness Theorem establishes the unprovability, in number theory, of the consistency of number theory. First we have to write down a number-theoretic formula that expresses the consistency of the axioms. This is surprisingly simple. We just let Con(P) be the sentence ¬Prov(⌈0 = 1⌉).  \\nTheorem 4 (Gödel’s Second Incompleteness Theorem) If P is consistent, then Con(P) is not provable from P.  \\nProof: Let φ be as in (3). The reasoning used to infer ‘if P ⊢ φ, then P ⊢ 0 ≠ 1‘ does not go beyond elementary number theory, and can therefore, albeit with a lot of effort (see below), be formalized in P. This yields: P ⊢ (Prov(⌈φ⌉) → ¬Con(P)), and thus by (3), P ⊢ (Con(P) → φ). Since P ⊬ φ, we must have P ⊬ Con(P).  \\nThe above proof (sketch) of the Second Incompleteness Theorem is deceptively simple as it avoids the formalization. A rigorous proof would have to establish the proof of ‘if P ⊢ φ, then P ⊢ 0 ≠ 1’ in P.  \\nIt is noteworthy that ω-consistency is not needed in the proof of Gödel’s Second Incompleteness Theorem. Also note that neither is ¬Con(P) provable, by the consistency of P and the fact, now known as Löb’s theorem, that P ⊢ Prov(⌈φ⌉) implies P ⊢ φ.  \\nThe assumption of ω-consistency in the First Incompleteness Theorem was eliminated by Rosser in 1936, and replaced by the weaker notion of consistency. Rosser’s generalization involves applying the fixed point theorem to the formula R(x): ‘for all z: either z is not the Gödel number of a proof of the formula with Gödel number x or there is a proof shorter than z of the negation of (the formula with Gödel number) x’ (see Rosser 1936).  \\nWith regard to the Second Incompleteness Theorem, the argument relies in part on formalizing the proof of the First Incompleteness Theorem as we saw. This step is omitted in Gödel 1931. He planned to include the step in what would have been a second part II (see footnote 48a of Gödel 1931). But instead of writing it he turned to the continuum problem.[13] (Part II was to elaborate on other points too: the ‘true reason for incompleteness,’ and the applicability of the two theorems to other systems.) He perhaps did not feel compelled to attend to what looked like an exercise in formalization, relying instead on the informal argument to convince (in which it succeeded). However this step turned out to be somewhat non-trivial. As Kleene puts it in his introduction to Gödel 1931, of the informal presentation, “Certainly the idea of the argument for Theorem XI (consistency) was very convincing; but it turned out that the execution of the details required somewhat more work and care than had been anticipated.” (See pp. 126–141 of Gödel 1986.) Eventually a complete proof of the Second Theorem was given by Hilbert and Bernays in some seventy pages in their Hilbert and Bernays 1939. A much more compact treatment of the theorem was given by Löb in his Löb 1956, and subsequently Feferman, in his 1960 “Arithmetization of Metamathematics in a General Setting” (Feferman 1960/1961), gave a succinct and completely general treatment of both the First and Second Theorems. But see the supplementary document:  \\nDid the Incompleteness Theorems Refute Hilbert’s Program?  \\nFor more detailed discussion, see the entry on Gödel’s incompleteness theorems.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Gödel’s 1936 ‘Speed-up’ theorem, published in an abstract “On the length of proofs”, Gödel 1936 says that while some sentences of arithmetic are true but unprovable, there are other sentences which are provable, but even the shortest proof is longer than any bound given in advance as a recursive function of the sentence. More exactly:  \\nTheorem 5. Given any recursive function f there are provable sentences φ of arithmetic such that the shortest proof is greater than f(⌈φ⌉) in length.  \\nThe proof we will outline is sensitive to the particular concept we use for the length of a proof. Another possibility, and the one that Gödel has in mind, is the number of formulas in the proof. Buss (see below) proves the theorem in either case, so both cases are resolved.  \\nProof: Let f be total recursive function. By Gödel’s Fixed Point theorem there is a formula φ(n) stating ‘φ(n) has no proof in PA shorter than f(n)’. This is tenable if the length is measured by number of symbols, because we only need to search through finitely many proofs shorter than f(n). Note that φ(n) is true for all n, for if φ(n) were false, then there would be a short proof of φ(n), and hence by soundness φ(n) would be true, a contradiction: φ(n) would both true and false. This can be formalized in PA and thus we get the result that for each n the sentence φ(n) is provable in PA. Since φ(n) is true for all n, it cannot have a proof in PA which is shorter than f(n).  \\nThe Speed-up Theorem is the result of contemplating and elaborating the proof of the incompleteness theorem. It applies the fixed-point technique to the concept of unprovability by a short proof, as opposed to the original idea of applying the fixed-point theorem to mere unprovability. The proof has very much the same flavor as the proof of the incompleteness theorem. Interestingly, it dates from the same year as the construction, due to Rosser, that eliminates the use of ω-consistency in the first Incompleteness Theorem; like the Speed-up Theorem of Gödel, Rosser’s construction exploits the issue of short and long proofs. Gödel never submitted a proof for the Speed-up Theorem. Over the years several related proofs were published, but the first full proof of Gödel’s original result was given only in 1994 by Sam Buss in his ‘On Gödel’s theorems on lengths of proofs I: Number of lines and speedups for arithmetic.’ (Buss 1994). Buss also gives a second proof of the theorem which avoids self-reference, following a technique due to Statman. Gödel measures the length of proofs by the number of formulas; but there are also other possibilities, such as the number of symbols in the proof. The case of the Speed-up Theorem where the length of proof is measured by the number of symbols was proved by Mostowski in 1952 (Mostowski 1982). For proofs of similar results see Ehrenfeucht and Mycieleski 1971, and Parikh 1971. Though both measures may be equally natural candidates for measuring the length of a proof, proving the theorem for length measured by the number of symbols avoids a technical complication introduced by the other measure: there are only finitely many proofs with a given number of symbols, whereas there are infinitely many proofs with a given number of formulas.  \\nGödel states the Speed-up Theorem differently from the above. Let Sn be the system of logic of the n-th order, the variables of the first level being thought of as ranging over natural numbers. In this setting, variables of the second level range over sets of natural numbers and so on. Gödel’s formulation is:  \\nTheorem 6. Let n be a natural number > 0. If f is a computable function, then there are infinitely many formulas A, provable in Sn, such that if k is the length of the shortest proof of A in Sn and l is the length of the shortest proof of A in Sn+1, then k > f(l).  \\nProof sketch: The idea is the following: Let φ(x) be a formula, like above, for which φ(m) does not have a short proof in Sn for any m. Suppose we have a higher type system Sn+1 in which we can prove ∀xφ(x). This proof is of constant length. Thus each φ(m) is derivable from this universal statement by one application of the logical rule ∀xφ(x) → φ(t). Thus φ(m) has in that system for all m a short proof.  \\nWhat kind of stronger system can we have in which ∀xφ(x) is provable? We may consider second order logic in which we can define a predicate N(x) for the set of natural numbers and furthermore can prove of a new predicate symbol Tr(x) that it satisfies the inductive clauses of the truth definition of first order formulas of arithmetic, relativized to N. Then the stronger system can prove that provable first order sentences of arithmetic satisfy the predicate Tr . By the above argument, we can prove in the stronger system that ∀xφ(x) satisfies Tr. Then by adding a few lines we can prove each φ(n) satisfies Tr. Because of the nature of φ(n), this implies the stronger system has a (short) proof of φ(n). An alternative system is Peano’s axioms PA in an extended language where we have a new predicate symbol Tr and axioms stating that the predicate Tr codes the satisfaction relation for all sentences of the vocabulary not containing Tr.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='Gödel’s proof of the consistency of the continuum hypothesis with the axioms of Zermelo-Fraenkel set theory is a tour de force and arguably the greatest achievement of his mathematical life. This is because aside from the arithmetization, virtually all of the technical machinery used in the proof had to be invented ab initio.  \\nThe Continuum Hypothesis (henceforth CH) was formulated by Georg Cantor, and was the first problem on Hilbert’s list of twenty-three unsolved problems as given in his famous address to the International Mathematical Congress in Paris in 1900. The problem as stated by Hilbert is as follows: Let A be an infinite set of real numbers. Then A is either countable, or has cardinality 2ℵ0, i.e., A is in one-to-one correspondence either with the set of natural numbers or with the set of all real numbers (otherwise known as the continuum). Another way to state the continuum hypothesis is that (the first uncountably infinite cardinal) ℵ1 = 2ℵ0.  \\nAs early as 1922 Skolem speculated that the CH was independent of the axioms for set theory given by Zermelo in 1908. Nevertheless Hilbert published a (false) proof of the CH in Hilbert 1926. In 1937 Gödel proved its consistency with the axioms of ZF set theory. (Henceforth we use the standard abbreviations for Zermelo-Fraenkel set theory, ZF, and Zermelo-Fraenkel set theory with the Axiom of Choice, ZFC.) The consistency of the negation of the CH was shown by Paul Cohen in 1961 (see Cohen 1963) and hence together with Gödel’s result one infers that the CH is independent of ZF (and ZFC).  \\nCohen invented an important new technique called forcing in the course of proving his result; this technique is at present the main method used to construct models of set theory. Forcing led to a revival of formalism among set theorists, the plurality of models being an indication of the “essential variability in set theory,” (Dehornoy 2004) and away from the notion that there is an intended model of set theory—a perspective Gödel advocated since at least 1947, if not earlier.[14] Recently there have been signs that the CH may again be coming to be regarded as a problem to be solved mathematically (with the help of course of some new evident axioms extending ZF). (See for example Woodin 2001a, 2002, 2001b, and Foreman 1998.) If any of the proposed solutions gain acceptance, this would confirm Gödel’s view that the CH would eventually be decided by finding an evident extension of the ZF axioms for set theory. The program associated with this view is called “Gödel’s Large Cardinal Program.”  \\nThe continuum problem is shown to be consistent with ZF by finding an enumeration of the reals which is indexed by the countable ordinals, a strategy which had been recognized as a promising one already by Hilbert.[15] The problem, and the intuition behind the proof, is to build a “small” model, one in which the absolute minimum number of reals is allowed, while at the same time the model is large enough to be closed under all the operations the ZF axioms assert to exist.  \\nGödel’s is a relative consistency proof, obtained by constructing a so-called “inner model” for ZF together with the CH. An inner model is a subcollection M of the collection V of all sets (see below) which satisfies the axioms of ZF when only sets in M are considered. Gödel’s inner model is called the inner model of constructible sets (see below) and is denoted by L. Whatever is true in an inner model is consistent with ZF for the same reason that any theory with a model is consistent. An artifact of the construction is that the Axiom of Choice (henceforth AC) is satisfied in Gödel’s inner model and hence the consistency of the AC with ZF was established by Gödel. Later on it was shown by Sierpinski that the AC is actually a consequence of the Generalized Continuum Hypothesis or the GCH, which states that for each κ, 2κ = κ+ (see Sierpinski 1947).  \\nGödel published two versions of these theorems, in 1939 and in 1940, entitled “Consistency Proof for the Generalized Continuum Hypothesis,” and “The Consistency of the Axiom of Choice and of the Generalized Continuum Hypothesis with the Axioms of Set Theory,” respectively. Though completely definitive, the 1939 version is lacking in a great many details, most notably the arguments showing that if L is built inside L itself, the same L results; that is to say, the so-called absoluteness arguments are missing. Also missing are the details of the proofs that the ZF axioms hold in L. Unlike the case of the Second Incompleteness Theorem, however, Gödel subsequently gave a completely detailed proof of the two theorems in the 1940 monograph. (The 1940 proof differs substantially from the first version. For details about the two proofs and the difference between them the reader is referred to Solovay 1990 and Kanamori 2006.)  \\nWe now sketch the proof of the consistency of CH and of AC with ZFC, using modern terminology. Some preliminary concepts before sketching the proof: We first define the stratified set theoretic universe, denoted V. (V is also known as the cumulative hierarchy.) It is obtained by iteration of the power set operation (℘) beginning with the null set:  \\nV0 = ∅, Vα+1 = ℘(Vα), Vγ = ∪β<γ Vβ,  \\nwhere α, β are any ordinals, γ is a limit ordinal and ℘(x) denotes the power set of x. Finally  \\nV = ∪α∈Ord Vα,  \\nwhere Ord denotes the class of all ordinals.  \\nThe constructible hierarchy L is likewise defined by recursion on ordinals. But whereas the full power set operation is iterated to obtain the cumulative hierarchy, the levels of the constructible hierarchy are defined strictly predicatively, that is by including at the next level only those sets which are first order definable using parameters from the previous level. More exactly, let Def(A) denote the set of all subsets of A definable in the structure < A, ∈ > by first order formulas with parameters in A. (For more on definability see the entry on model theory in this encyclopedia.)  \\nWith this notation the constructible hierarchy is defined by induction over the ordinals as follows:  \\nL0 = ∅, Lα+1 = Def(Lα), Lγ = ∪α<γ Lα, L = ∪α∈Ord Lα,  \\nA set x is said to be constructible if x ∈ L. The axiom which states that all sets are constructible is denoted V = L and is called the Axiom of Constructibility. Note that L is a proper class and not a set; although as we will see, each Lα is a set, and the predicate “x is constructible” is actually a definable term of the language.  \\nOur next task is to show that L is a model of ZF. A set or a class is transitive if elements of it are also subsets. By a meticulous transfinite induction, Lα can be shown to be transitive for each α; and therefore so is L itself. This fact, together with the observation that some elementary closure properties hold in L [16] is enough to show that L is a model of ZF. (Indeed, as it turns out, L is the minimal transitive model of the ZF axioms containing all the ordinals, and is therefore in this sense canonical.)  \\nIn detail, proving that the ZF axioms, apart from the comprehension axiom, are true in L, amounts to showing that, roughly speaking, any set with a property P that a ZF axiom asserts to exist, can be seen to exist in L by considering the relativization PL of the property P to L. (A property P is relativized to an inner model M by replacing every quantifier ∃xφ by ∃x(x ∈ M ∧ φ) and every quantifier ∀xφ by ∀x(x ∈ M→ φ).) As for the comprehension axiom, verifying it requires showing that the set asserted to exist is constructed at a particular successor level Lα + 1. Proving this requires an important principle of set theory which in modern terminology is called the Levy (or ZF) Reflection Principle. This principle says that any statement in the language of ZF which is true in V is already true on some level of any continuously increasing hierarchy such as L. (For the history of this principle, see Kanamori 2006.) The Levy Reflection Principle gives the level α at which the elements of the set are all constructed. Gödel did not actually have the Levy Reflection Principle but used the argument behind the proof of the principle.  \\nOnce it is established that L is a model of ZF, one can now prove that both the CH and the AC hold in L. To this end, one first shows that the definition of L is absolute for L, where absoluteness is defined as follows: given a class M, a predicate P(x) is said to be absolute for M if and only if for all x ∈ M, P(x) ↔ PM(x).  \\nProving that the predicate “x is constructible” is absolute requires formalizing the notion of definability, which in turn requires formalizing the notion of satisfaction. This is because the predicate “x is constructible” says of a set, that for some ordinal α, and for some formula φ with parameters in Lα, x = {y ∈ Lα | Lα ⊨ φ(y)}. This part of the proof is tedious but unproblematic.  \\nOnce the absoluteness of L is established, it follows that ZF satisfies the axiom of constructibility if it is relativized to L; that is, ZF ⊢ (V=L)L. In particular, the axiom V = L is consistent if ZF is.  \\nWe now give the idea of the proof of CH and AC in ZF + V = L. (For a detailed exposition of the proof, the reader is referred to the standard sources. See for example Devlin’s chapter on constructibility in Barwise 1977; see also Kunen 1983, and Jech 2003.)  \\nAs concerns the CH, the idea behind the proof of it in L is simply the following: Gödel showed that assuming V = L, every real number occurs on some countable level of the L-hierarchy. Since every countable level is itself countable (after all, there are only countably many possible defining formulas), and there are ω1 countable levels, there must be only ω1 real numbers.  \\nThe difficulty here, if not of the whole proof altogether, lies in showing that every real is constructed already on a countable level of the L-hierarchy. To show this Gödel argued as follows: Suppose A is a real number thought of as a set of natural numbers. By a combination of the Levy Reflection principle and the Löwenheim-Skolem Theorem there is a countable submodel < M, ∈ > of < L, ∈ > satisfying a sufficiently large finite part of the ZF axioms + V = L, such that A belongs to M. By a simple procedure < M, ∈ > can be converted into a transitive model < N, ∈ >. This procedure, used by Gödel already in 1937, was explicitly isolated by Mostowski (Mostowski 1949). The resulting model is referred to as the Mostowski Collapse.  \\nLet us pause to discuss this important technique. Suppose < M, E> is a well-founded model of the axiom of extensionality. It is a consequence of the well-foundedness of the binary predicate E on M, and of the principle of transfinite recursion, that the equation π(x) = {π(y)\\u2009|\\u2009y ∈ M ∧ yEx} defines a unique function on M. The range N of π is transitive, for if π(a) ∈ N and y ∈ π(a), then y = π(b) for some b ∈ M with bEa, whence π(b) ∈ N. The fact that π is an isomorphism between < M, E> and < N, ∈ > can be proved by transfinite induction on elements on M, based again on the well-foundedness of E. The well-foundedness of < M, E> is in practice often the consequence of < M, E> being a submodel of some < Vα, ε >.  \\nWe now return to the proof of the CH in L. We used the Mostowski Collapse to construct the transitive set N. As it turns out, the real number A is still an element of < N, ∈ > . By basic properties of L, < N, ∈ > must be < Lα , ∈ > for some α . Since N is countable, α is countable too. (It can be shown that |Lα| = |α| + ℵ0.) Thus A is constructible on a countable level, which was to have been shown.  \\nAs for the AC, Gödel exhibits a definable well-ordering, that is, a formula of set theory which defines, in L, a well-ordering of all of L. The formula is tedious to write down but the idea is a simple one: A set x precedes a set y in the well-ordering if and only if either x occurs in the L-hierarchy on an earlier level Lα than y, or else they occur on the same level but x is defined by a shorter formula than y, or else they are defined by the same formula but the parameters in the definition of x occur in L earlier than the parameters of y. This well-ordering of L shows that the AC holds in L.  \\nThis concludes the proof of the consistency of AC and the CH in L.  \\nWe note that Gödel proved more in his 1939 and 1940 than what was shown here, namely he proved the Generalized Continuum Hypothesis in L and hence that its consistency with ZF.  \\nAs noted above, it was suggested already in the 1920s that the CH might be independent of ZF or ZFC. After first conjecturing that the Axiom of Constructibility might be “absolutely consistent,” meaning not falsifiable by any further extension of models of ZF + V = L,[17] in his 1947 “What is Cantor’s Continuum Hypothesis?” Gödel conjectured that the CH would be shown to be independent. The main consequence of Gödel’s result, then, as far as the problem of proving the independence of the CH is concerned, was that it pointed mathematicians in the direction of adding non-constructible sets to a model of set theory in order to establish the consistency of the negation of the CH. In 1961 Dana Scott proved that the failure of the Axiom of Constructibility follows from the existence of a measurable cardinal, contrary to a conjecture Gödel had made in 1940. (See Scott 1961. A cardinal κ is said to be measurable if there is a non-principal κ-complete ultrafilter in the power-set Boolean algebra of κ.) In 1963, as noted, Paul Cohen proved the consistency of the negation of the CH by adding non-constructible sets to an inner model.  \\nWhat other open questions of set theory could be solved by Gödel’s method? Gödel himself noted some consequences. They are related to so called projective sets of real numbers and finite sequences of real numbers. The simplest projective sets are the closed sets, also called Π10-sets. A set is Σ1n+1 if it is the projection of a Π1n-subset of the real plane. A set is Δ1n+1 if it and its complement are Σ1n+1. Gödel observed that there is both a non-Lebesgue measurable Δ12-set and an uncountable Π11-set without a perfect subset in L. (A set of reals is perfect if it is closed, non-empty, and has no isolated points. Such sets have the size of the continuum.) Gödel gave a sketch of the proof in the 1951 second printing of Gödel 1940.  \\nIt has turned out subsequently that the axiom V = L gives a virtually complete extension of ZFC. This means that, apart from sentences arising from Gödel’s incompleteness theorems, essentially all set-theoretical questions can be decided by means of the axioms V = L. This is not to imply that such results are in any way trivial. Indeed, it has turned out that L is quite a complicated structure, despite its relatively simple description. As for settling open set-theoretical questions in L, the main step was the emergence of Jensen’s fine structure theory of L (Jensen 1972). Recalling that the successor step Lα +1 in the definition of the constructible hierarchy adds to L all subsets of Lα definable by first order formulas φ over (Lα, ∈), fine structure theory, roughly speaking, ramifies the step from Lα to Lα+1 into smaller steps according to the complexity of the defining formula φ. Jensen established by means of his fine structure a strengthening, denoted by ◊, of CH, that he used to construct a Souslin tree in L, and a combinatorial principle □ that he used to show that the Souslin Hypothesis is consistent with CH.  \\nIf he did not think this way from the outset, Gödel soon came to adopt the view that the Axiom of Constructibility was implausible. As he remarked at the end of his 1947 “What is Cantor’s Continuum Hypothesis?”  \\n…it is very suspicious that, as against the numerous plausible propositions which imply the negation of the continuum hypothesis, not one plausible proposition is known which would imply the continuum hypothesis. (Gödel 1990, p. 186)  \\nGödel was compelled to this view of L by the Leibnizian[18] idea that, rather than the universe being “small,” that is, one with the minimum number of sets, it is more natural to think of the set theoretic universe as being as large as possible.[19]This idea would be reflected in his interest in maximality principles, i.e., principles which are meant to capture the intuitive idea that the universe of set theory is maximal in the sense that nothing can be added; and in his conviction that maximality principles would eventually settle statements like the CH. As Gödel put it in a letter to Ulam in the late 1950s, about a maximality principle of von Neumann:  \\nThe great interest which this axiom has lies in the fact that it is a maximality principle, somewhat similar to Hilbert’s axiom of completeness in geometry. For, roughly speaking, it says that any set which does not, in a certain well defined way, imply an inconsistency exists. Its being a maximum principle also explains the fact that this axiom implies the axiom of choice. I believe that the basic problems of set theory, such as Cantor’s continuum problem, will be solved satisfactorily only with the help of stronger axioms of this kind, which in a sense are opposite or complimentary to the constructivistic interpretation of mathematics. (Ulam 1958, as quoted in Gödel 1990, p. 168; original emphasis. Note that this is different from the very similar passage Gödel 2003b, p.295.)  \\nTwenty years earlier, in 1938, Gödel had written seemingly differently about the Axiom of Constructibility:  \\nThe proposition A (i.e., V = L) added as a new axiom seems to give a natural completion of the axioms of set theory, in so far as it determines the vague notion of an arbitrary infinite set in a definite way. (Gödel 1986, p.27)  \\nGödel may have meant by “natural completion” here “the correct completion,” or he may have meant to say no more than that the Axiom of Constructibility determines the notion of set in a definite way. In any case he used the term “natural” differently in a conversation with Wang on constructibility in 1972 (Wang 1996, p. 144):  \\nGödel talked more about the relation between axioms of infinity and the constructible universe…(he observed that) preliminary concepts such as that of constructible sets are necessary to arrive at the natural concept, such as that of set.  \\nThis is reminiscent of a remark of Hugh Woodin, that studying forcing leads to a better understanding of V — the general principle being that studying the models of a theory is not only useful to understand the theory itself, but useful to obtain a better picture of V (Woodin 1988).  \\nFor more on Gödel’s program and on Gödel’s program relative to the CH the reader is referred e.g., to Steel forthcoming and Feferman et al. 2000. For more on Gödel’s result, its history , and its significance the reader is referred to Floyd/Kanamori 2006 and Kennedy 2006.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='Gödel’s interest in intuitionism was deep and long-lasting. Although he himself did not subscribe to that view, he made a number of important contributions to intuitionistic logic. Perhaps the importance he placed on the concept of evidence (see below) led to his close consideration of it.  \\nWe discuss Gödel’s results on intuitionistic logic in their chronological order.  \\nBoth many-valued logic, introduced by Łukasiewicz in the twenties (Łukasiewicz 1970) and intuitionistic logic, formalized by Heyting in 1930, fail to satisfy the law of excluded middle. It was therefore natural to ask whether intuitionistic logic can be presented as a many-valued logic, and indeed a number of logicians in the 1920s had suggested just that. In his 1932 Gödel gave a simple argument which shows that intuitionistic propositional logic cannot be thought of as a finitely-valued logic. Precisely, Gödel proved two theorems:  \\nTheorem 7. There is no realization with finitely many elements (truth values) for which the formulas provable in H, and only those, are satisfied (that is, yield designated values for an arbitrary assignment).  \\n(H is intuitionistic propositional logic, after Heyting.)  \\nTheorem 8. Infinitely many systems lie between H and the system A of the ordinary propositional calculus, that is, there is a monotonically decreasing sequence of systems all of which include H as a subset and are included in A as subsets.  \\nIn his proof he considered for each natural number n > 0 the sentence  \\nFn = ∨1 ≤ i < j ≤ n pi ≡ pj.  \\nHe observed that in an n-valued logic the sentences Fm, for m > n, should be derivable. However, Gödel showed, Fn is not derivable from Heyting’s axioms for any n.  \\nSubsequently Jaśkowski (Jaśkowski 1936) showed that intuitionistic propositional logic can be given a many-valued semantics in terms of infinitely many truth-values. For further discussion of many-valued logics, see for example the entry on many-valued logic in this encyclopedia as well as van Stigt’s article on intuitionistic logic in Mancosu 1998.  \\nWe now consider Gödel 1933e, in which Gödel showed, in effect, that intuitionistic or Heyting arithmetic is only apparently weaker than classical first-order arithmetic. This is because the latter can be interpreted within the former by means of a simple translation, and thus to be convinced of the consistency of classical arithmetic, it is enough to be convinced of the consistency of Heyting arithmetic. Heyting arithmetic is defined to be the same as classical arithmetic, except that the underlying predicate logic is given by intuitionistic axioms and rules of inference (see below).  \\nThis result extends the same assertion for the propositional case. Let H denote the intuitionistic propositional logic, and A denote its classical counterpart (as above). Inductively define:  \\nA′ ≡ ¬¬A (A atomic) (¬A)′ ≡ ¬A′ (A → B)′ ≡ ¬(A′ ∧ ¬B′) (A ∨ B)′ ≡ ¬(¬A′ ∧ ¬B′) (A ∧ B)′ ≡ A′ ∧ B′  \\nThen,  \\nTheorem 9. Let F be a propositional formula. Then H ⊢ F if and only if A ⊢ F′,  \\nThe theorem follows easily from the result of Glivenko (1929) that ¬F follows from H if and only if ¬F follows from A, for any propositional formula F.  \\nGödel’s so-called double negation interpretation extends Theorem 9 to a reduction of classical first order logic to intuitionistic predicate logic. The translation in this case can be taken to map A′ to A for atomic A. Moreover, we let ∀xA(x)′ = ∀xA′(x) :  \\nTheorem 10. Suppose A is a first order formula. If A is provable in classical first order logic, then A′ is provable in intuitionistic first order logic.  \\nThe above result had been obtained independently by Gentzen (with Bernays), but upon hearing of Gödel’s result Gentzen withdrew his paper from publication. It had also been anticipated by Kolmogorov in his 1925 “On the Principle of the Excluded Middle,” (English translation van Heijenoort 1967) but that paper was largely unknown to logicians who were outside of Kolmogorov’s circle.  \\nBernays has written (see Bernays’ entry on David Hilbert in Edwards 1967) that this result of Gödel’s drew the attention of the Hilbert school to two observations: first, that intuitionistic logic goes beyond finitism, and secondly, that finitist systems may not be the only acceptable ones from the foundational point of view.  \\nThe following theorem for the case of arithmetic follows from Theorem 10:  \\nTheorem 11. Suppose A is a first order formula of arithmetic. If A is provable in classical Peano arithmetic, then A′ is provable in intuitionistic first order arithmetic.  \\nFor a list of the axioms and rules of intuitionistic first order logic see Gödel 1958, reprinted with detailed introductory note by A.S. Troelstra in Gödel 1990. See also Troelstra 1973, and Troelstra’s “Aspects of constructive mathematics” in Barwise 1977. For a detailed proof of the above theorem the reader is referred also to the latter.  \\nThis result of Gödel’s (Gödel 1933f), which marks the beginning of provability logic, makes exact the difference between the concept of “provability in a specified formal system” and that of “provability by any correct means.”  \\nGödel had already noted this difference in the introduction to his 1929 thesis. The context was the following: Gödel entertains there the possibility that his proof of the Completeness Theorem might be circular, since the law of excluded middle was used to prove it. This is because while the Completeness Theorem asserts ‘a kind of decidability,’ namely every quantificational formula is either provable or a counterexample to it can be given, ‘the principle of the excluded middle seems to express nothing other than the decidability of every problem’:  \\n… what is affirmed (by the law of excluded middle) is the solvability not at all through specified means but only through all means that are in any way imaginable … [20]  \\nGödel considers intuitionistic propositional logic (henceforth IPL); he also considers a second system, classical propositional logic enriched by an operator “B”, where the intended meaning of “B” is “provable.” The axiom system now known as S4 (for a list of these axioms see for example the entry on modal logic in this encyclopedia) is added to the standard axioms for classical propositional logic together with a new rule of proof: from A, BA may be inferred. Let us call this second system G. Gödel’s theorem states that IPL is interpretable in G via the following translation:  \\n¬p ≡ ~Bp p ⊃ q ≡ Bp → Bq p ∨ q ≡ Bp ∨ Bq p ∧ q ≡ Bp ∧ Bq  \\nThat is,  \\nTheorem 12. Let A be a formula of IPL, and let A′ be its translation. Then IPL ⊢ A implies G ⊢ A′.  \\nGödel conjectures that the converse implication must be true, and indeed this was shown in McKinsey and Tarski 1948.  \\nThe difference between the two notions of provability: “provable in a given formal system S” and provability by any correct means — manifests itself as a consequence of Gödel’s Second Incompleteness Theorem, as follows. Let S contain Peano arithmetic, and let the operator B be interpreted as “provable in S”. If the axioms of S4 were valid for this interpretations of B, then from B(0 ≠ 1) → (0 ≠ 1), the sentence ¬B(0 ≠ 1) would be provable, contradicting the Second Incompleteness Theorem.  \\nFor further discussion of Gödel’s theorem, its antecedents and its extensions, as well as its philosophical significance, the reader is referred to A.S Troelstra’s introduction to 1933f.  \\nGödel’s so-called Dialectica intepretation (Gödel 1958) delivers a relative consistency proof and justification for Heyting arithmetic by means of a concrete interpretation involving a system T of computable functionals of finite type. Taken together with his 1933e, which reduces classical first order arithmetic to Heyting arithmetic, a justification in these terms is also obtained for classical first order arithmetic.  \\nGödel’s inductive definition of the notion “function of finite type” is as follows: (Gödel 1990, p. 245).  \\nThe functionals of type 0 are the natural numbers. If t0,…, tk are types and we have already defined what functionals of types t0,…,tk are, then (t0,…, tk) is a type and a functional of that type assigns to every k-tuple of functionals of respective types t1,…, tk, a functional of type t0.  \\nGödel considers the quantifier free theory of these functionals of finite type, denoted by T. T has the following features: the language of T contains variables of each type, constants for distinguished types, and a ternary predicate =σ for equality for type σ. Equality between terms of the same type is decidable. The non-logical axioms and rules for T include the classical arithmetic axioms for 0 and successor, and the induction rule:  \\n(F(0) ∧ (F(x0) → F(S(x0)))) → F(x0)  \\nfor quantifier-free formulas F(x0). As Gödel remarks (Gödel 1990, p. 247), the axioms for T are essentially those of primitive recursive arithmetic, except that the variables can be of any finite type.  \\nGödel’s translation associates with every formula F(x) of the language of Peano arithmetic a formula F′(x) = ∃y∀zA(y, z, x) of the language of the theory T, where A is quantifier free and the (boldface) bound variables are finite sequences of variables thought to range over functionals of a finite type determined by the type of the variable. Intuitively, y is a concrete analogue of the abstract notion of a construction constituting the meaning of F.  \\nGödel’s theorem is as follows:  \\nTheorem 13. Suppose F′ = ∃y∀zA(y, z, x). If F is provable in intuitionistic first order arithmetic, then there are computable functionals Q of finite type such that A(Q(x), z, x) is provable in T.  \\nThe proof is by induction on the structure of the proof of F in intuitionistic first order arithmetic. (For a treatment of the proof in detail, the reader is referred to Troelstra 1986.)  \\nThe importance of the theorem for foundations cannot be overstated.[21] A discussion of its generalizations, of ensuing work on functional interpretations stimulated by the theorem due to Kreisel, Tait, Howard, Feferman and others; its foundational and philosophical significance; and finally its relation particularly to the earlier, informal, proof interpretation, so-called, given by Heyting-Kolmogorov, will not be attempted here. Accordingly the reader is referred to the large literature on the subject, e.g., the abovementioned Troelstra 1986, Tait 1967, Feferman 1993 and Avigad & Feferman 1998. For interesting recent developments, e.g., in the area of relating Gödel’s Dialectica interpretation and Kreisel’s modified realizability, see Oliva 2006. See also van Oosten 2008.  \\nA remark concerning the philosophical context in which Gödel presented his translation, namely finitism. The question addressed in the introduction to the paper is what abstract notions must be added to finitary mathematics in order to obtain a consistency proof for arithmetic. Equivalently: what does the finitary view presuppose, which must be given up in the light of the Second Incompleteness Theorem, if the consistency proof is to be obtained:  \\nIn any case Bernays’ remark teaches us to distinguish two components of the finitary attitude; namely, first, the constructive element, which consists in our being allowed to speak of mathematical objects only insofar as we can exhibit them or actually produce them by means of a construction; second, the specifically finitistic element, which makes the further demand that the objects about which we make statements, with which the constructions are carried out and which we obtain by means of these constructions, are ‘intuitive’, that is, are in the last analysis spatiotemporal arrangements of elements whose characteristics other than their identity or nonidentity are irrelevant.… It is the second requirement that must be dropped. This fact has hitherto been taken into account by our adjoining to finitary mathematics parts of intuitionistic logic and the theory of ordinals. In what follows we shall show that, for the consistency proof of number theory, we can use, instead, the notion of computable function of finite type on the natural numbers and certain rather elementary principles of construction for such functions. (Gödel 1990, p.245).  \\nAside from its technical contribution, then, Gödel’s 1958/72 is one of Gödel’s most important philosophical works; notable for its analysis of the nature of finitary mathematics, as well as its analysis of the notions of “intuitive,” as in “intuitive knowledge,” and that of abstract versus concrete evidence.  \\nIn the next section, we turn to Gödel’s philosophical views. But interested readers may wish to read a brief discussion about Gödel’s Nachlass, important source of philosophical material by Gödel:  \\nSupplement Document: Gödel’s Documents', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='Gödel’s philosophical views can be broadly characterized by two points of focus, or, in modern parlance, commitments. These are: realism, namely the belief that mathematics is a descriptive science in the way that the empirical sciences are. The second commitment is to a form of Leibnizian rationalism in philosophy; and in fact Gödel’s principal philosophical influences, in this regard particularly but also many others, were Leibniz, Kant and Husserl. (For further discussion of how these philosophers influenced Gödel, see van Atten and Kennedy 2003.)  \\nThe terms “Gödel’s realism” and “Gödel’s rationalism” must be prefaced with a disclaimer: there is no single view one could associate with each of these terms. Gödel’s realism underwent a complex development over time, in both the nature of its ontological claims as well as in Gödel’s level of commitment to those claims. Similarly Gödel’s rationalism underwent a complex development over time, from a tentative version of it at the beginning, to what was adjudged to be a fairly strong version of it in the 1950s. Around 1959 and for some time afterward Gödel fused his rationalistic program of developing exact philosophy with the phenomenological method as developed by Husserl.  \\nWe examine these two strains of Gödel’s thinking below:', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '3. Gödel’s Philosophical Views'}),\n",
       " Document(page_content='Gödel’s rationalism has its roots in the Leibnizian thought that the world, not that which we immanently experience but that which itself gives rise to immanent experience, is perfect and beautiful, and therefore rational and ordered. Gödel’s justification of this belief rests partly on an inductive generalization from the perfection and beauty of mathematics:  \\nRationalism is connected with Platonism because it is directed to the conceptual aspect rather than toward the (real) world. One uses inductive evidence…Mathematics has a form of perfection…We may expect that the conceptual world is perfect, and, furthermore, that objective reality is beautiful, good, and perfect. (Wang 1996, 9.4.18)  \\nOur total reality and total experience are beautiful and meaningful—this is also a Leibnizian thought. We should judge reality by the little which we truly know of it. Since that part which conceptually we know fully turns out to be so beautiful, the real world of which we know so little should also be beautiful. (9.4.20)  \\nAlthough the roots of Gödel’s belief in rationalism are metaphysical in nature, his long-standing aspirations in that domain had always been practical ones. Namely, to develop exact methods in philosophy; to transform it into an exact science, or strenge Wissenschaft, to use Husserl’s term.  \\nWhat this means in practice is taking the strictest view possible of what constitutes the dialectical grounds for the acceptance of an assertion; put another way, a level of rigor is aspired to in philosophical arguments approaching that which is found in mathematical proofs. A formulation of the view—one which is somewhat phenomenologically colored (see below)—can be found in a document in the Gödel Nachlass. This is a fourteen item list Gödel drew up in about 1960, entitled “My Philosophical Viewpoint.” Two items on the list are relevant here:  \\nThere are systematic methods for the solution of all problems (also art, etc.).  \\nThere is a scientific (exact) philosophy and theology, which deals with concepts of the highest abstractness; and this is also most highly fruitful for science.  \\n(The list was transcribed by Cheryl Dawson and was published in Wang 1996, p. 316.)  \\nGödel’s earlier conception of rationalism refers to mathematical rigor and includes the concept of having a genuine proof, and is therefore in some sense a more radical one than that to which he would later subscribe. One can see it at work at the end of the Gibbs lecture, after a sequence of arguments in favor of realism are given:  \\nOf course I do not claim that the foregoing considerations amount to a real proof of this view about the nature of mathematics. The most I could assert would be to have disproved the nominalistic view, which considers mathematics to consist solely in syntactical conventions and their consequences. Moreover, I have adduced some strong arguments against the more general view that mathematics is our own creation. There are, however, other alternatives to Platonism, in particular psychologism and Aristotelian realism. In order to establish Platonic realism, these theories would have to be disproved one after the other, and then it would have to be shown that they exhaust all possibilities. I am not in a position to do this now; however I would like to give some indications along these lines. (Gödel 1995, p. 321–2).  \\n(For a penetrating analysis of this passage see Tait 2001.) Such an analysis must be based on conceptual analysis:  \\nI am under the impression that after sufficient clarification of the concepts in question it will be possible to conduct these discussions with mathematical rigour and that the result will then be…that the Platonistic view is the only one tenable. (Gödel 1995, p. 322).  \\nAlong with the methodological component, as can be seen from the items on Gödel’s list, there was also an “optimistic” component to Gödel’s rationalism: once the appropriate methods have been developed, philosophical problems such as, for example, those in ethics (e.g., item 9 on the list is: “Formal rights comprise a real science.”) can be decisively solved. As for mathematical assertions, such as the Continuum Hypothesis in set theory, once conceptual analysis has been carried out in the right way, that is, once the basic concepts, such as that of “set,” have been completely clarified, the Continuum Hypothesis should be able to be decided.  \\nAlthough at the time of the Gibbs lecture the analogy in Gödel’s mind between philosophical and mathematical reasoning may have been a very close one, Gödel’s view at other periods was that the envisaged methods will not be mathematical in nature. What was wanted was a general, informal science of conceptual analysis.  \\nPhilosophy is more general than science. Already the theory of concepts is more general than mathematics…True philosophy is precise but not specialized.  \\nPerhaps the reason why no progress is made in mathematics (and there are so many unsolved problems), is that one confines oneself to the ext[ensional]—thence also the feeling of disappointment in the case of many theories, e.g., propositional logic and formalisation altogether. (Wang 1996, 9.3.20, 9.3.21)[22]  \\n(See notebook Max IV, p. 198 (Gödel Nachlaß, Firestone Library, Princeton, item 030090). Transcription Cheryl Dawson; translation from the German ours; amendment ours. Gödel’s dating of Max IV indicates that it is from May 1941 to April 1942. See also Gödel’s letter to Bernays, Gödel 2003a, p. 283.)  \\nAn important source for understanding Gödel’s advance toward a general theory of concepts are Gödel’s remarks on conceptual analysis published by Hao Wang in Logical Journey. In remark 8.6.10 for example, Gödel expresses the belief that extensionality fails for concepts, contrary to what he said in his 1944 “Russell’s Mathematical Logic,” a remark which he now wishes to retract:  \\nI do not (no longer) believe that generally sameness of range is sufficient to exclude the distinctness of two concepts.  \\nIn some of Gödel’s later discussions another component of conceptual analysis emerges, namely the project of finding the so-called primitive terms or concepts, and their relations. These are roughly terms or concepts which comprise a theoretical “starting point,” on the basis of their meaning being completely definite and clear. For example, the concept of “the application of a concept to another concept” is a primitive term, along with “force”. (Wang 1996, 9.1.29).  \\nHe spoke to Wang about the general project in 1972:  \\nPhenomenology is not the only approach. Another approach is to find a list of the main categories (e.g., causation, substance, action) and their interrelations, which, however, are to be arrived at phenomenologically. The task must be done in the right manner. (Wang 1996, 5.3.7).  \\nGödel spoke with Sue Toledo between 1972 and 1975 about the project of finding primitive terms, as well as other aspects of phenomenology. See Toledo 2011. We discuss Gödel’s involvement with phenomenology further in the supplementary document Gödel’s Turn to Phenomenology.  \\nThe judgement levied upon Gödel’s rationalism by contemporary philosophers was a harsh one. (See for example Gödel 1995, pp. 303–4). Nevertheless Gödel himself remained optimistic. As he commented to Wang:  \\nIt is not appropriate to say that philosophy as rigorous science is not realizable in the foreseeable future. Time is not the main factor; it can happen anytime when the right idea appears. (Wang 1996, 4.3.14).  \\nGödel concluded his 1944 on a similarly optimistic note.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '3. Gödel’s Philosophical Views', 'Header 3': '3.1 Gödel’s Rationalism'}),\n",
       " Document(page_content='Gödel’s realist views were formulated mostly in the context of the foundations of mathematics and set theory.  \\nWe referred above the list “What I believe,” thought to have been written in 1960 or thereabouts. Out of 14 items, only two refer to realism, remarks 10 and 12:  \\nMaterialism is false.  \\nConcepts have an objective existence.  \\nGödel published his views on realism for the first time in his 1944. The following is one of his most quoted passages on the subject:  \\nClasses and concepts may, however, also be conceived as real objects, namely classes as “pluralities of things,” or as structures consisting of a plurality of things and concepts as the properties and relations of things existing independently of our definitions and constructions.  \\nIt seems to me that the assumption of such objects is quite as legitimate as the assumption of physical bodies and there is quite as much reason to believe in their existence. They are in the same sense necessary to obtain a satisfactory system of mathematics as physical bodies are necessary for a satisfactory theory of our sense perceptions and in both cases it is impossible to interpret the propositions one wants to assert about these entities as propositions about the “data,” i.e., in the latter case the actually occurring sense perceptions.  \\nGödel’s reference to the impossibility of interpreting empirical laws, or more precisely, instantiations of them—the statements “one wants to assert,”—as statements about sense perceptions, is likely an endorsement of the (then) contemporary critique of phenomenalism. The critique was based on the observation that sense data are so inextricably bound up with the conditions under which they are experienced, that no correspondence between statements about those and the statements “we want to assert” can be given (see Chisholm 1948 for example). More generally Gödel was against verificationism, namely the idea that the meaning of a statement is its mode of verification.  \\nThe analogical point in the first part of the passage was amplified by Gödel in the draft manuscript “Is Mathematics a Syntax of Language?”:  \\nIt is arbitrary to consider “This is red” an immediate datum, but not so to consider the proposition expressing modus ponens or complete induction (or perhaps some simpler propositions from which the latter follows). (Gödel 1995, p. 359)  \\nSome writers have interpreted Gödel in this and similar passages pragmatically, attributing to him the view that because empirical statements are paradigmatic of successful reference, reference in the case of abstract concepts should be modelled causally. (See Maddy 1990.) Interpreting reference to abstract objects this way, it is argued, addresses the main difficulty associated with realism, the problem how we can come to have knowledge of abstract objects. Others have argued that Gödel had no paradigm case in mind; that for him both the empirical and the abstract case are either equally problematic, or equally unproblematic. (See Tait 1986.) The latter view is referred to as epistemological parity in van Atten and Kennedy 2003. (See also Kennedy and van Atten 2004.)  \\nIn his 1947 “What is Cantor’s Continuum Problem?”, Gödel expounds the view that in the case of meaningful propositions of mathematics, there is always a fact of the matter to be decided in a yes or no fashion. This is a direct consequence of realism, for if there exists a domain of mathematical objects or concepts, then any meaningful proposition concerning them must be either true or false.[23] The Continuum Hypothesis is Gödel’s example of a meaningful question. The concept “how many” leads “unambiguously” to a definite meaning of the hypothesis, and therefore it should be decidable—at least in principle. Most strikingly Gödel does not leave the matter there but goes on to offer a practical strategy for determining the value of the continuum, as well as the truth value of other axioms extending ZFC. Specifically, he offers two criteria for their decidability: the first involves conceptual analysis and is associated with Gödel’s rationalistic program. (See the above section on Gödel’s rationalism.) Secondly one must keep an eye on the so-called success of the axiom, as a check or indicator of which direction to look to for the solution of its truth. For example, Gödel notes in the paper that none of the consequences of the Axiom of Constructibility are very plausible. It is, then, likely false. See Maddy 2011 and Koellner 2014 for discussion of intrinsic vs extrinsic justifications for new axioms of set theory.  \\nFor further discussion of Gödel’s philosophical views see the supplementary documents:  \\nGödel’s Turn to Phenomenology  \\nand  \\nA Philosophical Argument About the Content of Mathematics', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '3. Gödel’s Philosophical Views', 'Header 3': '3.2 Gödel’s Realism'}),\n",
       " Document(page_content='Bibliography Primary Sources Gödel’s Writings The Collected Papers of Kurt Gödel Selected Works of Kurt Gödel [1929] “I”, Dissertation, University of Vienna. Reprinted in Gödel 1986, pp. 60–101. [1930] “Die Vollständigkeit der Axiome des logischen Funktionenkalküls”, Monatshefte für Mathematik und Physik, 37: 349–360. Reprinted in Gödel 1986, pp. 102–123. [1931] “Über formal unentscheidbare Sätze der Principia Mathematica und verwandter Systeme, I”, Monatshefte für Mathematik und Physik, 38: 173–198. Reprinted in Gödel 1986, pp. 144–195. [1932] “Zum intuitionistischen Aussagenkalkül”, Anzeiger der Akademie der Wissenschaften in Wien, 69: 65–66. Reprinted in Gödel 1986, pp. 222–225. [1933e] “Zur intuitionistischen Arithmetik und Zahlentheorie”, Ergebnisse eines mathematischen Kolloquiums, 4: 34–38. Reprinted in Gödel 1986, pp. 286–295. [1933f] “Eine Interpretation des intuitionistischen Aussagenkalküls”, Ergebnisse eines mathematischen Kolloquiums 4, 39–40. Reprinted in Gödel 1986, pp. 300–301. [1933i] “Zum Entscheidungsproblem des logischen Functionenkalküls”, Monatshefte für Mathematik und Physik, 40: 433–443. Reprinted in Gödel 1986, pp. 306–326. [*1933o] “The present situation in the foundations of mathematics”, manuscript. Printed in Gödel 1995, pp. 45–53. [1934c] Review of Skolem (1933). Zentralblatt für Mathematik und ihre Grenzgebiete, 7: 193–194. Reprinted in Gödel 1986, pp. 379–380. [1936a] “Über die Länge von Beweisen”, Ergebnisse eines mathematischen Kolloquiums, 7: 23–24. Reprinted in Gödel 1986, pp. 395–399. [1939a] “Consistency proof for the generalized continuum hypothesis”, Proceedings of the National Academy of Sciences, U.S.A., 25: 220–224. Reprinted in Gödel 1990, pp. 28–32. [1940] “The Consistency of the Continuum Hypothesis”, Annals of Mathematics Studies, Volume 3, Princeton: Princeton University Press. Reprinted in Gödel 1990, pp. 33–101. [*1941] “In what sense is intuitionistic logic constructive?”, lecture manuscript. Printed in Gödel 1995, pp. 189–200. [1944] “Russell’s mathematical logic”, The Philosophy of Bertrand Russell (Library of Living Philosophers), P. Schilpp (ed.), New York: Tudor, 1951, pp. 123–153. Reprinted in Gödel 1990, pp. 119–141. [*1946/9-B2] “Some observations about the relationship between theory of relativity and Kantian philosophy”, manuscript. Printed in Gödel 1995, pp. 230–246. [*1946/9-C1] “Some observations about the relationship between theory of relativity and Kantian philosophy”, manuscript. Printed in Gödel 1995, pp. 247–259. [1947] “What is Cantor’s continuum problem?”, Amer. Math. Monthly, 54: 515–525. Reprinted in Gödel 1990, pp. 176–187. [1949a] “A remark on the relationship between relativity theory and idealistic philosophy”, Albert Einstein: Philosopher-Scientist (Library of Living Philosophers), P. Schilpp (ed.), La Salle, IL: Open Court, 1949, pp. 555–562. Reprinted in Gödel 1990, pp. 202–207. [1949] “An Example of a New Type of Cosmological Solutions of Einstein’s Field Equations of Gravitation,” Reviews of Modern Physics, 21: 447–450. Reprinted in Gödel 1990, pp. 190–198. [*1951] “Some basic theorems on the foundations of mathematics and their implications”, lecture manuscript. Printed in Gödel 1995, pp. 304–323. [*1953/9-III] “Is mathematics a syntax of language?”, lecture manuscript. Printed in Gödel 1995, pp. 334–356. [*1953/9-V] “Is mathematics a syntax of language?,” lecture manuscript. Printed in Gödel 1995, pp. 356–362. [1958] “Über eine bisher noch nicht benützte Erweiterung des finiten Standpunktes”, Dialectica, 12: 280–287. Reprinted in Gödel 1990, pp. 240–251. [*1961/?] “The modern development of the foundations of mathematics in light of philosophy”, manuscript. Printed in Gödel 1995, pp. 374–387. [1964] “What is Cantor’s continuum problem?”, revised version of Gödel 1947, in Benacerraf, P. and Putnam, H. (eds.), 1983, Philosophy of mathematics: selected readings (2nd ed.), Cambridge: Cambridge University Press. Reprinted in Gödel 1990, pp. 254–270. [*1970] “Ontological proof”, manuscript. Printed in Gödel 1995, pp. 403–404. [*1970a] “Some considerations leading to the probable conclusion that the true power of the continuum is ℵ2”, manuscript. Printed in Gödel 1995, pp. 420–422. [*1970b] “A proof of Cantor’s continuum hypothesis from a highly plausible axioms about orders of growth”, manuscript. Printed in Gödel 1995, pp. 422–423. Secondary Sources', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='The Gödel Nachlass is located at Firestone Library of Princeton University with the exception of Gödel’s preprint collection, which is housed at the library of the Institute for Advanced Study. The Nachlass itself is the property of the Institute but a microfilm copy of it may be purchased from Brill. All of Gödel’s published work, together with a large number of the unpublished material from the Nachlass, together with a selection of Gödel’s correspondence is published in Kurt Gödel, Collected Works, Volumes I-V.  \\n1986, Collected Works. I: Publications 1929–1936. S. Feferman, S. Kleene, G. Moore, R. Solovay, and J. van Heijenoort (eds.), Oxford: Oxford University Press. 1990, Collected Works. II: Publications 1938–1974. S. Feferman, J. Dawson, S. Kleene, G. Moore, R. Solovay, and J. van Heijenoort (eds.), Oxford: Oxford University Press. 1995, Collected Works. III: Unpublished essays and lectures. S. Feferman, J. Dawson, S. Kleene, G. Moore, R. Solovay, and J. van Heijenoort (eds.), Oxford: Oxford University Press. 2003a, Collected Works. IV: Correspondence A-G. S. Feferman, J. Dawson, S. Kleene, G. Moore, R. Solovay, and J. van Heijenoort (eds.), Oxford: Oxford University Press. 2003b, Collected Works. V: Correspondence H-Z. S. Feferman, J. Dawson, S. Kleene, G. Moore, R. Solovay, and J. van Heijenoort (eds.), Oxford: Oxford University Press.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': 'Bibliography', 'Header 3': 'Primary Sources'}),\n",
       " Document(page_content='Avigad, J. and S. Feferman, 1998, “Gödel’s Functional (‘Dialectica’) Interpretation”, in Handbook of Proof Theory (Studies in Logic and the Foundations of Mathematics, Volume 137), Samuel Buss (ed.), Amsterdam: North-Holland, pp. 337-405. Awodey, S. and A. W. Carus, 2010, “Gödel and Carnap”, in Kurt Gödel: Essays for his Centennial, Solomon Feferman, Charles Parsons & Stephen G. Simpson (eds.), Cambridge: Cambridge University Press. Baaz, M., and C. Papadimitriou, D.Scott, H. Putnam, and C. Harper (eds.), 2011, Kurt Gödel and the Foundations of Mathematics: Horizons of Truth, Cambridge: Cambridge University Press. Badesa, C., and P. Mancosu, and R. Zach, 2009, “The Development of Mathematical Logic from Russell to Tarski, 1900–1935”, in Leila Haaparanta (ed.), The History of Modern Logic. New York and Oxford: Oxford University Press:318–470.. Barwise, Jon (ed.), 1977, Handbook of Mathematical Logic (Studies in Logic and the Foundations of Mathematics, Volume 90), Amsterdam: North-Holland Publishing Co. Behmann, Heinrich, 1922, “Beiträge, Algebra, Logik, insbesodere zum Entscheidungsproblem”, Mathematische Annalen, 86: 419–432. Benacerraf, P. and H. Putnam (eds.), 1983, Philosophy of Mathematics: Selected Readings, Cambridge: Cambridge University Press, 2nd edition. Bernays, Paul, 1926, “Axiomatische Untersuchung des Aussagen-Kalkuls der ‘Principia Mathematica’”, Mathematisches Zeitschrift, 25(1): 305–320. Bezboruah, A., and J.C. Sheperdson, 1976, “Gödel’s second incompleteness theorem for \\\\(Q\\\\)”, Journal of Symbolic Logic, 41 (2): 503–512. Bolzano, Bernard, 1969, Wissenschaftslehre, Sections 349–391, in Bernard Bolzano — Gesamtausgabe, Reihe I/Band 13, edited and with an introduction by Jan Berg, Stuttgart-Bad Cannstatt: Frommann Holzboog. Burgess, John, 2009, “”Intuitions of Three Kinds in Gödel’s Views on the Continuum“”, in Interpreting GödelKennedy, J. (ed.) Cambridge: Cambridge University Press, 2014. Buss, Samuel R., 1994, “On Gödel’s Theorems on Lengths of Proofs. I. Number of Lines and Speedup for Arithmetics”, Journal of Symbolic Logic, 59(3): 737–756. Chisholm, R., 1948, “The Problem of Empiricism”, The Journal of Philosophy, 45: 512–7. Cohen, Paul, 1963, “The Independence of the Continuum Hypothesis”, Proceedings of the National Academy of Sciences of the U.S.A., 50: 1143–1148. Crocco, G., 2003, “Gödel, Carnap and the Fregean Heritage”, History and Philosophy of Logic, 27: 171–191. –––, 2006, “Gödel on Concepts”, Synthese, 137(1,2): 21–41. Dawson, Jr., John W., 1997, Logical dilemmas: The Life and Work of Kurt Gödel, Wellesley, MA: A. K. Peters, Ltd. Dehornoy, Patrick, 2004, “Progrès récents sur l’hypothèse du continu (d’après Woodin)”, Astérisque, 294: viii, 147–172. Detlefsen, Michael, 1986, Hilbert’s Program: An essay on mathematical instrumentalism, Dordrecht: D. Reidel. –––, 2001, “What Does Gödel’s Second theorem Say?”, Philosophia Mathemathica, 9(1): 37–71. –––, 2014, “Completeness and the Ends of Axiomatization”, in Interpreting Gödel, Kennedy, J. (ed.) Cambridge: Cambridge University Press, 2014. Dreben, B. and J. van Heijenoort, 1986, “Introductory Note to 1929, 1930 and 1930a”, in Gödel 1986, pp. 44–59. Edwards, Paul (ed.), 1967, The Encyclopedia of Philosophy, New York: MacMillan. Ehrenfeucht, A. and J. Mycielski, 1971, “Abbreviating Proofs by Adding New Axioms”, Bulletin of the American Mathematical Society, 77: 366–367. Feferman, Solomon, 1960/1961, “Arithmetization of Metamathematics in a General Setting”, Fundamenta Mathematicae, 49: 35–92. –––, 1993, “Gödel’s Dialectica Interpretation and Its Two-way Stretch”, in Computational Logic and Proof Theory (Lecture Notes in Computer Science, Volume 713), G. Gottlob, A. Leitsch, and D. Mundici (eds.), Berlin: Springer, pp. 23–40. –––, 1986, “Gödel’s Life and Work”, in Gödel 1986, pp. 1–34. –––, 1988, “Hilbert’s Program Relativized: Proof-Theoretical and Foundational Reductions”, Journal of Symbolic Logic, 53: 364–384. –––, 1996, “Proof Theory”, in The Encyclopedia of Philosophy Supplement, D. Borchrt (ed.), New York: MacMillan, pp. 466–469. Feferman, S., and H. Friedman, P. Maddy, and J. Steel, 2000, “Does Mathematics Need New Axioms?”, Bulletin of Symbolic Logic, 6(4): 401–446. Feferman, S., C. Parsons, and S. Simpson (eds.), 2010, Kurt Gödel: Essays for his Centennial (Lecture Notes in Logic, 33), Cambridge: Cambridge University Press. Feigl, H. and A. Blumberg, 1931, “Logical Positivism. A New Movement in European Philosophy”, Journal of Philosophy, 28: 281–296. Floyd, J. and A. Kanamori, 2006, “How Gödel Transformed Set Theory”, Notices of the American Mathematical Society, 53(4): 419–427. Folina, Janet, 2014, “Gödel on How to Have your Mathematics and Know it Too”, in Interpreting Gödel, Kennedy, J. (ed.) Cambridge: Cambridge University Press, 2014. Føllesdal, Dagfinn, 1995, “Gödel and Husserl”, in From Dedekind to Gödel (Synthese Library, Volume 251), J. Hintikka (ed.), Dordrecht, Boston: Kluwer, pp. 427–446. Foreman, Matthew, 1998, “Generic Large Cardinals: New Axioms for Mathematics?”, in Documenta Mathematica, Extra Volume, Proceedings of the International Congress of Mathematicians, II, pp. 11–21 [available online (in compressed Postscript)]. Franks, Curtis, 2009, “The Autonomy of Mathematical Knowledge: Hilbert’s Program Revisited”, Cambridge: Cambridge University Press. –––, 2011, “Stanley Tennenbaum’s Socrates”, in Set Theory, Arithmetic and Foundations of Mathematics: Theorems, Philosophies, Kennedy, J. and Kossak, R., (eds.), Lecture Notes in Logic, 36, Cambridge: Cambridge University Press, 2011. –––, 2014, “Logical Completeness, Form and Content: An Archaeology”, in Interpreting Gödel, Kennedy, J. (ed.) Cambridge: Cambridge University Press, 2014. Gaifman, H., 2000, “What Godel’s Incompleteness Result Does and Does Not Show”, Journal of Philosophy, 97 (8): 462–471. Garson, James, 2003, “Modal Logic”, in The Stanford Encyclopedia of Philosophy, Fall 2003 Edition, Edward N. Zalta (ed.), URL = <https://plato.stanford.edu/archives/fall2003/entries/logic-modal/>. Glivenko, V., 1929, “Sur quelques points de la logique de m. Brouwer.”, Académie Royale de Belgique, Bulletin de la Classe des Sciences, 15: 183–188. Gottwald, Siegfried, 2004, “Many-valued Logic”, in The Stanford Encyclopedia of Philosophy, Winter 2004 Edition, Edward N. Zalta (ed.), URL = <https://plato.stanford.edu/archives/win2004/entries/logic-manyvalued/>. Gödel, Rudolf, 1983, “History of the Gödel Family”, Susan Simonsin (trans.), in Weingartner and Schmetterer 1987, pp. 11–27. Hauser, Kai, 2006, “Gödel’s Program Revisited, Part 1: the Turn to Phenomenology”, Bulletin of Symbolic Logic, 12 (4): 529–590. Heyting, Arendt, 1930, “Die formalen Regeln der intuitionistischen Logik”, Sitzungsberichte der Preussischen Akademie der Wissenschaften, physikalisch-mathematische Klasse, II, pp. 42–56. Hilbert, David, 1926, “Über das Unendliche”, Mathematische Annalen, 95: 161–190. Hilbert, D. and W. Ackermann, 1928, Grundzüge der theoretischen Logik, Berlin: Springer-Verlag. Hilbert, D. and P. Bernays, 1934, Grundlagen der Mathematik, Volume 1, Berlin: Springer-Verlag. –––, 1939, Grundlagen der Mathematik, Volume II, Berlin: Springer-Verlag. Hodges, Wilfrid, 2005, “Model Theory”, in The Stanford Encyclopedia of Philosophy, Fall 2005 Edition, Edward N. Zalta (ed.), URL = <https://plato.stanford.edu/archives/fall2005/entries/model-theory/>. Husserl, Edmund, 1911, “Philosophie als strenge Wissenschaft”, Logos, 1: 289–341. Jaśkowski, Stanisław, 1936, “Investigations into the System of Intuitionist Logic”, Studia Logica, 34(2) (1975): 117–120. (Translated by S. McCall from the French “Rechereches sur le système de la logique intuitioniste” in Actes du Congrés International de Philosophie Scientifique, Volume VI, Hermann, Paris, 1936, pp. 58–61.) Jech, Thomas, 2003, Set theory, (Springer Monographs in Mathematics), Berlin: Springer-Verlag. 3rd millennium edition, revised and expanded. Jensen, R. Björn, 1972, “The Fine Structure of the Constructible Hierarchy” (with a section by Jack Silver), Annals of Mathematical Logic, 4: 229–308; Erratum, 4 (1972): 443. Kanamori, Aki, 1996, “The Mathematical Development of Set theory from Cantor to Cohen.” Bulletin of Symbolic Logic, 2(1): 1–71. –––, 2006, “Levy and Set Theory”, Annals of Pure and Applied Logic, 140(3): 233–252. Kennedy, Juliette, 2006, “Incompleteness — A Book Review,” Notices of the American Mathematical Societ, 53(4): 448–455. –––, 2011, “Gödel’s Thesis: An Appreciation” in Kurt Gödel and the Foundations of Mathematics: Horizons of Truth, M. Baaz, C. Papadimitriou, D. Scott, H. Putnam, and C. Harper (eds.), Cambridge: Cambridge University Press 95–110. –––, 2013, “On Formalism Freeness: Implementing Gödel’s 1946 Princeton Bicentennial Lecture”, Bulletin of Symbolic Logic, 19(3): 351–393. –––, 2014, “Gödel’s 1946 Princeton Bicentennial Lecture: An Appreciation”, in Interpreting Gödel: Critical Essays, Cambridge: Cambridge University Press. Kennedy, Juliette (ed.), 2014, Interpreting Gödel: Critical Essays, Cambridge: Cambridge University Press. Kennedy, J. and van Atten, M., 2003, “On the Philosophical Development of Kurt Gödel”, Bulletin of Symbolic Logic, 9(4): 425–476. Reprinted in Kurt Gödel: Essays for his Centennial, Solomon Feferman, Charles Parsons and Stephen G. Simpson (eds.), Cambridge: Cambridge University Press. –––, 2004, “Gödel’s Modernism: On Set-theoretic Incompleteness”, Graduate Faculty Philosophy Journal, 25(2): 289–349. (See the Erratum in Graduate Faculty Philosophy Journal, 26(1) (2005), page facing contents.) –––, 2009, “Gödel’s Modernism: On Set-theoretic Incompleteness, Revisited”, in Logicism, Intuitionism and Formalism: What has become of them?, S. Linström, E. Palmgren, K. Segerberg, and V. Stoltenberg-Hansen (eds.), Berlin: Springer: 303–356. –––, 2009, “Gödel’s Logic”, in D. Gabbay and J. Woods (eds.), The Handbook of the History of Logic: Logic from Russell to Gödel, Volume 5, Amsterdam: Elsevier: 449–509. Kleene, S. C., 1987, “Gödel’s Impression on Students of Logic in the 1930s”, in Weingartner and Schmetterer 1987, pp. 49–64. Koellner, Peter, 2014, “Large Cardinals and Determinacy”, The Stanford Encyclopedia of Philosophy (Spring Edition), Edward N. Zalta (ed.), URL = <https://plato.stanford.edu/archives/spr2014/entries/large-cardinals-determinacy/>. Kreisel, Georg, 1980, “Kurt Gödel, 28 April 1906 – 14 January 1978”, Biographical Memoirs of Fellows of the Royal Society, 26: 148–224. Corrigenda, 27 (1981): 697; further corrigenda, 28 (1982): 697. –––, 1988, “Review of Kurt Gödel: Collected works, Volume I”, Notre Dame Journal of Formal Logic, 29(1): 160–181. –––, 1990, “Review of Kurt Gödel: Collected Works, Volume II”, Notre Dame Journal of Formal Logic, 31(4): 602–641. –––, 1998, “Second Thoughts Around Some of Gödel’s Writings: A Non-academic Option”, Synthese, 114(1): 99–160. Kripke, Saul, 2009, “The collapse of the Hilbert program: why a system cannot prove its own 1-consistency”, Bulletin of Symbolic Logic, 15 (2): 229–231. Kunen, Kenneth, 1983, Set Theory: An Introduction to Independence Proofs, (Studies in Logic and the Foundations of Mathematics, Volume 102), Amsterdam: North-Holland Publishing Co. Reprint of the 1980 original. Löb, M. H., 1956, “Formal Systems of Constructive Mathematics”, Journal of Symbolic Logic, 21: 63–75. Löwenheim, L., 1915, “Über Möglichkeiten im Relativkalkül”, Mathematische Annalen, 76(4): 447–470. Łukasiewicz, Jan, 1970, Selected works, (Studies in Logic and the Foundations of Mathematics), L. Borkowski (ed.), Amsterdam: North-Holland Publishing Co. Maddy, Penelope, 1990, Realism in Mathematics, New York: Clarendon Press. Maddy, Penelope, 2011, Defending the Axioms, Oxford: Oxford University Press. Mal’cev, Anatoli Ivanovic, 1971, The Metamathematics of Algebraic Systems. Collected Papers: 1936–1967 (Studies in Logic and the Foundations of Mathematics, Volume 66), translated, edited, and provided with supplementary notes by Benjamin Franklin Wells, III, Amsterdam: North-Holland Publishing Co. Mancosu, Paolo, 1998, From Brouwer to Hilbert. The Debate on the Foundations of Mathematics in the 1920s, Oxford: Oxford University Press. –––, 2004, “Review of Kurt Gödel, Collected Works, Volumes IV and V”, Notre Dame Journal of Formal Logic, 45: 109–125. Martin, D.A., 2005, “Gödel’s Conceptual Realism”, Bulletin of Symbolic Logic, 11: 207–224. McKinsey, J. C. C. and A. Tarski, 1948, “Some Theorems About the Sentential Calculi of Lewis and Heyting”, Journal of Symbolic Logic, 13: 1–15. Mostowski, Andrzej, 1949, “An Undecidable Arithmetical Statement”, Fundamenta Mathematicae, 36: 143–164. –––, 1982, Sentences Undecidable in Formalized Arithmetic: An Exposition of the Theory of Kurt Gödel, Westport, CT: Greenwood Press. Reprint of the 1952 original. Oliva, Paulo, 2006, “Unifying Functional Interpretations”, Notre Dame Journal of Formal Logic, 47(2): 263–290. Parikh, Rohit, 1971, “Existence and Feasibility in Arithmetic”, Journal of Symbolic Logic, 36: 494–508. Parsons, Charles, 1995a, “Platonism and Mathematical Intuition in Kurt Gödel’s Thought”, Bulletin of Symbolic Logic, 1(1): 44–74. –––, 1995b, “Quine and Gödel on Analyticity”, in On Quine: New Essays, Cambridge: Cambridge University Press, pp. 297–313. –––, 2000, “Reason and Intuition”, Synthese, 125(3): 299–315. –––, 2002, “Realism and the Debate on Impredicativity, 1917–1944”, in Reflections on the Foundations of Mathematics: Essays in Honor of Solomon Feferman, (Lecture Notes in Logic, Volume 15), W. Sieg, R. Sommer, and C. Talcott (eds.), Urbana, IL: Association of Symbolic Logic, pp. 372–389. –––, 2010, “Gödel and Philosophical Idealism”Philosophia Mathematica, 18 (2): 166–192. –––, 2014, “Analyticity for Realists”, in Interpreting Gödel, Kennedy, J. (ed.) Cambridge: Cambridge University Press, 2014. Poonen, Bjorn, 2014, “Undecidable Problems: A Sampler”, in Interpreting Gödel: Critical Essays, Cambridge: Cambridge University Press. Post, Emil L., 1921, “Introduction to a General Theory of Elementary Propositions”, American Journal of Mathematics, 43(3): 163–185. Pudlák, Pavel, 1996, “On the lengths of proofs of consistency: a survey of results”, Annals of the Kurt Gödel Society, 2: 65-86. Raatikainen, P., 2005, “On the Philosophical Relevance of Gödel’s Incompleteness Theorems”, Revue Internationale de Philosophie, 59 (4): 513–534. Rogers, Jr., Hartley, 1967, Theory of Recursive Functions and Effective Computability, New York: McGraw-Hill Book Co. Rosser, J.B., 1936, “Extensions of Some Theorems of Gödel and Church”, Journal of Symbolic Logic, 1(3): 87–91. Scott, Dana, 1961, “Measurable Cardinals and Constructible Sets”, Bulleint de l’Academie Polonaise des Sciences (Série des Science, Mathématiques, Astronomiques et Physiques), 9: 521–524. Shelah, Saharon, 2014, “Reflecting on Logical Dreams”, in Interpreting Gödel: Critical Essays, Cambridge: Cambridge University Press. Sieg, Wilfried, 1988, “Hilbert’s Program Sixty Years Later”, Journal of Symbolic Logic, 53(2): 338–348. –––, 1990, “Relative Consistency and Accessible Domains”, Synthese, 84(2): 259–297. –––, 1999, “Hilbert’s Programs: 1917–1922”, Bulletin of Symbolic Logic, 5(1): 1–44. –––, 2006, “Gödel on Computability”, Philosophia Mathematica, 14: 189–207. Sierpinski, Wacław, 1947, “L’hypothèse généralisée du continu et l’axiome du choix”, Fundamenta Mathematicae, 34: 1–5. Sigmund, Karl, 2006, “Pictures at an Exhibition”, Notices of the American Mathematical Society, 53(4): 428–432. Skolem, Thoralf, 1920, “Logisch-kombinatorische Untersuchungen über die Erfüllbarkeit oder Beweisbarkeit mathematischer Sätze nebst einem Theoreme über dichte Mengen”, Skrifter utgit av Videnskappsselskapet i Kristiania, I. Matematisk-naturvidenskabelig klasse, Number 4, pp. 1–36. Reprinted in Skolem 1970, pp. 103–136. –––, 1923, “Einige Bemerkungen zur axiomatischen Begründung der Mengenlehre”, Matematikerkongressen i Helsingfors den 4–7 Juli 1922, Den femte skandinaviska matematikerkongressen, Redogörelse, Helsinki, pp. 217–232. Reprinted in Skolem 1970, pp. 137–152. –––, 1933, “Über die Unmöglichkeit einer vollständigen Charakterisierung der Zahlenreihe mittels eines endlichen Axiomensystems”, Norsk Matematisk forenings skrifter, 10: 73–82. –––, 1970, Selected Works in Logic, Jens Erik Fenstad (ed.), Oslo: Universitetsforlaget. Smith, David Woodruff, 2005, “Phenomenology”, in The Stanford Encyclopedia of Philosophy (Winter Edition), Edward N. Zalta (ed.), URL = <https://plato.stanford.edu/archives/win2005/entries/phenomenology/>. Solovay, Robert, 1990, “Introductory Note to 1938, 1939, 1939a, 1940”, in Gödel 1990, pp. 1–25. Steel, John, 2000, “Mathematics Needs New Axioms”, Bulletin of Symbolic Logic, 6(4): 422–433. Steel, John, 2014, “Gödel’s Program”, in Interpreting Gödel, Kennedy, J. (ed.) Cambridge: Cambridge University Press, 2014. Tait, William, 1967, “Intensional Interpretations of Functionals of Finite Type I,” Journal of Symbolic Logic, 32(2): 198–212. –––, 1981, “Finitism”, Journal of Philosophy, 78: 524–556. Reprinted in Tait 2005, pp. 21–42. –––, 1986, “Truth and Proof: The Platonism of Mathematics”, Synthese, 69(3): 341–370. Reprinted in Tait 2005, pp. 61–88. –––, 2001, “Gödel’s Unpublished Papers on Foundations of Mathematics”, Philosophia Mathematica, 9(1): 87–126. Reprinted in Tait 2005, pp. 276–313. –––, 2002, “Remarks on Finitism”, in Reflections on the Foundations of Mathematics: Essays in Honor of Solomon Feferman (Lecture Notes in Logic, Volume 15), W. Sieg, R. Sommer, and C. Talcott (eds.), Urbana, IL: Association of Symbolic Logic, pp. 410–419. Reprinted in Tait 2005, pp. 43–53. –––, 2005, The Provenance of Pure Reason: Essays in the Philosophy of Mathematics and its History (Logic and Computation in Philosophy), New York: Oxford University Press. –––, 2006, “Gödel’s correspondence on proof theory and constructive mathematics”Philosophia Mathematica, 14 (1): 76–111. –––, 2006, “Gödel’s interpretation of intuitionism”,Philosophia Mathematica, 14 (2): 208–228. Taussky-Todd, Olga, 1983, “Remembrances of Kurt Gödel”, in Weingartner and Schmetterer 1987, pp. 29–41. Tieszen, Richard, 1992, “Kurt Gödel and Phenomenology”, Philosophy of Science, 59(2): 176–194. –––, 2002, “Gödel and the Intuition of Concepts”, Synthese, 133 (3): 363–391. –––, 2005, Phenomenology, Logic and the Philosophy of Mathematics, Cambridge: Cambridge University Press. –––, 2011, After Gödel: Platonism and Rationalism in Mathematics and Logic, Oxford: Oxford University Press. Toledo, Sue, 2011, “Sue Toledo’s Notes of her Conversations with Kurt Gödel in 1972-5”, in Set Theory, Arithmetic and Foundations of Mathematics: Theorems, Philosophies (Lecture Notes in Logic, 36), Kennedy, J. and Kossak, R., (eds.), Cambridge: Cambridge University Press, forthcoming. Tragesser, Robert, 1977, Phenomenology and Logic, Ithaca: Cornell University Press. –––, 1984, Husserl and Realism in Logic and Mathematics, (Series: Modern European Philosophy), Cambridge: Cambridge University Press. –––, 1989, “Sense Perceptual Intuition, Mathematical Existence, and Logical Imagination”, Philosphia Mathematica, 4(2): 154–194. Troelstra, A. S., 1986, “Note to 1958 and 1972”, in Gödel 1990, pp. 217–241. Troelstra, A. S. (ed.), 1973, Metamathematical Investigation of Intuitionistic Arithmetic and Analysis, (Lecture Notes in Mathematics, Volume 344), Berlin: Springer-Verlag. Turing, A. M., 1937, “On Computable Numbers, with an Application to the Entscheidungsproblem”, Proceedings of the London Mathematical Society (Series 2), 42: 230–265. van Atten, Mark, 2005, “On Gödel’s Awareness of Skolem’s Helsinki Lecture”, History and Philosophy of Logic, 26(4): 321–326. –––, 2006, “Two Draft Letters from Gödel on Self-knowledge of Reason”, Philosophia Mathematica, 14(2): 255–261. –––, 2015, “Essays on Gödel’s Reception of Leibniz, Husserl and Brouwer”, Springer. van Heijenoort, J. (ed.), 1967, From Frege to Gödel: A sourcebook in mathematical logic, 1879–1931, Cambridge, MA: Harvard University Press. van Oosten, Jaap, 2008, Realizability: An Introduction to its Categorical Side (Studies in Logic and Foundations of Mathematics: Volume 152), Amsterdam: Elsevier. von Neumann, John, 2005, John von Neumann: Selected Letters (History of Mathematics, Volume 27), foreword by P. Lax, introduction by Marina von Neumann Whitman, preface and introductory comments by Miklós Rédei (ed.), Providence, RI: American Mathematical Society. Väänänen, Jouko, 2014, “Multiverse Set Theory and Absolutely Undecidable Propositions”, in Interpreting Gödel, J. Kennedy (ed.), Cambridge: Cambridge University Press, 2014. Wang, Hao, 1957, “The Axiomatization of Arithmetic”, Journal of Symbolic Logic, 22: 145–158. –––, 1973, From Mathematics to Philosophy, London: Routledge. –––, 1981, “Some Facts about Kurt Gödel”, Journal of Symbolic Logic, 46(3): 653–659. –––, 1987, Reflections on Kurt Gödel, Cambridge, MA: MIT Press. –––, 1993, Popular Lectures on Mathematical Logic, New York: Dover Publications Inc., 2nd edition. –––, 1996, A Logical Lourney: From Gödel to Philosophy (Representation and Mind), Cambridge, MA: MIT Press. Weingartner, P., and L. Schmetterer (eds.), 1987, Gödel Remembered: Salzburg 10–12 July 1983, (History of Logic, Number 4), Naples: Bibliopolis. Wilkie, Alex, and J.B. Paris, 1987, “On the scheme of induction for bounded arithmetic formulas”, 35: 261–302. Woodin, W. Hugh, 1988, “Supercompact Cardinals, Sets of Reals, and Weakly Homogeneous Trees”, Proceedings of the National Academy of Sciences of the U.S.A., 85(18): 6587–6591. –––, 2001a, “The Continuum Hypothesis. I”, Notices of the American Mathematical Society, 48(6): 567–576. –––, 2001b, “The Continuum Hypothesis. II”, Notices of the American Mathematical Society, 48(7): 681–690. –––, 2002, “Correction: ‘The Continuum Hypothesis. II’”, Notices of the American Mathematical Society, 49(1): 46. Yourgrau, Palle, 2005, A World Without Time. The Forgotten Legacy of Gödel and Einstein, New York: Basic Books. Zach, Richard, 1999, “Completeness Before Post: Bernays, Hilbert, and the Development of Propositional Logic”, Bulletin of Symbolic Logic, 5(3): 331–366. –––, 2003, “Hilbert’s Program”, in The Stanford Encyclopedia of Philosophy (Fall Edition), Edward N. Zalta (ed.), URL = <https://plato.stanford.edu/archives/fall2003/entries/hilbert-program/>.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': 'Bibliography', 'Header 3': 'Secondary Sources'}),\n",
       " Document(page_content='Academic Tools', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='How to cite this entry. Preview the PDF version of this entry at the Friends of the SEP Society. Look up topics and thinkers related to this entry at the Internet Philosophy Ontology Project (InPhO). Enhanced bibliography for this entry at PhilPapers, with links to its database.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': 'Academic Tools'}),\n",
       " Document(page_content='Other Internet Resources', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='Avigad, Jeremy, “Gödel and the metamathematical tradition”, manuscript in PDF available online. Koellner, Peter, “Truth in Mathematics:The question of Pluralism”, manuscript in PDF available online. The Bernays Project.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': 'Other Internet Resources'}),\n",
       " Document(page_content='Related Entries', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='Gödel, Kurt: incompleteness theorems | Hilbert, David: program in the foundations of mathematics | Husserl, Edmund | Leibniz, Gottfried Wilhelm | mathematics, philosophy of: intuitionism | mathematics, philosophy of: Platonism | model theory | model theory: first-order | phenomenology | realism | set theory | set theory: continuum hypothesis | set theory: large cardinals and determinacy', metadata={'Header 1': 'Kurt Gödel', 'Header 2': 'Related Entries'}),\n",
       " Document(page_content='Acknowledgments', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='This entry was very much improved by discussion and correspondence with the following: Aki Kanamori, who made helpful corrections and comments to section 2.4; Jouko Väänänen, whose expertise in all areas of mathematical logic the author benefited from in a great many invaluable discussions regarding the material in section 2; my sub-editor Richard Zach, whose many important and helpful suggestions led to a vast improvement of this entry, and an anonymous referee for helpful comments and corrections. The author is grateful to the NWO for their support during the last period of the writing of this entry, to the Institute for Advanced Study for their hospitality during the writing of this entry, and to Marcia Tucker of the IAS and the Rare Books and Special Collections department of Firestone Library for all of their assistance over the years .', metadata={'Header 1': 'Kurt Gödel', 'Header 3': 'Acknowledgments'}),\n",
       " Document(page_content=\"Copyright © 2015 by Juliette Kennedy <juliette.kennedy@helsinki.fi>  \\nOpen access to the SEP is made possible by a world-wide funding initiative. The Encyclopedia Now Needs Your Support Please Read How You Can Help Keep the Encyclopedia Free  \\nBrowse  \\nTable of Contents What's New Random Entry Chronological Archives  \\nAbout  \\nEditorial Information About the SEP Editorial Board How to Cite the SEP Special Characters Advanced Tools Contact  \\nSupport SEP  \\nSupport the SEP PDFs for SEP Friends Make a Donation SEPIA for Libraries  \\nMirror Sites  \\nView this site from another server:  \\nUSA (Main Site) Philosophy, Stanford University  \\nInfo about mirror sites  \\nThe Stanford Encyclopedia of Philosophy is copyright © 2021 by The Metaphysics Research Lab, Department of Philosophy, Stanford University  \\nLibrary of Congress Catalog Data: ISSN 1095-5054\")]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "url = \"https://plato.stanford.edu/entries/goedel/\"    # html loaded from web url ---> for this I need a pipeline\n",
    "\n",
    "html_header_split_on = [\n",
    "    (\"h1\", 'header1'),\n",
    "    (\"h2\", 'header2'),\n",
    "    (\"h3\", 'header3'),\n",
    "    (\"h4\", 'header4'),\n",
    "]\n",
    "\n",
    "html_splitters = HTMLHeaderTextSplitter(headers_to_split_on=html_header_split_on)\n",
    "html_header_splitts = html_splitter.split_text_from_url(url)      #pipeline to another splitter\n",
    "html_header_splitts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Stanford Encyclopedia of Philosophy  \\nMenu  \\nBrowse About Support SEP'),\n",
       " Document(page_content=\"Browse About Support SEP  \\nTable of Contents What's New Random Entry Chronological Archives\"),\n",
       " Document(page_content='Editorial Information About the SEP Editorial Board How to Cite the SEP Special Characters Advanced'),\n",
       " Document(page_content='Special Characters Advanced Tools Contact'),\n",
       " Document(page_content='Support the SEP PDFs for SEP Friends Make a Donation SEPIA for Libraries  \\nEntry Navigation'),\n",
       " Document(page_content='Entry Contents Bibliography Academic Tools Friends PDF Preview Author and Citation Info Back to Top'),\n",
       " Document(page_content='and Citation Info Back to Top'),\n",
       " Document(page_content='Kurt Gödel'),\n",
       " Document(page_content='First published Tue Feb 13, 2007; substantive revision Fri Dec 11, 2015', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='Kurt Friedrich Gödel (b. 1906, d. 1978) was one of the principal founders of the modern,', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='founders of the modern, metamathematical era in mathematical logic. He is widely known for his', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='He is widely known for his Incompleteness Theorems, which are among the handful of landmark', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='among the handful of landmark theorems in twentieth century mathematics, but his work touched every', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='but his work touched every field of mathematical logic, if it was not in most cases their original', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='in most cases their original stimulus. In his philosophical work Gödel formulated and defended', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='Gödel formulated and defended mathematical Platonism, the view that mathematics is a descriptive', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='mathematics is a descriptive science, or alternatively the view that the concept of mathematical', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='the concept of mathematical truth is objective. On the basis of that viewpoint he laid the', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='of that viewpoint he laid the foundation for the program of conceptual analysis within set theory', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='analysis within set theory (see below). He adhered to Hilbert’s “original rationalistic conception”', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='rationalistic conception” in mathematics (as he called it);[1] and he was prophetic in anticipating', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='was prophetic in anticipating and emphasizing the importance of large cardinals in set theory', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='large cardinals in set theory before their importance became clear.', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='1. Biographical Sketch 2. Gödel’s Mathematical Work 3. Gödel’s Philosophical Views Bibliography', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='Views Bibliography Academic Tools Other Internet Resources Related Entries', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='2.1 The Completeness Theorem 2.2 The Incompleteness Theorems 2.3 Speed-up Theorems 2.4 Gödel’s Work', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='Theorems 2.4 Gödel’s Work in Set theory 2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='Logic and Arithmetic Supplement Document: Gödel’s Documents', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='2.1.1 Introduction 2.1.2 Proof of the Completeness Theorem 2.1.3 An Important Consequence of the', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='Important Consequence of the Completeness Theorem', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='2.2.1 The First Incompleteness Theorem 2.2.2 The proof of the First Incompleteness Theorem 2.2.3', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='Incompleteness Theorem 2.2.3 The Second Incompleteness Theorem Supplementary Document: Did the', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='Document: Did the Incompleteness Theorems Refute Hilbert’s Program?', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='2.4.1 The consistency of the Continuum Hypothesis and the Axiom of Choice 2.4.2 Gödel’s Proof of', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='Choice 2.4.2 Gödel’s Proof of the Consistency of the Continuum Hypothesis and the Axiom of Choice', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='and the Axiom of Choice with the Axioms of Zermelo-Fraenkel Set Theory 2.4.3 Consequences of', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='Theory 2.4.3 Consequences of Consistency 2.4.4 Gödel’s view of the Axiom of Constructibility', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='2.5.1 Intuitionistic Propositional Logic is not Finitely-Valued 2.5.2 Classical Arithmetic is', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='2.5.2 Classical Arithmetic is Interpretable in Heyting Arithmetic 2.5.3 Intuitionistic', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='2.5.3 Intuitionistic Propositional Logic is Interpretable in S4 2.5.4 Heyting Arithmetic is', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='2.5.4 Heyting Arithmetic is Interpretable into Computable Functionals of Finite Type.', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='3.1 Gödel’s Rationalism 3.2 Gödel’s Realism Supplementary Document: Gödel’s Turn to Phenomenology', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='Gödel’s Turn to Phenomenology Supplementary Document: A Philosophical Argument About the Content of', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='Argument About the Content of Mathematics', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='Primary Sources Secondary Sources', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='Gödel’s Writings The Collected Papers of Kurt Gödel Selected Works of Kurt Gödel', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='1. Biographical Sketch 2. Gödel’s Mathematical Work 2.1 The Completeness Theorem 2.1.1 Introduction', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='Theorem 2.1.1 Introduction 2.1.2 Proof of the Completeness Theorem 2.1.3 An Important Consequence', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='An Important Consequence of the Completeness Theorem 2.2 The Incompleteness Theorems 2.2.1 The', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='Theorems 2.2.1 The First Incompleteness Theorem 2.2.2 The proof of the First Incompleteness Theorem', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='First Incompleteness Theorem 2.2.3 The Second Incompleteness Theorem 2.3 Speed-up Theorems 2.4', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='2.3 Speed-up Theorems 2.4 Gödel’s Work in Set theory 2.4.1 The consistency of the Continuum', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='consistency of the Continuum Hypothesis and the Axiom of Choice 2.4.2 Gödel’s Proof of the', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='2.4.2 Gödel’s Proof of the Consistency of the Continuum Hypothesis and the Axiom of Choice with the', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='the Axiom of Choice with the Axioms of Zermelo-Fraenkel Set Theory 2.4.3 Consequences of', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='Theory 2.4.3 Consequences of Consistency 2.4.4 Gödel’s view of the Axiom of Constructibility 2.5', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='Axiom of Constructibility 2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic 2.5.1', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='Logic and Arithmetic 2.5.1 Intuitionistic Propositional Logic is not Finitely-Valued 2.5.2', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='is not Finitely-Valued 2.5.2 Classical Arithmetic is Interpretable in Heyting Arithmetic 2.5.3', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='in Heyting Arithmetic 2.5.3 Intuitionistic Propositional Logic is Interpretable in S4 2.5.4 Heyting', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='in S4 2.5.4 Heyting Arithmetic is Interpretable into Computable Functionals of Finite Type. 3.', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='of Finite Type. 3. Gödel’s Philosophical Views 3.1 Gödel’s Rationalism 3.2 Gödel’s Realism', metadata={'Header 1': 'Kurt Gödel'}),\n",
       " Document(page_content='Kurt Gödel was born on April 28, 1906 in what was then the Austro-Hungarian city of Brünn, and what', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='city of Brünn, and what is now Brno in the Czech Republic.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='Gödel’s father Rudolf August was a businessman, and his mother Marianne was a well-educated and', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='was a well-educated and cultured woman to whom Gödel remained close throughout his life, as', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='close throughout his life, as witnessed by the long and wide-ranging correspondence between them.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='correspondence between them. The family was well off, and Gödel’s childhood was an uneventful one,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='was an uneventful one, with one important exception; namely, from about the age of four Gödel', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='about the age of four Gödel suffered frequent episodes of poor health, and the health problems he', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='and the health problems he suffered then as well as others of various kinds were to plague him his', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='kinds were to plague him his entire life.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='Health problems notwithstanding, Gödel proved to be an exemplary student at primary school and', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='student at primary school and later the Gymnasium, excelling especially in mathematics, languages', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='in mathematics, languages and religion. Upon his graduation from the Gymnasium in Brno in 1924', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='the Gymnasium in Brno in 1924 Gödel enrolled in the University of Vienna, attending lectures on', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='Vienna, attending lectures on physics, his initial field of interest, lectures on philosophy given', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='lectures on philosophy given by Heinrich Gomperz, and lectures on mathematics. Gödel took a number', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='Gödel took a number of physics courses during his undergraduate years, as witnessed by his', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='years, as witnessed by his university transcript; this is notable in view of Gödel’s subsequent', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='in view of Gödel’s subsequent contributions to relativity in 1947. Philipp Furtwängler, cousin of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='Furtwängler, cousin of the great German conductor Wilhelm Furtwängler, was one of his mathematics', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='was one of his mathematics professors, and indeed Furtwängler’s course on class field theory almost', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='on class field theory almost tempted Gödel to pursue his studies in that area. Gödel learned his', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='that area. Gödel learned his logic from Rudolph Carnap and from Hans Hahn, eventually graduating', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='Hahn, eventually graduating under Hahn with a Dr.phil. in mathematics in 1929. The main theorem of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='in 1929. The main theorem of his dissertation was the completeness theorem for first order logic', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='theorem for first order logic (Gödel 1929).[2]', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='Gödel’s university years also marked the beginning of his attendance at meetings of the Vienna', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='at meetings of the Vienna Circle, a group around Moritz Schlick that quickly became known as', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='that quickly became known as “logical positivists,” a term coined by Feigl and Blumberg in their', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='Feigl and Blumberg in their 1931 “Logical positivism: A new movement in European philosophy” (Feigl', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='European philosophy” (Feigl and Blumberg 1931). Though Gödel was not himself a logical positivist,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='himself a logical positivist, those discussions were a crucial formative influence.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='The 1930s were a prodigious decade for Gödel. After publishing his 1929 dissertation in 1930, he', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='1929 dissertation in 1930, he published his groundbreaking incompleteness theorems in 1931, on the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='theorems in 1931, on the basis of which he was granted his Habilitation in 1932 and a', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='Habilitation in 1932 and a Privatdozentur at the University of Vienna in 1933.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='Among his mathematical achievements at the decade’s close is the proof of the consistency of both', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='of the consistency of both the Axiom of Choice and Cantor’s Continuum Hypothesis with the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='Continuum Hypothesis with the Zermelo-Fraenkel axioms for set theory, obtained in 1935 and 1937,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='obtained in 1935 and 1937, respectively. Gödel also published a number of significant papers on', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='of significant papers on modal and intuitionistic logic and arithmetic during this period,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='during this period, principal among which is his “On intuitionistic arithmetic and number theory,”', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='and number theory,” (Gödel 1933e), in which he showed that classical first order arithmetic is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='first order arithmetic is interpretable in Heyting arithmetic by a simple translation. Other', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='a simple translation. Other publications of the 1930s include those on the decision problem for the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='the decision problem for the predicate calculus, on the length of proofs, and on differential and', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='and on differential and projective geometry.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='By the end of the decade both Gödel’s advisor Hans Hahn and Moritz Schlick had died (the latter was', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='had died (the latter was assassinated by an ex-student), two events which led to a personal crisis', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='led to a personal crisis for Gödel. Also, his appointment at the University, that of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='at the University, that of Privatdozentur, was cancelled, being replaced by the position “Dozentur', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='by the position “Dozentur neuer Ordnung,” granted to candidates only after they had passed a racial', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='they had passed a racial test.[3] Gödel’s three trips the United States during that decade', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='States during that decade triggered an investigation. (See Sigmund 2006.) Finally, Gödel was found', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='Finally, Gödel was found fit for military service by the Nazi government in 1939.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='All of these events were decisive in influencing his decision to leave Austria in 1940, when he and', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='Austria in 1940, when he and his wife Adele emigrated to the United States. This long and difficult', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='This long and difficult episode in their life is recounted by John Dawson in his biography of Gödel', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='in his biography of Gödel called “Logical Dilemmas,” (Dawson 1997) as well as by Solomon Feferman', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='well as by Solomon Feferman in “Gödel’s Life and Work,” (Feferman 1986) to both of which the reader', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='to both of which the reader is referred.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='Upon arrival Gödel took up an appointment as an ordinary member at the Institute for Advanced', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='at the Institute for Advanced Study; he would become a permanent member of the Institute in 1946', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='of the Institute in 1946 and would be granted his professorship in 1953. (Gödel and his wife were', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='(Gödel and his wife were granted American citizenship in April 1948.) He would remain at the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='1948.) He would remain at the Institute until his retirement in 1976. The Gödels never returned to', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='The Gödels never returned to Europe.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='Gödel’s early years at the Institute were notable for his close friendship with his daily walking', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='with his daily walking partner Albert Einstein, as well as for his turn to philosophy of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='for his turn to philosophy of mathematics, a field on which Gödel began to concentrate almost', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='began to concentrate almost exclusively from about 1943. The initial period of his subsequent', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='period of his subsequent lifelong involvement with philosophy was a fruitful one (in terms of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='a fruitful one (in terms of publications): in 1944 he published his first philosophical paper,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='first philosophical paper, entitled “On Russell’s Mathematical Logic” (Gödel 1944), and in 1947 he', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='(Gödel 1944), and in 1947 he published his second, entitled “What is Cantor’s Continuum', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='“What is Cantor’s Continuum Hypothesis?” (Gödel 1947). In 1949 he published his third, entitled “A', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='his third, entitled “A Remark on the Relationship between Relativity Theory and Idealistic', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='Theory and Idealistic Philosophy.” (Gödel 1949a). The latter paper coincided with results on', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='coincided with results on rotating universes in relativity he had obtained in 1949, which were', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='obtained in 1949, which were first published in an article entitled: “An Example of a New Type of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='“An Example of a New Type of Cosmological Solutions of Einstein’s Field Equations of Gravitation.”', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='Equations of Gravitation.” (Gödel 1949).', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='Among Gödel’s other significant philosophical works of the 1940s must be counted his 1941 lecture', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='be counted his 1941 lecture entitled “In What Sense is Intuitionistic Logic Constructive?” (Gödel', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='Logic Constructive?” (Gödel *1941) in which the notion: “computable function of finite type” is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='function of finite type” is introduced. A paper based on the ideas in the lecture entitled “Über', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='in the lecture entitled “Über eine bisher noch nicht benützte Erweiterung des finiten', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='Erweiterung des finiten Standpunktes,” was published only in 1958, and the interpretation of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='and the interpretation of Heyting arithmetic into the quantifier free calculus T in it became known', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='calculus T in it became known as the “Dialectica Interpretation,” after the journal in which the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='the journal in which the article was published (Gödel 1958). (For the revision of it from 1972, see', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='revision of it from 1972, see Gödel 1995.) Finally the decade saw the beginning of Gödel’s', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='saw the beginning of Gödel’s intensive study of Leibniz, which, Gödel reports, occupied the period', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='reports, occupied the period from 1943 to 1946.[4]', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='The 1950s saw a deepening of Gödel’s involvement with philosophy: In 1951 Gödel delivered a', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='In 1951 Gödel delivered a philosophical lecture at Brown University, usually referred to as the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='usually referred to as the Gibbs Lecture, entitled “Some Basic Theorems on the Foundations of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='on the Foundations of Mathematics and Their Philosophical Implications” (Gödel *1951). From 1953 to', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='(Gödel *1951). From 1953 to 1959 Gödel worked on a submission to the Schilpp volume on Rudolf', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='the Schilpp volume on Rudolf Carnap entitled “Is Mathematics a Syntax of Language?” (Gödel', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='a Syntax of Language?” (Gödel *1953/9-III, Gödel *1953/9-V). Gödel published neither of these two', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='neither of these two important manuscripts in his lifetime, although both would appear on two lists', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='would appear on two lists which were found in the Gödel Nachlass, entitled “Was ich publizieren', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='entitled “Was ich publizieren könnte.” (In English: “What I could publish.” Both manuscripts', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='publish.” Both manuscripts eventually appeared in Gödel 1995.) By the decade’s close Gödel', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='By the decade’s close Gödel developed a serious interest in phenomenology.[5]', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='Gödel’s final years are notable for his circulation of two manuscripts: “Some considerations', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='“Some considerations leading to the probable conclusion that the true power of the continuum is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='power of the continuum is ℵ2,” (Gödel *1970a, *1970b) his attempt to derive the value of the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='to derive the value of the continuum from the so-called scale axioms of Hausdorff, and his', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='axioms of Hausdorff, and his “Ontologischer Beweis,” (Gödel *1970) which he entrusted to Dana Scott', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='he entrusted to Dana Scott in 1970 (though it appears to have been written earlier). Taken', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='been written earlier). Taken together, the two manuscripts are the fitting last words of someone', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='fitting last words of someone who, in a fifty year involvement with mathematics and philosophy,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='mathematics and philosophy, pursued, or more precisely, sought the grounds for pursuing those two', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='for pursuing those two subjects under the single heading: “strenge Wissenschaft”—a turn of mind', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='Wissenschaft”—a turn of mind that had been in place from Gödel’s start in 1929, when at the age of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='in 1929, when at the age of twenty-three he opened his doctoral thesis with some philosophical', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='with some philosophical remarks.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='Gödel died in Princeton on January 14, 1978 at the age of 71. His death certificate records the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='death certificate records the cause of death as “starvation and inanition, due to personality', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='inanition, due to personality disorder.” His wife Adele survived him by three years.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='For further biographical material, see Gödel 1987, Kleene 1987, Kreisel 1980, Taussky-Todd 1987 and', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='1980, Taussky-Todd 1987 and Yourgrau 2005.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}),\n",
       " Document(page_content='Below is an examination of some of Gödel’s main contributions in logic and set theory. This', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work'}),\n",
       " Document(page_content='in logic and set theory. This treatment of Gödel’s technical work is not exhaustive, omitting', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work'}),\n",
       " Document(page_content='is not exhaustive, omitting discussion of Gödel’s work in physics and his work on the decision', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work'}),\n",
       " Document(page_content='and his work on the decision problem. These will be treated in the sequel to this entry.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work'}),\n",
       " Document(page_content='For a complete chronology of Gödel’s work the reader is referred to that compiled by John Dawson in', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work'}),\n",
       " Document(page_content='compiled by John Dawson in volume I of Gödel’s Collected Works (Gödel 1986, p. 37).', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work'}),\n",
       " Document(page_content='The completeness question for the first order predicate calculus was stated precisely and in print', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='stated precisely and in print for the first time in 1928 by Hilbert and Ackermann in their text', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='and Ackermann in their text Grundzüge der theoretischen Logik (Hilbert and Ackermann 1928), a text', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='and Ackermann 1928), a text with which Gödel would have been quite familiar.[6]', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='The question Hilbert and Ackermann pose is whether a certain explicitly given axiom system for the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='given axiom system for the first order predicate calculus “…is complete in the sense that from it', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='in the sense that from it all logical formulas that are correct for each domain of individuals can', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='domain of individuals can be derived…” (van Heijenoort 1967, p. 48).', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='We give an outline of Gödel’s own proof in his doctoral thesis (Gödel 1929). An essential', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='(Gödel 1929). An essential difference with earlier efforts (discussed below and elsewhere, e.g. in', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='below and elsewhere, e.g. in Zach 1999), is that Gödel defines meticulously all the relevant basic', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='all the relevant basic concepts.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='A “logical expression” in Gödel’s terminology is a well-formed first order formula without', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='first order formula without identity. An expression is “refutable” if its negation is provable,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='if its negation is provable, “valid” if it is true in every interpretation and “satisfiable” if it', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='and “satisfiable” if it is true in some interpretation. The Completeness Theorem is stated as', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='Theorem is stated as follows:', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='Theorem 1. Every valid logical expression is provable. Equivalently, every logical expression is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='every logical expression is either satisfiable or refutable.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='Gödel’s proof calculus is that of Hilbert and Ackermann’s text. An expression is in normal form if', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='is in normal form if all the quantifiers occur at the beginning. The degree of an expression or', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='degree of an expression or formula is the number of alternating blocks of quantifiers at the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='blocks of quantifiers at the beginning of the formula, assumed to begin with universal quantifiers.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='with universal quantifiers. Gödel shows that if the completeness theorem holds for formulas of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='theorem holds for formulas of degree k it must hold for formulas of degree k + 1. Thus the question', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='k + 1. Thus the question of completeness reduces to formulas of degree 1. That is, it is to be', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='1. That is, it is to be shown that any normal formula (Q)φ of degree 1 is either satisfiable or', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='1 is either satisfiable or refutable, where “(Q)” stands for a (non-empty) block of universal', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='block of universal quantifiers followed by a (possibly empty) block of existential ones.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='Gödel defines a book-keeping device, a well-ordering of all tuples of variables arising from a need', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='variables arising from a need to satisfy φ as dictated by (Q). For example, if (Q)φ is ∀x0∃x1ψ(x0,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='if (Q)φ is ∀x0∃x1ψ(x0, x1), we list the quantifier-free formulas ψ(xn, xn+1). (Or more precisely,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='xn+1). (Or more precisely, finite conjunctions of these in increasing length. See below.) Then in', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='length. See below.) Then in any domain consisting of the values of the different xn, in which each', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='different xn, in which each ψ(xn, xn+1) is true, the sentence (Q)φ is clearly true. A crucial lemma', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='clearly true. A crucial lemma claims the provability, for each k, of the formula (Q)φ → (Qk)φk,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='of the formula (Q)φ → (Qk)φk, where the quantifier free formula φk asserts the truth of ψ for all', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='the truth of ψ for all tuples up to the kth tuple of variables arising from (Q), and (Qk)φk is the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='from (Q), and (Qk)φk is the existential closure of φk. (See the example below where the definition', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='below where the definition of the φk′s is given.) This lemma is the main step missing from the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='main step missing from the various earlier attempts at the proof due to Löwenheim and Skolem, and,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='to Löwenheim and Skolem, and, in the context of the completeness theorem for first order logic,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='for first order logic, renders the connection between syntax and semantics completely explicit.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='Let us consider an example of how a particular formula would be found to be either satisfiable or', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='to be either satisfiable or its negation provable, following Gödel’s method: Consider φ =', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='Gödel’s method: Consider φ = ∀x0∃x1ψ(x0, x1), where ψ(x0, x1) is quantifier-free. We show that this', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='We show that this is either refutable or satisfiable. We make the following definitions:', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='φ0 is the expression ψ(x0, x1) φ1 is the expression ψ(x0, x1) ∧ ψ(x1, x2) … φn is the expression', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='x2) … φn is the expression ψ(x0, x1) ∧ …∧ ψ(xn, xn+1).', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='The crucial lemma, referred to above, shows that from φ we can derive for each n, ∃x0…∃xn+1φn.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='Case 1: For some n, φn is not satisfiable. Then, Gödel argued, using the already known completeness', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='already known completeness theorem for propositional logic,[7] that ¬φn is provable, and hence so', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='¬φn is provable, and hence so is ∀x0,…, xn+1¬φn. Thus ¬∃x0…∃xn+1φn is provable and therefore the ¬φ', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='provable and therefore the ¬φ is provable, i.e., φ is refutable in the Hilbert-Ackermann system.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='the Hilbert-Ackermann system. (Some partial results about propositional logic in addition to those', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='logic in addition to those already mentioned include the semantic completeness of the propositional', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='of the propositional calculus due to Post (1921), as well as a more general completeness theorem', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='general completeness theorem for the same due to Bernays in 1918; the latter appears in Bernays’', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='latter appears in Bernays’ unpublished Habilitationsschrift of 1918; see also Bernays 1926.)', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='Case 2: Each φn is satisfiable. There are only finitely many possible models with universe {x0,…,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='models with universe {x0,…, xn+1}. Gödel orders them as a tree by defining a model M to be below a', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='a model M to be below a model M′ if M is a submodel of M′. In this way we obtain a tree which is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='way we obtain a tree which is finitely branching but infinite. By König’s Lemma there is an', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='By König’s Lemma there is an infinite branch B. (In the proof, Gödel explicitly constructs the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='explicitly constructs the branch given by König’s Lemma rather than citing it by name.) The union', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='citing it by name.) The union of the models on B forms a model M with universe {x0, x1,…}. Since M', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='universe {x0, x1,…}. Since M satisfies each φn, the original formula φ holds in M. So φ is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='formula φ holds in M. So φ is satisfiable and we are done.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='Note that the model, in the satisfiability case of Gödel’s proof, is always countable. Thus this', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='always countable. Thus this proof of the Completeness Theorem gives also the Löweheim-Skolem', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='also the Löweheim-Skolem Theorem (see below). Gödel extends the result to countably many formulas', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='to countably many formulas and to the case of first order logic with identity. He also proves the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='identity. He also proves the independence of the axioms.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='In 1930 Gödel published the paper based on his thesis (Gödel 1930) notable also for the inclusion', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='also for the inclusion of the compactness theorem, which is only implicitly stated in the thesis.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='stated in the thesis. The theorem as stated by Gödel in Gödel 1930 is as follows: a countably', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='is as follows: a countably infinite set of quantificational formulas is satisfiable if and only if', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='is satisfiable if and only if every finite subset of those formulas is satisfiable. Gödel uses', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='is satisfiable. Gödel uses compactness to derive a generalization of the completeness theorem.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='The Compactness Theorem was extended to the case of uncountable vocabularies by Maltsev in 1936', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='by Maltsev in 1936 (see Mal’cev 1971), from which the Upward Löwenheim-Skolem theorem immediately', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='theorem immediately follows. The Compactness Theorem would become one of the main tools in the then', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='of the main tools in the then fledgling subject of model theory.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='A theory is said to be categorical if it has only one model up to isomorphism; it is λ-categorical', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='it is λ-categorical if it has only one model of cardinality λ, up to isomorphism. One of the main', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='isomorphism. One of the main consequences of the completeness theorem is that categoricity fails', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='is that categoricity fails for Peano arithmetic and for Zermelo-Fraenkel set theory.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='In detail, regarding the first order Peano axioms (henceforth PA), the existence of non-standard', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='the existence of non-standard models of them actually follows from completeness together with', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='completeness together with compactness. One constructs these models, which contain infinitely large', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='contain infinitely large integers, as follows: add a new constant symbol c to the language of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='symbol c to the language of arithmetic. Extend PA to a new theory PA* by adding to it the infinite', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='by adding to it the infinite collection of axioms: {c > 0, c > 1, …}, where, e.g., 3 is S(S(S(0))).', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='where, e.g., 3 is S(S(S(0))). PA* is finitely consistent (i.e., every finite subset of PA* is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='every finite subset of PA* is consistent) hence consistent, hence by the Completeness Theorem it', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='the Completeness Theorem it has a model.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='This simple fact about models of Peano arithmetic was not pointed out by Gödel in any of the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='out by Gödel in any of the publications connected with the Completeness Theorem from that time, and', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='Theorem from that time, and it seems not to have been noticed by the general logic community until', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='general logic community until much later. Skolem’s definable ultrapower construction from 1933 (see', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='construction from 1933 (see Skolem 1933) gives a direct construction of a non-standard model of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='of a non-standard model of True Arithmetic (which extends Peano arithmetic, being the set of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='arithmetic, being the set of arithmetic sentences true in the natural numbers). But Skolem never', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='numbers). But Skolem never mentions the fact that the existence of such models follows from the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='such models follows from the completeness and compactness theorems. Gödel in his review (1934c) of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='in his review (1934c) of Skolem’s paper also does not mention this fact, rather observing that the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='rather observing that the failure of categoricity for arithmetic follows from the incompleteness', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='from the incompleteness theorem.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='As for set theory, the failure of categoricity was already taken note of by Skolem in 1923, because', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='of by Skolem in 1923, because it follows from the Löwenheim-Skolem Theorem (which Skolem arrived at', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='(which Skolem arrived at that year; see Skolem 1923, based on Löwenheim 1915 and Skolem 1920): any', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='1915 and Skolem 1920): any first order theory in a countable language that has a model has a', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='that has a model has a countable model.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='Skolem’s observation that categoricity fails for set theory because it has countable models is now', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='has countable models is now known as the Skolem paradox.[8]The observation is strongly emphasized', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='is strongly emphasized in Skolem’s paper, which is accordingly entitled ‘An Observation on the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='‘An Observation on the Axiomatic Foundations of Set Theory’ As he wrote in the conclusion of it, he', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='in the conclusion of it, he had not pointed out the relativity in set theory already in 1915', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='in set theory already in 1915 because:', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='… first, I have in the meantime been occupied with other problems; second, I believed that it was', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='I believed that it was so clear that axiomatization in terms of sets was not a satisfactory', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='sets was not a satisfactory ultimate foundation of mathematics that mathematicians would, for the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='mathematicians would, for the most part, not be very much concerned with it. But in recent times I', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='it. But in recent times I have seen to my surprise that so many mathematicians think that these', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='think that these axioms of set theory provide the ideal foundation for mathematics; therefore it', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='for mathematics; therefore it seemed to me that the time had come to publish a critique. (English', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='publish a critique. (English translation taken from van Heijenoort 1967, p. 300.)', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='As an aside, in the proof of the Löwenheim-Skolem theorem, specifically that part of the theorem in', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='that part of the theorem in which one constructs a model for a satisfiable sentence, Löwenheim and', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='sentence, Löwenheim and Skolem’s tree construction was more or less the same as appears in Gödel’s', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='same as appears in Gödel’s thesis. In a 1967 letter to Hao Wang, Gödel takes note of the fact that', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='takes note of the fact that his completeness proof had almost been obtained by Skolem in 1923.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='obtained by Skolem in 1923. Though van Heijenoort and Dreben (Dreben and van Heijenoort 1986)', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='and van Heijenoort 1986) remark that “Throughout much of the 1920s it was not semantic completeness', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='was not semantic completeness but the decision problem for quantificational validity, a problem', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='validity, a problem originating from the work of Schröder and Löwenheim, that was the dominant', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='that was the dominant concern in studying quantification theory” (examples of such results would', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='of such results would include the decision procedure for the first order monadic predicate calculus', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='monadic predicate calculus due to Behmann, (Behmann 1922)), according to Gödel, the reasons that', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='to Gödel, the reasons that Skolem did not obtain the complete proof are different and', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='proof are different and philosophically important, having to do with the then dominant bias against', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='then dominant bias against semantics and against infinitary methods:', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='The Completeness Theorem, mathematically, is indeed an almost trivial consequence of Skolem 1923.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='consequence of Skolem 1923. However, the fact is that, at that time, nobody (including Skolem', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='nobody (including Skolem himself) drew this conclusion neither from Skolem 1923 nor, as I did, from', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='1923 nor, as I did, from similar considerations of his own …This blindness (or prejudice, or', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='blindness (or prejudice, or whatever you may call it) of logicians is indeed surprising. But I', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='is indeed surprising. But I think the explanation is not hard to find. It lies in the widespread', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='It lies in the widespread lack, at that time, of the required epistemological attitude toward', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='attitude toward metamathematics and toward non-finitary reasoning. (Gödel 2003b).', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='The matter of Skolem’s contribution to the Completeness Theorem has been extensively discussed in', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='been extensively discussed in van Atten and Kennedy 2009, as well as in van Atten 2005.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem'}),\n",
       " Document(page_content='Gödel mentioned the possibility of the unsolvability of a question about the reals already in his', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='the reals already in his 1929 thesis, in arguing against the formalist principle of Hilbert’s, that', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='principle of Hilbert’s, that consistency is a criterion for existence. In fact, giving a finitary', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='In fact, giving a finitary proof of the consistency of analysis was a key desideratum of what was', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='a key desideratum of what was then known as the Hilbert program, along with proving its', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='along with proving its completeness. Accordingly it was Gödel’s turn to these questions, especially', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='these questions, especially the first, which led him to the two incompleteness theorems. (For a', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='theorems. (For a discussion of the Hilbert Program the reader is referred to the standard', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='is referred to the standard references: Sieg 1990, 1988, 1999; Mancosu 1998, Zach 2003, Tait 1981', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='1998, Zach 2003, Tait 1981 and Tait 2002.)', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='The First Incompleteness Theorem provides a counterexample to completeness by exhibiting an', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='completeness by exhibiting an arithmetic statement which is neither provable nor refutable in Peano', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='nor refutable in Peano arithmetic, though true in the standard model. The Second Incompleteness', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='The Second Incompleteness Theorem shows that the consistency of arithmetic cannot be proved in', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='cannot be proved in arithmetic itself. Thus Gödel’s theorems demonstrated the infeasibility of the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='the infeasibility of the Hilbert program, if it is to be characterized by those particular', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='by those particular desiderata, consistency and completeness.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='As an aside, von Neumann understood the two theorems this way, even before Gödel did. In fact von', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='before Gödel did. In fact von Neumann went much further in taking the view that they showed the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='the view that they showed the infeasibility of classical mathematics altogether. As he wrote to', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='altogether. As he wrote to Carnap in June of 1931:', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Thus today I am of the opinion that 1. Gödel has shown the unrealizability of Hilbert’s program. 2.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='of Hilbert’s program. 2. There is no more reason to reject intuitionism (if one disregards the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='(if one disregards the aesthetic issue, which in practice will also for me be the decisive factor).', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='me be the decisive factor). Therefore I consider the state of the foundational discussion in', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='foundational discussion in Königsberg to be outdated, for Gödel’s fundamental discoveries have', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='fundamental discoveries have brought the question to a completely different level.[9]', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='And the previous fall von Neumann had written to Gödel in even stronger terms:', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Thus, I think that your result has solved negatively the foundational question: there is no', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='question: there is no rigorous justification for classical mathematics. (Gödel 2003b, p. 339)', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='It would take Gödel himself a few years to see that those aspects of the Hilbert Program had been', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='the Hilbert Program had been decisively refuted by his results (Mancosu 2004).', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='In his Logical Journey (Wang 1996) Hao Wang published the full text of material Gödel had written', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='of material Gödel had written (at Wang’s request) about his discovery of the incompleteness', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='of the incompleteness theorems. This material had formed the basis of Wang’s “Some Facts about Kurt', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Wang’s “Some Facts about Kurt Gödel,” and was read and approved by Gödel:', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='In the summer of 1930 I began to study the consistency problem of classical analysis. It is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='of classical analysis. It is mysterious why Hilbert wanted to prove directly the consistency of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='directly the consistency of analysis by finitary methods. I saw two distinguishable problems: to', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='distinguishable problems: to prove the consistency of number theory by finitary number theory and', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='by finitary number theory and to prove the consistency of analysis by number theory … Since the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='by number theory … Since the domain of finitary number theory was not well-defined, I began by', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='not well-defined, I began by tackling the second half… I represented real numbers by predicates in', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='real numbers by predicates in number theory… and found that I had to use the concept of truth (for', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='use the concept of truth (for number theory) to verify the axioms of analysis. By an enumeration of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='By an enumeration of symbols, sentences and proofs within the given system, I quickly discovered', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='system, I quickly discovered that the concept of arithmetic truth cannot be defined in arithmetic.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='be defined in arithmetic. If it were possible to define truth in the system itself, we would have', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='system itself, we would have something like the liar paradox, showing the system to be', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='showing the system to be inconsistent… Note that this argument can be formalized to show the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='can be formalized to show the existence of undecidable propositions without giving any individual', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='without giving any individual instances. (If there were no undecidable propositions, all (and only)', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='propositions, all (and only) true propositions would be provable within the system. But then we', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='the system. But then we would have a contradiction.)… In contrast to truth, provability in a given', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='truth, provability in a given formal system is an explicit combinatorial property of certain', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='property of certain sentences of the system, which is formally specifiable by suitable elementary', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='by suitable elementary means…', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='We see that Gödel first tried to reduce the consistency problem for analysis to that of arithmetic.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='to that of arithmetic. This seemed to require a truth definition for arithmetic, which in turn led', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='arithmetic, which in turn led to paradoxes, such as the Liar paradox (“This sentence is false”) and', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='sentence is false”) and Berry’s paradox (“The least number not defined by an expression consisting', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='by an expression consisting of just fourteen English words”). Gödel then noticed that such', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Gödel then noticed that such paradoxes would not necessarily arise if truth were replaced by', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='if truth were replaced by provability. But this means that arithmetic truth and arithmetic', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='truth and arithmetic provability are not co-extensive — whence the First Incompleteness Theorem.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='This account of Gödel’s discovery was told to Hao Wang very much after the fact; but in Gödel’s', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='the fact; but in Gödel’s contemporary correspondence with Bernays and Zermelo, essentially the same', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Zermelo, essentially the same description of his path to the theorems is given. (See Gödel 2003a', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='is given. (See Gödel 2003a and Gödel 2003b respectively.) From those accounts we see that the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='accounts we see that the undefinability of truth in arithmetic, a result credited to Tarski, was', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='credited to Tarski, was likely obtained in some form by Gödel by 1931. But he neither publicized', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='But he neither publicized nor published the result; the biases logicians had expressed at the time', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='had expressed at the time concerning the notion of truth, biases which came vehemently to the fore', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='came vehemently to the fore when Tarski announced his results on the undefinability of truth in', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='undefinability of truth in formal systems 1935, may have served as a deterrent to Gödel’s', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='as a deterrent to Gödel’s publication of that theorem.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='We now describe the proof of the two theorems, formulating Gödel’s results in Peano arithmetic.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='results in Peano arithmetic. Gödel himself used a system related to that defined in Principia', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='to that defined in Principia Mathematica, but containing Peano arithmetic. In our presentation of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='In our presentation of the First and Second Incompleteness Theorems we refer to Peano arithmetic as', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='refer to Peano arithmetic as P, following Gödel’s notation.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Before proceeding to the details of the formal proof, we define the notion of ω-consistency used by', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='of ω-consistency used by Gödel in the First Incompleteness Theorem: P is ω-consistent if P ⊢ ¬φ(n)', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='is ω-consistent if P ⊢ ¬φ(n) for all n implies P ⊬ ∃xφ(x). Naturally this implies consistency and', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='this implies consistency and follows from the assumption that the natural numbers satisfy the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='natural numbers satisfy the axioms of Peano arithmetic.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='One of the main technical tools used in the proof is Gödel numbering, a mechanism which assigns', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='a mechanism which assigns natural numbers to terms and formulas of our formal theory P. There are', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='formal theory P. There are different ways of doing this. The most common is based on the unique', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='common is based on the unique representation of natural numbers as products of powers of primes.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='products of powers of primes. Each symbol s of number theory is assigned a positive natural number', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='a positive natural number #(s) in a fixed but arbitrary way, e.g.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='#(0) = 1 #(=) = 5 #(¬) = 9 #(1) = 2 #(\\u2009(\\u2009) = 6 #(∀) = 10 #(+) = 3 #(\\u2009)\\u2009) = 7 #(vi) = 11 + i #(×) =', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='= 7 #(vi) = 11 + i #(×) = 4 #(∧) = 8', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='The natural number corresponding to a sequence w = < w0,…, wk > of symbols is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='⌈w⌉ = 2#(w0) · 3#(w1) · … · pk#(wk),', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='where pk is the k+1st prime. It is called its Gödel number and denoted by ⌈w⌉. In this way we can', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='by ⌈w⌉. In this way we can assign Gödel numbers to formulas, sequences of formulas (once a method', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='of formulas (once a method for distinguishing when one formula ends and another begins has been', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='and another begins has been adopted), and most notably, proofs.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='An essential point here is that when a formula is construed as a natural number, then the numeral', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='number, then the numeral corresponding to that natural number can occur as the argument of a', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='occur as the argument of a formula, thus enabling the syntax to “refer” to itself, so to speak', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='to itself, so to speak (i.e., when a numeral is substituted into a formula the Gödel number of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='a formula the Gödel number of which the numeral represents). This will eventually allow Gödel to', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='eventually allow Gödel to formalize the Liar paradox (with “provability” in place of “truth”) by', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='in place of “truth”) by substituting into the formula which says, ‘the formula, whose code is x, is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='formula, whose code is x, is unprovable,’ its own natural number code (or more precisely the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='code (or more precisely the corresponding numeral).', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Another concept required to carry out the formalization is the concept of numeralwise', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='is the concept of numeralwise expressibility of number theoretic predicates. A number-theoretic', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='A number-theoretic formula φ(n1, …, nk) is numeralwise expressible in P if for each tuple of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='in P if for each tuple of natural numbers (n1, …, nk):', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='N ⊨ φ(n1, …, nk) ⇒ P ⊢ φ(n1, …, nk) N ⊨ ¬φ(n1, …, nk) ⇒ P ⊢ ¬φ(n1, …, nk)', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='where n is the formal term which denotes the natural number n. (In P, this is S(S(…S(0)…), where n', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='this is S(S(…S(0)…), where n is the number of iterations of the successor function applied to the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='function applied to the constant symbol 0.) One of the principal goals is to numeralwise express', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='is to numeralwise express the predicate', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Prf(x, y): ‘the sequence with Gödel number x is a proof of the sentence with Gödel number y.’', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Reaching this goal involves defining forty-five relations, each defined in terms of the preceding', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='in terms of the preceding ones. These relations are all primitive recursive.[10] Relations needed', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Relations needed are, among others, those which assert of a natural number that it codes a', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='number that it codes a sequence, or a formula, or an axiom, or that it is the code, denoted by', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='it is the code, denoted by Sb(ru1…unZ(x1)…Z(xn)), of a formula obtained from a formula with code r', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='from a formula with code r by substituting for its free variable ui the xi th numeral for i = 1, …,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='xi th numeral for i = 1, …, n. The forty-fifth primitive recursive relation defined is Prf(x, y),', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='defined is Prf(x, y), and the forty-sixth is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Prov(y): ‘the sentence with Gödel number y is provable in P’', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='which without being primitive recursive, is however obtained from Prf(x, y) by existentially', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Prf(x, y) by existentially quantifying x. (Prov(y) satisfies only the ‘positive’ part of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='only the ‘positive’ part of numeralwise expressibility, and not the negative part; but the negative', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='part; but the negative part is not needed.)', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='In Theorem V of his paper, Gödel proves that any number theoretic predicate which is primitive', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='predicate which is primitive recursive is numeralwise expressible in P. Thus since Prf(x, y) and', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='P. Thus since Prf(x, y) and substitution are primitive recursive, these are decided by P when', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='these are decided by P when closed terms are substituted for the free variables x and y. This is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='variables x and y. This is the heart of the matter as we will see. Another key point about', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='see. Another key point about numeralwise expressibility is that although we informally interpret,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='we informally interpret, for example, Prov(Sb(ru1…unZ(x1)…Z(xn))), by: ‘the formula with Gödel', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='by: ‘the formula with Gödel number r is provable if the Gödel number for the xi th numeral is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='for the xi th numeral is substituted in place of the i th variable,’ neither the formal statement', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='neither the formal statement within the theory P nor anything we prove about it appeals to such', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='about it appeals to such meanings. On the contrary Prov(Sb(ru1…unZ(x1)…Z(xn))), is a meaningless', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='is a meaningless string of logical and arithmetical symbols. As Gödel puts it in his introduction', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='puts it in his introduction to his theorem V, ‘The fact that can be formulated vaguely by saying', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='formulated vaguely by saying that every recursive relation is definable in the system P (if the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='in the system P (if the usual meaning is given to the formulas of this system) is expressed in', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='this system) is expressed in precise language, without reference to any interpretation of the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='to any interpretation of the formulas of P, by the following Theorem (V) (Gödel 1986, p. 171,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='(V) (Gödel 1986, p. 171, italics Gödel’s).', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Gödel in his incompleteness theorems uses a method given in what is called nowadays Gödel’s Fixed', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='called nowadays Gödel’s Fixed Point Theorem. Although Gödel constructs a fixed point in the course', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='a fixed point in the course of proving the incompleteness theorem, he does not state the fixed', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='he does not state the fixed point theorem explicitly. The fixed point theorem is as follows:', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Theorem 2 (Gödel’s Fixed Point Theorem) If φ(v0) is a formula of number theory, then there is a', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='theory, then there is a sentence ψ such that P ⊢ ψ ↔ φ(⌈ψ⌉), where ⌈ψ⌉ is the formal term', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='where ⌈ψ⌉ is the formal term corresponding to the natural number code of ⌈ψ⌉.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Proof: Let σ(x,y,z) be a formula that numeralwise expresses the number theoretic predicate ‘y is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='theoretic predicate ‘y is the Gödel number of the formula obtained by replacing the variable v0 in', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='replacing the variable v0 in the formula whose Gödel number is x by the term z’. Let θ(v0) be the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='the term z’. Let θ(v0) be the formula ∃v1(φ(v1) ∧ σ(v0, v1, v0)). Let k = ⌈θ(v0)⌉ and ψ = θ(k). Now', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='k = ⌈θ(v0)⌉ and ψ = θ(k). Now directly by the construction P ⊢ ψ ↔ φ(⌈ψ⌉).', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='A sentence is refutable from a theory if its negation is provable. The First Incompleteness Theorem', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='First Incompleteness Theorem as Gödel stated it is as follows:', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Theorem 3 (Gödel’s First Incompleteness Theorem) If P is ω-consistent, then there is a sentence', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='then there is a sentence which is neither provable nor refutable from P.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Proof: By judicious coding of syntax referred to above, write a formula Prf(x,y)[11] of number', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Prf(x,y)[11] of number theory, representable in P, so that', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='n codes a proof of φ ⇒ P ⊢ Prf(n, ⌈φ⌉).  \\nand  \\nn does not code a proof of φ ⇒ P ⊢ ¬Prf(n, ⌈φ⌉).', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Let Prov(y) denote the formula ∃x Prf(x,y)[12]. By Theorem 2 there is a sentence φ with the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='is a sentence φ with the property', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='P ⊢ (φ ↔ ¬Prov(⌈φ⌉)).', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Thus φ says ‘I am not provable.’ We now observe, if P ⊢ φ, then by (1) there is n such that P ⊢', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='(1) there is n such that P ⊢ Prf(n, ⌈φ⌉), hence P ⊢ Prov(⌈φ⌉), hence, by (3) P ⊢ ¬φ, so P is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='hence, by (3) P ⊢ ¬φ, so P is inconsistent. Thus', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='P ⊬ φ', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Furthermore, by (4) and (2), we have P ⊢ ¬Prf(n, ⌈φ⌉) for all natural numbers n. By ω-consistency P', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='numbers n. By ω-consistency P ⊬ ∃x Prf(x, ⌈φ⌉). Thus (3) gives P ⊬ ¬φ. We have shown that if P is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='We have shown that if P is ω-consistent, then φ is independent of P.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='On concluding the proof of the first theorem, Gödel remarks, “we can readily see that the proof', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='readily see that the proof just given is constructive; that is … proved in an intuitionistically', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='in an intuitionistically unobjectionable manner…” (Gödel 1986, p. 177). This is because, as he', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='177). This is because, as he points out, all the existential statements are based on his theorem V', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='are based on his theorem V (giving the numeralwise expressibility of primitive recursive', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='of primitive recursive relations), which is intuitionistically unobjectionable.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='The Second Incompleteness Theorem establishes the unprovability, in number theory, of the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='in number theory, of the consistency of number theory. First we have to write down a', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='First we have to write down a number-theoretic formula that expresses the consistency of the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='the consistency of the axioms. This is surprisingly simple. We just let Con(P) be the sentence', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='let Con(P) be the sentence ¬Prov(⌈0 = 1⌉).', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Theorem 4 (Gödel’s Second Incompleteness Theorem) If P is consistent, then Con(P) is not provable', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='then Con(P) is not provable from P.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Proof: Let φ be as in (3). The reasoning used to infer ‘if P ⊢ φ, then P ⊢ 0 ≠ 1‘ does not go', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='then P ⊢ 0 ≠ 1‘ does not go beyond elementary number theory, and can therefore, albeit with a lot', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='therefore, albeit with a lot of effort (see below), be formalized in P. This yields: P ⊢ (Prov(⌈φ⌉)', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='This yields: P ⊢ (Prov(⌈φ⌉) → ¬Con(P)), and thus by (3), P ⊢ (Con(P) → φ). Since P ⊬ φ, we must', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='→ φ). Since P ⊬ φ, we must have P ⊬ Con(P).', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='The above proof (sketch) of the Second Incompleteness Theorem is deceptively simple as it avoids', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='simple as it avoids the formalization. A rigorous proof would have to establish the proof of ‘if P', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='establish the proof of ‘if P ⊢ φ, then P ⊢ 0 ≠ 1’ in P.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='It is noteworthy that ω-consistency is not needed in the proof of Gödel’s Second Incompleteness', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Gödel’s Second Incompleteness Theorem. Also note that neither is ¬Con(P) provable, by the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='is ¬Con(P) provable, by the consistency of P and the fact, now known as Löb’s theorem, that P ⊢', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='as Löb’s theorem, that P ⊢ Prov(⌈φ⌉) implies P ⊢ φ.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='The assumption of ω-consistency in the First Incompleteness Theorem was eliminated by Rosser in', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='was eliminated by Rosser in 1936, and replaced by the weaker notion of consistency. Rosser’s', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='of consistency. Rosser’s generalization involves applying the fixed point theorem to the formula', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='point theorem to the formula R(x): ‘for all z: either z is not the Gödel number of a proof of the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='number of a proof of the formula with Gödel number x or there is a proof shorter than z of the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='a proof shorter than z of the negation of (the formula with Gödel number) x’ (see Rosser 1936).', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='With regard to the Second Incompleteness Theorem, the argument relies in part on formalizing the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='in part on formalizing the proof of the First Incompleteness Theorem as we saw. This step is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='as we saw. This step is omitted in Gödel 1931. He planned to include the step in what would have', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='the step in what would have been a second part II (see footnote 48a of Gödel 1931). But instead of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Gödel 1931). But instead of writing it he turned to the continuum problem.[13] (Part II was to', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='problem.[13] (Part II was to elaborate on other points too: the ‘true reason for incompleteness,’', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='reason for incompleteness,’ and the applicability of the two theorems to other systems.) He perhaps', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='to other systems.) He perhaps did not feel compelled to attend to what looked like an exercise in', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='looked like an exercise in formalization, relying instead on the informal argument to convince (in', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='argument to convince (in which it succeeded). However this step turned out to be somewhat', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='turned out to be somewhat non-trivial. As Kleene puts it in his introduction to Gödel 1931, of the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='to Gödel 1931, of the informal presentation, “Certainly the idea of the argument for Theorem XI', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='the argument for Theorem XI (consistency) was very convincing; but it turned out that the execution', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='turned out that the execution of the details required somewhat more work and care than had been', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='work and care than had been anticipated.” (See pp. 126–141 of Gödel 1986.) Eventually a complete', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='1986.) Eventually a complete proof of the Second Theorem was given by Hilbert and Bernays in some', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Hilbert and Bernays in some seventy pages in their Hilbert and Bernays 1939. A much more compact', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='1939. A much more compact treatment of the theorem was given by Löb in his Löb 1956, and', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='by Löb in his Löb 1956, and subsequently Feferman, in his 1960 “Arithmetization of Metamathematics', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='of Metamathematics in a General Setting” (Feferman 1960/1961), gave a succinct and completely', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='a succinct and completely general treatment of both the First and Second Theorems. But see the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Second Theorems. But see the supplementary document:', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Did the Incompleteness Theorems Refute Hilbert’s Program?', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='For more detailed discussion, see the entry on Gödel’s incompleteness theorems.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}),\n",
       " Document(page_content='Gödel’s 1936 ‘Speed-up’ theorem, published in an abstract “On the length of proofs”, Gödel 1936 says', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='of proofs”, Gödel 1936 says that while some sentences of arithmetic are true but unprovable, there', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='true but unprovable, there are other sentences which are provable, but even the shortest proof is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='even the shortest proof is longer than any bound given in advance as a recursive function of the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='a recursive function of the sentence. More exactly:', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='Theorem 5. Given any recursive function f there are provable sentences φ of arithmetic such that', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='φ of arithmetic such that the shortest proof is greater than f(⌈φ⌉) in length.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='The proof we will outline is sensitive to the particular concept we use for the length of a proof.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='for the length of a proof. Another possibility, and the one that Gödel has in mind, is the number', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='has in mind, is the number of formulas in the proof. Buss (see below) proves the theorem in either', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='proves the theorem in either case, so both cases are resolved.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='Proof: Let f be total recursive function. By Gödel’s Fixed Point theorem there is a formula φ(n)', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='there is a formula φ(n) stating ‘φ(n) has no proof in PA shorter than f(n)’. This is tenable if the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='f(n)’. This is tenable if the length is measured by number of symbols, because we only need to', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='because we only need to search through finitely many proofs shorter than f(n). Note that φ(n) is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='than f(n). Note that φ(n) is true for all n, for if φ(n) were false, then there would be a short', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='then there would be a short proof of φ(n), and hence by soundness φ(n) would be true, a', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='φ(n) would be true, a contradiction: φ(n) would both true and false. This can be formalized in PA', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='This can be formalized in PA and thus we get the result that for each n the sentence φ(n) is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='each n the sentence φ(n) is provable in PA. Since φ(n) is true for all n, it cannot have a proof in', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='n, it cannot have a proof in PA which is shorter than f(n).', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='The Speed-up Theorem is the result of contemplating and elaborating the proof of the incompleteness', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='proof of the incompleteness theorem. It applies the fixed-point technique to the concept of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='technique to the concept of unprovability by a short proof, as opposed to the original idea of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='to the original idea of applying the fixed-point theorem to mere unprovability. The proof has very', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='The proof has very much the same flavor as the proof of the incompleteness theorem. Interestingly,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='theorem. Interestingly, it dates from the same year as the construction, due to Rosser, that', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='due to Rosser, that eliminates the use of ω-consistency in the first Incompleteness Theorem; like', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='Incompleteness Theorem; like the Speed-up Theorem of Gödel, Rosser’s construction exploits the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='construction exploits the issue of short and long proofs. Gödel never submitted a proof for the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='submitted a proof for the Speed-up Theorem. Over the years several related proofs were published,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='proofs were published, but the first full proof of Gödel’s original result was given only in 1994', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='result was given only in 1994 by Sam Buss in his ‘On Gödel’s theorems on lengths of proofs I:', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='on lengths of proofs I: Number of lines and speedups for arithmetic.’ (Buss 1994). Buss also gives', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='(Buss 1994). Buss also gives a second proof of the theorem which avoids self-reference, following a', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='self-reference, following a technique due to Statman. Gödel measures the length of proofs by the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='the length of proofs by the number of formulas; but there are also other possibilities, such as the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='possibilities, such as the number of symbols in the proof. The case of the Speed-up Theorem where', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='of the Speed-up Theorem where the length of proof is measured by the number of symbols was proved', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='number of symbols was proved by Mostowski in 1952 (Mostowski 1982). For proofs of similar results', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='For proofs of similar results see Ehrenfeucht and Mycieleski 1971, and Parikh 1971. Though both', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='and Parikh 1971. Though both measures may be equally natural candidates for measuring the length of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='for measuring the length of a proof, proving the theorem for length measured by the number of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='measured by the number of symbols avoids a technical complication introduced by the other measure:', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='by the other measure: there are only finitely many proofs with a given number of symbols, whereas', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='number of symbols, whereas there are infinitely many proofs with a given number of formulas.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='Gödel states the Speed-up Theorem differently from the above. Let Sn be the system of logic of the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='be the system of logic of the n-th order, the variables of the first level being thought of as', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='level being thought of as ranging over natural numbers. In this setting, variables of the second', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='variables of the second level range over sets of natural numbers and so on. Gödel’s formulation is:', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='on. Gödel’s formulation is:', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='Theorem 6. Let n be a natural number > 0. If f is a computable function, then there are infinitely', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='then there are infinitely many formulas A, provable in Sn, such that if k is the length of the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='if k is the length of the shortest proof of A in Sn and l is the length of the shortest proof of A', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='of the shortest proof of A in Sn+1, then k > f(l).', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='Proof sketch: The idea is the following: Let φ(x) be a formula, like above, for which φ(m) does not', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='for which φ(m) does not have a short proof in Sn for any m. Suppose we have a higher type system', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='we have a higher type system Sn+1 in which we can prove ∀xφ(x). This proof is of constant length.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='proof is of constant length. Thus each φ(m) is derivable from this universal statement by one', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='universal statement by one application of the logical rule ∀xφ(x) → φ(t). Thus φ(m) has in that', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='→ φ(t). Thus φ(m) has in that system for all m a short proof.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='What kind of stronger system can we have in which ∀xφ(x) is provable? We may consider second order', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='We may consider second order logic in which we can define a predicate N(x) for the set of natural', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='N(x) for the set of natural numbers and furthermore can prove of a new predicate symbol Tr(x) that', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='predicate symbol Tr(x) that it satisfies the inductive clauses of the truth definition of first', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='the truth definition of first order formulas of arithmetic, relativized to N. Then the stronger', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='to N. Then the stronger system can prove that provable first order sentences of arithmetic satisfy', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='of arithmetic satisfy the predicate Tr . By the above argument, we can prove in the stronger system', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='prove in the stronger system that ∀xφ(x) satisfies Tr. Then by adding a few lines we can prove each', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='a few lines we can prove each φ(n) satisfies Tr. Because of the nature of φ(n), this implies the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='of φ(n), this implies the stronger system has a (short) proof of φ(n). An alternative system is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='An alternative system is Peano’s axioms PA in an extended language where we have a new predicate', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='where we have a new predicate symbol Tr and axioms stating that the predicate Tr codes the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='the predicate Tr codes the satisfaction relation for all sentences of the vocabulary not containing', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='the vocabulary not containing Tr.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}),\n",
       " Document(page_content='Gödel’s proof of the consistency of the continuum hypothesis with the axioms of Zermelo-Fraenkel set', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='of Zermelo-Fraenkel set theory is a tour de force and arguably the greatest achievement of his', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='greatest achievement of his mathematical life. This is because aside from the arithmetization,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='from the arithmetization, virtually all of the technical machinery used in the proof had to be', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='used in the proof had to be invented ab initio.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='The Continuum Hypothesis (henceforth CH) was formulated by Georg Cantor, and was the first problem', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='and was the first problem on Hilbert’s list of twenty-three unsolved problems as given in his', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='problems as given in his famous address to the International Mathematical Congress in Paris in', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='Congress in Paris in 1900. The problem as stated by Hilbert is as follows: Let A be an infinite set', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='Let A be an infinite set of real numbers. Then A is either countable, or has cardinality 2ℵ0, i.e.,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='or has cardinality 2ℵ0, i.e., A is in one-to-one correspondence either with the set of natural', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='with the set of natural numbers or with the set of all real numbers (otherwise known as the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='(otherwise known as the continuum). Another way to state the continuum hypothesis is that (the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='hypothesis is that (the first uncountably infinite cardinal) ℵ1 = 2ℵ0.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='As early as 1922 Skolem speculated that the CH was independent of the axioms for set theory given', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='axioms for set theory given by Zermelo in 1908. Nevertheless Hilbert published a (false) proof of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='published a (false) proof of the CH in Hilbert 1926. In 1937 Gödel proved its consistency with the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='its consistency with the axioms of ZF set theory. (Henceforth we use the standard abbreviations for', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='standard abbreviations for Zermelo-Fraenkel set theory, ZF, and Zermelo-Fraenkel set theory with', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='set theory with the Axiom of Choice, ZFC.) The consistency of the negation of the CH was shown by', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='of the CH was shown by Paul Cohen in 1961 (see Cohen 1963) and hence together with Gödel’s result', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='together with Gödel’s result one infers that the CH is independent of ZF (and ZFC).', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='Cohen invented an important new technique called forcing in the course of proving his result; this', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='of proving his result; this technique is at present the main method used to construct models of set', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='to construct models of set theory. Forcing led to a revival of formalism among set theorists, the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='among set theorists, the plurality of models being an indication of the “essential variability in', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='the “essential variability in set theory,” (Dehornoy 2004) and away from the notion that there is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='from the notion that there is an intended model of set theory—a perspective Gödel advocated since', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='Gödel advocated since at least 1947, if not earlier.[14] Recently there have been signs that the CH', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='have been signs that the CH may again be coming to be regarded as a problem to be solved', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='as a problem to be solved mathematically (with the help of course of some new evident axioms', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='of some new evident axioms extending ZF). (See for example Woodin 2001a, 2002, 2001b, and Foreman', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='2002, 2001b, and Foreman 1998.) If any of the proposed solutions gain acceptance, this would', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='gain acceptance, this would confirm Gödel’s view that the CH would eventually be decided by finding', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='be decided by finding an evident extension of the ZF axioms for set theory. The program associated', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='The program associated with this view is called “Gödel’s Large Cardinal Program.”', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='The continuum problem is shown to be consistent with ZF by finding an enumeration of the reals', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='an enumeration of the reals which is indexed by the countable ordinals, a strategy which had been', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='a strategy which had been recognized as a promising one already by Hilbert.[15] The problem, and', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='Hilbert.[15] The problem, and the intuition behind the proof, is to build a “small” model, one in', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='build a “small” model, one in which the absolute minimum number of reals is allowed, while at the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='is allowed, while at the same time the model is large enough to be closed under all the operations', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='under all the operations the ZF axioms assert to exist.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='Gödel’s is a relative consistency proof, obtained by constructing a so-called “inner model” for ZF', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='“inner model” for ZF together with the CH. An inner model is a subcollection M of the collection V', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='M of the collection V of all sets (see below) which satisfies the axioms of ZF when only sets in M', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='of ZF when only sets in M are considered. Gödel’s inner model is called the inner model of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='is called the inner model of constructible sets (see below) and is denoted by L. Whatever is true', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='by L. Whatever is true in an inner model is consistent with ZF for the same reason that any theory', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='same reason that any theory with a model is consistent. An artifact of the construction is that the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='the construction is that the Axiom of Choice (henceforth AC) is satisfied in Gödel’s inner model', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='in Gödel’s inner model and hence the consistency of the AC with ZF was established by Gödel. Later', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='established by Gödel. Later on it was shown by Sierpinski that the AC is actually a consequence of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='is actually a consequence of the Generalized Continuum Hypothesis or the GCH, which states that for', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='GCH, which states that for each κ, 2κ = κ+ (see Sierpinski 1947).', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='Gödel published two versions of these theorems, in 1939 and in 1940, entitled “Consistency Proof', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='entitled “Consistency Proof for the Generalized Continuum Hypothesis,” and “The Consistency of the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='and “The Consistency of the Axiom of Choice and of the Generalized Continuum Hypothesis with the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='Continuum Hypothesis with the Axioms of Set Theory,” respectively. Though completely definitive,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='Though completely definitive, the 1939 version is lacking in a great many details, most notably the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='details, most notably the arguments showing that if L is built inside L itself, the same L results;', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='L itself, the same L results; that is to say, the so-called absoluteness arguments are missing.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='arguments are missing. Also missing are the details of the proofs that the ZF axioms hold in L.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='that the ZF axioms hold in L. Unlike the case of the Second Incompleteness Theorem, however, Gödel', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='Theorem, however, Gödel subsequently gave a completely detailed proof of the two theorems in the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='of the two theorems in the 1940 monograph. (The 1940 proof differs substantially from the first', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='substantially from the first version. For details about the two proofs and the difference between', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='and the difference between them the reader is referred to Solovay 1990 and Kanamori 2006.)', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='We now sketch the proof of the consistency of CH and of AC with ZFC, using modern terminology. Some', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='modern terminology. Some preliminary concepts before sketching the proof: We first define the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='proof: We first define the stratified set theoretic universe, denoted V. (V is also known as the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='V. (V is also known as the cumulative hierarchy.) It is obtained by iteration of the power set', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='by iteration of the power set operation (℘) beginning with the null set:', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='V0 = ∅, Vα+1 = ℘(Vα), Vγ = ∪β<γ Vβ,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='where α, β are any ordinals, γ is a limit ordinal and ℘(x) denotes the power set of x. Finally', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='V = ∪α∈Ord Vα,  \\nwhere Ord denotes the class of all ordinals.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='The constructible hierarchy L is likewise defined by recursion on ordinals. But whereas the full', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='But whereas the full power set operation is iterated to obtain the cumulative hierarchy, the levels', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='hierarchy, the levels of the constructible hierarchy are defined strictly predicatively, that is by', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='predicatively, that is by including at the next level only those sets which are first order', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='sets which are first order definable using parameters from the previous level. More exactly, let', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='level. More exactly, let Def(A) denote the set of all subsets of A definable in the structure < A,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='in the structure < A, ∈ > by first order formulas with parameters in A. (For more on definability', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='A. (For more on definability see the entry on model theory in this encyclopedia.)', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='With this notation the constructible hierarchy is defined by induction over the ordinals as', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='over the ordinals as follows:', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='L0 = ∅, Lα+1 = Def(Lα), Lγ = ∪α<γ Lα, L = ∪α∈Ord Lα,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='A set x is said to be constructible if x ∈ L. The axiom which states that all sets are', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='states that all sets are constructible is denoted V = L and is called the Axiom of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='L and is called the Axiom of Constructibility. Note that L is a proper class and not a set;', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='a proper class and not a set; although as we will see, each Lα is a set, and the predicate “x is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='set, and the predicate “x is constructible” is actually a definable term of the language.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='Our next task is to show that L is a model of ZF. A set or a class is transitive if elements of it', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='transitive if elements of it are also subsets. By a meticulous transfinite induction, Lα can be', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='induction, Lα can be shown to be transitive for each α; and therefore so is L itself. This fact,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='so is L itself. This fact, together with the observation that some elementary closure properties', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='elementary closure properties hold in L [16] is enough to show that L is a model of ZF. (Indeed, as', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='is a model of ZF. (Indeed, as it turns out, L is the minimal transitive model of the ZF axioms', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='model of the ZF axioms containing all the ordinals, and is therefore in this sense canonical.)', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='In detail, proving that the ZF axioms, apart from the comprehension axiom, are true in L, amounts', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='axiom, are true in L, amounts to showing that, roughly speaking, any set with a property P that a', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='set with a property P that a ZF axiom asserts to exist, can be seen to exist in L by considering', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='to exist in L by considering the relativization PL of the property P to L. (A property P is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='P to L. (A property P is relativized to an inner model M by replacing every quantifier ∃xφ by ∃x(x', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='every quantifier ∃xφ by ∃x(x ∈ M ∧ φ) and every quantifier ∀xφ by ∀x(x ∈ M→ φ).) As for the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='by ∀x(x ∈ M→ φ).) As for the comprehension axiom, verifying it requires showing that the set', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='requires showing that the set asserted to exist is constructed at a particular successor level Lα +', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='successor level Lα + 1. Proving this requires an important principle of set theory which in modern', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='of set theory which in modern terminology is called the Levy (or ZF) Reflection Principle. This', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='Reflection Principle. This principle says that any statement in the language of ZF which is true in', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='of ZF which is true in V is already true on some level of any continuously increasing hierarchy', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='increasing hierarchy such as L. (For the history of this principle, see Kanamori 2006.) The Levy', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='see Kanamori 2006.) The Levy Reflection Principle gives the level α at which the elements of the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='at which the elements of the set are all constructed. Gödel did not actually have the Levy', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='not actually have the Levy Reflection Principle but used the argument behind the proof of the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='behind the proof of the principle.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='Once it is established that L is a model of ZF, one can now prove that both the CH and the AC hold', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='both the CH and the AC hold in L. To this end, one first shows that the definition of L is absolute', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='definition of L is absolute for L, where absoluteness is defined as follows: given a class M, a', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='follows: given a class M, a predicate P(x) is said to be absolute for M if and only if for all x ∈', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='M if and only if for all x ∈ M, P(x) ↔ PM(x).', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='Proving that the predicate “x is constructible” is absolute requires formalizing the notion of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='formalizing the notion of definability, which in turn requires formalizing the notion of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='formalizing the notion of satisfaction. This is because the predicate “x is constructible” says of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='“x is constructible” says of a set, that for some ordinal α, and for some formula φ with parameters', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='formula φ with parameters in Lα, x = {y ∈ Lα | Lα ⊨ φ(y)}. This part of the proof is tedious but', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='of the proof is tedious but unproblematic.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='Once the absoluteness of L is established, it follows that ZF satisfies the axiom of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='ZF satisfies the axiom of constructibility if it is relativized to L; that is, ZF ⊢ (V=L)L. In', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='L; that is, ZF ⊢ (V=L)L. In particular, the axiom V = L is consistent if ZF is.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='We now give the idea of the proof of CH and AC in ZF + V = L. (For a detailed exposition of the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='a detailed exposition of the proof, the reader is referred to the standard sources. See for example', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='sources. See for example Devlin’s chapter on constructibility in Barwise 1977; see also Kunen 1983,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='1977; see also Kunen 1983, and Jech 2003.)', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='As concerns the CH, the idea behind the proof of it in L is simply the following: Gödel showed that', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='following: Gödel showed that assuming V = L, every real number occurs on some countable level of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='on some countable level of the L-hierarchy. Since every countable level is itself countable (after', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='is itself countable (after all, there are only countably many possible defining formulas), and', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='defining formulas), and there are ω1 countable levels, there must be only ω1 real numbers.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='The difficulty here, if not of the whole proof altogether, lies in showing that every real is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='in showing that every real is constructed already on a countable level of the L-hierarchy. To show', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='of the L-hierarchy. To show this Gödel argued as follows: Suppose A is a real number thought of as', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='a real number thought of as a set of natural numbers. By a combination of the Levy Reflection', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='of the Levy Reflection principle and the Löwenheim-Skolem Theorem there is a countable submodel <', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='is a countable submodel < M, ∈ > of < L, ∈ > satisfying a sufficiently large finite part of the ZF', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='large finite part of the ZF axioms + V = L, such that A belongs to M. By a simple procedure < M, ∈', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='By a simple procedure < M, ∈ > can be converted into a transitive model < N, ∈ >. This procedure,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='< N, ∈ >. This procedure, used by Gödel already in 1937, was explicitly isolated by Mostowski', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='isolated by Mostowski (Mostowski 1949). The resulting model is referred to as the Mostowski', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='referred to as the Mostowski Collapse.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='Let us pause to discuss this important technique. Suppose < M, E> is a well-founded model of the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='a well-founded model of the axiom of extensionality. It is a consequence of the well-foundedness of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='of the well-foundedness of the binary predicate E on M, and of the principle of transfinite', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='the principle of transfinite recursion, that the equation π(x) = {π(y)\\u2009|\\u2009y ∈ M ∧ yEx} defines a', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='∈ M ∧ yEx} defines a unique function on M. The range N of π is transitive, for if π(a) ∈ N and y ∈', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='for if π(a) ∈ N and y ∈ π(a), then y = π(b) for some b ∈ M with bEa, whence π(b) ∈ N. The fact that', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='π(b) ∈ N. The fact that π is an isomorphism between < M, E> and < N, ∈ > can be proved by', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='and < N, ∈ > can be proved by transfinite induction on elements on M, based again on the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='on M, based again on the well-foundedness of E. The well-foundedness of < M, E> is in practice', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='of < M, E> is in practice often the consequence of < M, E> being a submodel of some < Vα, ε >.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='We now return to the proof of the CH in L. We used the Mostowski Collapse to construct the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='Collapse to construct the transitive set N. As it turns out, the real number A is still an element', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='number A is still an element of < N, ∈ > . By basic properties of L, < N, ∈ > must be < Lα , ∈ >', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='< N, ∈ > must be < Lα , ∈ > for some α . Since N is countable, α is countable too. (It can be shown', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='too. (It can be shown that |Lα| = |α| + ℵ0.) Thus A is constructible on a countable level, which', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='on a countable level, which was to have been shown.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='As for the AC, Gödel exhibits a definable well-ordering, that is, a formula of set theory which', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='a formula of set theory which defines, in L, a well-ordering of all of L. The formula is tedious to', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='L. The formula is tedious to write down but the idea is a simple one: A set x precedes a set y in', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='A set x precedes a set y in the well-ordering if and only if either x occurs in the L-hierarchy on', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='occurs in the L-hierarchy on an earlier level Lα than y, or else they occur on the same level but x', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='occur on the same level but x is defined by a shorter formula than y, or else they are defined by', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='or else they are defined by the same formula but the parameters in the definition of x occur in L', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='definition of x occur in L earlier than the parameters of y. This well-ordering of L shows that the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='of L shows that the AC holds in L.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='This concludes the proof of the consistency of AC and the CH in L.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='We note that Gödel proved more in his 1939 and 1940 than what was shown here, namely he proved the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='here, namely he proved the Generalized Continuum Hypothesis in L and hence that its consistency', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='hence that its consistency with ZF.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='As noted above, it was suggested already in the 1920s that the CH might be independent of ZF or', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='might be independent of ZF or ZFC. After first conjecturing that the Axiom of Constructibility', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='the Axiom of Constructibility might be “absolutely consistent,” meaning not falsifiable by any', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='not falsifiable by any further extension of models of ZF + V = L,[17] in his 1947 “What is Cantor’s', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='in his 1947 “What is Cantor’s Continuum Hypothesis?” Gödel conjectured that the CH would be shown', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='that the CH would be shown to be independent. The main consequence of Gödel’s result, then, as far', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='Gödel’s result, then, as far as the problem of proving the independence of the CH is concerned, was', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='of the CH is concerned, was that it pointed mathematicians in the direction of adding', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='in the direction of adding non-constructible sets to a model of set theory in order to establish', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='theory in order to establish the consistency of the negation of the CH. In 1961 Dana Scott proved', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='CH. In 1961 Dana Scott proved that the failure of the Axiom of Constructibility follows from the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='follows from the existence of a measurable cardinal, contrary to a conjecture Gödel had made in', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='conjecture Gödel had made in 1940. (See Scott 1961. A cardinal κ is said to be measurable if there', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='to be measurable if there is a non-principal κ-complete ultrafilter in the power-set Boolean', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='in the power-set Boolean algebra of κ.) In 1963, as noted, Paul Cohen proved the consistency of the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='proved the consistency of the negation of the CH by adding non-constructible sets to an inner', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='sets to an inner model.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='What other open questions of set theory could be solved by Gödel’s method? Gödel himself noted some', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='Gödel himself noted some consequences. They are related to so called projective sets of real', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='projective sets of real numbers and finite sequences of real numbers. The simplest projective sets', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='The simplest projective sets are the closed sets, also called Π10-sets. A set is Σ1n+1 if it is the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='A set is Σ1n+1 if it is the projection of a Π1n-subset of the real plane. A set is Δ1n+1 if it and', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='A set is Δ1n+1 if it and its complement are Σ1n+1. Gödel observed that there is both a non-Lebesgue', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='there is both a non-Lebesgue measurable Δ12-set and an uncountable Π11-set without a perfect subset', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='without a perfect subset in L. (A set of reals is perfect if it is closed, non-empty, and has no', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='closed, non-empty, and has no isolated points. Such sets have the size of the continuum.) Gödel', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='size of the continuum.) Gödel gave a sketch of the proof in the 1951 second printing of Gödel 1940.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='printing of Gödel 1940.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='It has turned out subsequently that the axiom V = L gives a virtually complete extension of ZFC.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='complete extension of ZFC. This means that, apart from sentences arising from Gödel’s', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='arising from Gödel’s incompleteness theorems, essentially all set-theoretical questions can be', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='questions can be decided by means of the axioms V = L. This is not to imply that such results are', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='imply that such results are in any way trivial. Indeed, it has turned out that L is quite a', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='turned out that L is quite a complicated structure, despite its relatively simple description. As', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='simple description. As for settling open set-theoretical questions in L, the main step was the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='in L, the main step was the emergence of Jensen’s fine structure theory of L (Jensen 1972).', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='theory of L (Jensen 1972). Recalling that the successor step Lα +1 in the definition of the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='+1 in the definition of the constructible hierarchy adds to L all subsets of Lα definable by first', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='of Lα definable by first order formulas φ over (Lα, ∈), fine structure theory, roughly speaking,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='theory, roughly speaking, ramifies the step from Lα to Lα+1 into smaller steps according to the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='steps according to the complexity of the defining formula φ. Jensen established by means of his', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='established by means of his fine structure a strengthening, denoted by ◊, of CH, that he used to', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='by ◊, of CH, that he used to construct a Souslin tree in L, and a combinatorial principle □ that he', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='principle □ that he used to show that the Souslin Hypothesis is consistent with CH.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='If he did not think this way from the outset, Gödel soon came to adopt the view that the Axiom of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='the view that the Axiom of Constructibility was implausible. As he remarked at the end of his 1947', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='at the end of his 1947 “What is Cantor’s Continuum Hypothesis?”', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='…it is very suspicious that, as against the numerous plausible propositions which imply the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='propositions which imply the negation of the continuum hypothesis, not one plausible proposition is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='one plausible proposition is known which would imply the continuum hypothesis. (Gödel 1990, p. 186)', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='(Gödel 1990, p. 186)', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='Gödel was compelled to this view of L by the Leibnizian[18] idea that, rather than the universe', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='rather than the universe being “small,” that is, one with the minimum number of sets, it is more', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='number of sets, it is more natural to think of the set theoretic universe as being as large as', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='universe as being as large as possible.[19]This idea would be reflected in his interest in', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='reflected in his interest in maximality principles, i.e., principles which are meant to capture the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='are meant to capture the intuitive idea that the universe of set theory is maximal in the sense', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='is maximal in the sense that nothing can be added; and in his conviction that maximality principles', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='that maximality principles would eventually settle statements like the CH. As Gödel put it in a', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='the CH. As Gödel put it in a letter to Ulam in the late 1950s, about a maximality principle of von', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='a maximality principle of von Neumann:', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='The great interest which this axiom has lies in the fact that it is a maximality principle,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='it is a maximality principle, somewhat similar to Hilbert’s axiom of completeness in geometry. For,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='in geometry. For, roughly speaking, it says that any set which does not, in a certain well defined', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='in a certain well defined way, imply an inconsistency exists. Its being a maximum principle also', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='a maximum principle also explains the fact that this axiom implies the axiom of choice. I believe', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='axiom of choice. I believe that the basic problems of set theory, such as Cantor’s continuum', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='such as Cantor’s continuum problem, will be solved satisfactorily only with the help of stronger', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='with the help of stronger axioms of this kind, which in a sense are opposite or complimentary to', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='opposite or complimentary to the constructivistic interpretation of mathematics. (Ulam 1958, as', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='mathematics. (Ulam 1958, as quoted in Gödel 1990, p. 168; original emphasis. Note that this is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='emphasis. Note that this is different from the very similar passage Gödel 2003b, p.295.)', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='Twenty years earlier, in 1938, Gödel had written seemingly differently about the Axiom of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='about the Axiom of Constructibility:', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='The proposition A (i.e., V = L) added as a new axiom seems to give a natural completion of the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='a natural completion of the axioms of set theory, in so far as it determines the vague notion of an', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='the vague notion of an arbitrary infinite set in a definite way. (Gödel 1986, p.27)', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='Gödel may have meant by “natural completion” here “the correct completion,” or he may have meant to', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='or he may have meant to say no more than that the Axiom of Constructibility determines the notion', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='determines the notion of set in a definite way. In any case he used the term “natural” differently', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='term “natural” differently in a conversation with Wang on constructibility in 1972 (Wang 1996, p.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='in 1972 (Wang 1996, p. 144):', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='Gödel talked more about the relation between axioms of infinity and the constructible universe…(he', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='constructible universe…(he observed that) preliminary concepts such as that of constructible sets', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='as that of constructible sets are necessary to arrive at the natural concept, such as that of set.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='such as that of set.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='This is reminiscent of a remark of Hugh Woodin, that studying forcing leads to a better', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='forcing leads to a better understanding of V — the general principle being that studying the models', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='that studying the models of a theory is not only useful to understand the theory itself, but useful', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='the theory itself, but useful to obtain a better picture of V (Woodin 1988).', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='For more on Gödel’s program and on Gödel’s program relative to the CH the reader is referred e.g.,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='the reader is referred e.g., to Steel forthcoming and Feferman et al. 2000. For more on Gödel’s', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='al. 2000. For more on Gödel’s result, its history , and its significance the reader is referred to', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='the reader is referred to Floyd/Kanamori 2006 and Kennedy 2006.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory'}),\n",
       " Document(page_content='Gödel’s interest in intuitionism was deep and long-lasting. Although he himself did not subscribe to', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='himself did not subscribe to that view, he made a number of important contributions to', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='of important contributions to intuitionistic logic. Perhaps the importance he placed on the concept', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='he placed on the concept of evidence (see below) led to his close consideration of it.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='We discuss Gödel’s results on intuitionistic logic in their chronological order.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='Both many-valued logic, introduced by Łukasiewicz in the twenties (Łukasiewicz 1970) and', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='(Łukasiewicz 1970) and intuitionistic logic, formalized by Heyting in 1930, fail to satisfy the law', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='1930, fail to satisfy the law of excluded middle. It was therefore natural to ask whether', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='natural to ask whether intuitionistic logic can be presented as a many-valued logic, and indeed a', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='logic, and indeed a number of logicians in the 1920s had suggested just that. In his 1932 Gödel', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='just that. In his 1932 Gödel gave a simple argument which shows that intuitionistic propositional', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='intuitionistic propositional logic cannot be thought of as a finitely-valued logic. Precisely,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='logic. Precisely, Gödel proved two theorems:', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='Theorem 7. There is no realization with finitely many elements (truth values) for which the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='(truth values) for which the formulas provable in H, and only those, are satisfied (that is, yield', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='are satisfied (that is, yield designated values for an arbitrary assignment).', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='(H is intuitionistic propositional logic, after Heyting.)', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='Theorem 8. Infinitely many systems lie between H and the system A of the ordinary propositional', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='of the ordinary propositional calculus, that is, there is a monotonically decreasing sequence of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='decreasing sequence of systems all of which include H as a subset and are included in A as subsets.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='are included in A as subsets.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='In his proof he considered for each natural number n > 0 the sentence', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='Fn = ∨1 ≤ i < j ≤ n pi ≡ pj.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='He observed that in an n-valued logic the sentences Fm, for m > n, should be derivable. However,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='should be derivable. However, Gödel showed, Fn is not derivable from Heyting’s axioms for any n.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='Subsequently Jaśkowski (Jaśkowski 1936) showed that intuitionistic propositional logic can be given', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='logic can be given a many-valued semantics in terms of infinitely many truth-values. For further', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='truth-values. For further discussion of many-valued logics, see for example the entry on', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='see for example the entry on many-valued logic in this encyclopedia as well as van Stigt’s article', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='well as van Stigt’s article on intuitionistic logic in Mancosu 1998.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='We now consider Gödel 1933e, in which Gödel showed, in effect, that intuitionistic or Heyting', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='intuitionistic or Heyting arithmetic is only apparently weaker than classical first-order', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='than classical first-order arithmetic. This is because the latter can be interpreted within the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='can be interpreted within the former by means of a simple translation, and thus to be convinced of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='and thus to be convinced of the consistency of classical arithmetic, it is enough to be convinced', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='it is enough to be convinced of the consistency of Heyting arithmetic. Heyting arithmetic is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='Heyting arithmetic is defined to be the same as classical arithmetic, except that the underlying', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='except that the underlying predicate logic is given by intuitionistic axioms and rules of inference', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='axioms and rules of inference (see below).', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='This result extends the same assertion for the propositional case. Let H denote the intuitionistic', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='H denote the intuitionistic propositional logic, and A denote its classical counterpart (as above).', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='counterpart (as above). Inductively define:', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='A′ ≡ ¬¬A (A atomic) (¬A)′ ≡ ¬A′ (A → B)′ ≡ ¬(A′ ∧ ¬B′) (A ∨ B)′ ≡ ¬(¬A′ ∧ ¬B′) (A ∧ B)′ ≡ A′ ∧ B′', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='Then,  \\nTheorem 9. Let F be a propositional formula. Then H ⊢ F if and only if A ⊢ F′,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='The theorem follows easily from the result of Glivenko (1929) that ¬F follows from H if and only if', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='follows from H if and only if ¬F follows from A, for any propositional formula F.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='Gödel’s so-called double negation interpretation extends Theorem 9 to a reduction of classical', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='9 to a reduction of classical first order logic to intuitionistic predicate logic. The translation', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='logic. The translation in this case can be taken to map A′ to A for atomic A. Moreover, we let', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='atomic A. Moreover, we let ∀xA(x)′ = ∀xA′(x) :', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='Theorem 10. Suppose A is a first order formula. If A is provable in classical first order logic,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='classical first order logic, then A′ is provable in intuitionistic first order logic.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='The above result had been obtained independently by Gentzen (with Bernays), but upon hearing of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='Bernays), but upon hearing of Gödel’s result Gentzen withdrew his paper from publication. It had', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='from publication. It had also been anticipated by Kolmogorov in his 1925 “On the Principle of the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='1925 “On the Principle of the Excluded Middle,” (English translation van Heijenoort 1967) but that', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='van Heijenoort 1967) but that paper was largely unknown to logicians who were outside of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='logicians who were outside of Kolmogorov’s circle.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='Bernays has written (see Bernays’ entry on David Hilbert in Edwards 1967) that this result of', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='1967) that this result of Gödel’s drew the attention of the Hilbert school to two observations:', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='school to two observations: first, that intuitionistic logic goes beyond finitism, and secondly,', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='finitism, and secondly, that finitist systems may not be the only acceptable ones from the', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='only acceptable ones from the foundational point of view.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='The following theorem for the case of arithmetic follows from Theorem 10:', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='Theorem 11. Suppose A is a first order formula of arithmetic. If A is provable in classical Peano', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='provable in classical Peano arithmetic, then A′ is provable in intuitionistic first order', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='in intuitionistic first order arithmetic.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='For a list of the axioms and rules of intuitionistic first order logic see Gödel 1958, reprinted', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='see Gödel 1958, reprinted with detailed introductory note by A.S. Troelstra in Gödel 1990. See also', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='in Gödel 1990. See also Troelstra 1973, and Troelstra’s “Aspects of constructive mathematics” in', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='constructive mathematics” in Barwise 1977. For a detailed proof of the above theorem the reader is', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='above theorem the reader is referred also to the latter.', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='This result of Gödel’s (Gödel 1933f), which marks the beginning of provability logic, makes exact', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " Document(page_content='logic, makes exact the difference between the concept of “provability in a specified formal system”', metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}),\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap = 30\n",
    ")\n",
    "\n",
    "#split\n",
    "splits = text_splitter.split_documents(html_header_splitts)\n",
    "splits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations:\n",
    "There can be quite a bit of structural variation from one HTML document to another, and while HTMLHeaderTextSplitter will attempt to attach all \"relevant\" headers to any given chunk, it can sometimes miss certain headers. For example, the algorithm assumes an informational hierarchy in which headers are always at nodes \"above\" associated text, i.e. prior siblings, ancestors, and combinations thereof. In the following news article (as of the writing of this document), the document is structured such that the text of the top-level headline, while tagged \"h1\", is in a distinct subtree from the text elements that we'd expect it to be \"above\"—so we can observe that the \"h1\" element and its associated text do not show up in the chunk metadata (but, where applicable, we do see \"h2\" and its associated text):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.Split by character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very simplest method.This method split base on the character(by default \"\\n\\n\") and measure chunks lenght <br>\n",
    "by number of character\n",
    "\n",
    "1: how the text is split: by single character <br>\n",
    "2: How the chunk size is measured by number of character "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"There can be quite a bit of structural \\n\\n variation from \n",
    "one HTML document to another, and while HTMLHeaderTextSplitter will \n",
    "attempt to attach all \"relevant\" headers to any given chunk,\\n\\n it can\n",
    " sometimes miss certain headers. For example, the algorithm assumes \n",
    " an informational hierarchy in which headers are always at nodes \"above\" \n",
    " associated text, i.e. prior siblings, ancestors, and combinations thereof.\n",
    "   In the following news article (as of the writing of this document), \n",
    "   the document is structured such that the text of the top-level headline, while tagged \"h1\"\n",
    "   , is in a distinct subtree from the text elements that we'd \n",
    "   expect it to be \"above\"—so we can observe that the \"h1\" \n",
    "element and its associated text do not show up in the chunk metadata \n",
    "(but, where applicable, we do see \"h2\" and its associated text):\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**chunk_size**: The size of each chunk of text that the splitter will process. In this case, the chunk size is set to 42, which means that the splitter will process the text in chunks of 42 characters each.<br>\n",
    "**chunk_overlap**: The amount of overlap between each chunk of text. In this case, the chunk overlap is set to 30, which means that each chunk of text will overlap with the previous chunk by 30 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Got a larger chunk overlap (30) than chunk size (10), should be smaller.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb Cell 228\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y435sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtext_splitter\u001b[39;00m \u001b[39mimport\u001b[39;00m CharacterTextSplitter\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y435sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m text_splitter \u001b[39m=\u001b[39m CharacterTextSplitter(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y435sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     separator\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y435sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     chunk_size \u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y435sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     chunk_overlap \u001b[39m=\u001b[39;49m \u001b[39m30\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y435sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# length_function = len,\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y435sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     is_separator_regex\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y435sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y435sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m texts \u001b[39m=\u001b[39m text_splitter\u001b[39m.\u001b[39mcreate_documents([text])\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y435sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# texts = text_splitter.create_documents(text)\u001b[39;00m\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/text_splitter.py:301\u001b[0m, in \u001b[0;36mCharacterTextSplitter.__init__\u001b[0;34m(self, separator, is_separator_regex, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    298\u001b[0m     \u001b[39mself\u001b[39m, separator: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, is_separator_regex: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any\n\u001b[1;32m    299\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    300\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Create a new TextSplitter.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    302\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_separator \u001b[39m=\u001b[39m separator\n\u001b[1;32m    303\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_separator_regex \u001b[39m=\u001b[39m is_separator_regex\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/text_splitter.py:123\u001b[0m, in \u001b[0;36mTextSplitter.__init__\u001b[0;34m(self, chunk_size, chunk_overlap, length_function, keep_separator, add_start_index, strip_whitespace)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Create a new TextSplitter.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \n\u001b[1;32m    113\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39m                      every document\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[39mif\u001b[39;00m chunk_overlap \u001b[39m>\u001b[39m chunk_size:\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    124\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot a larger chunk overlap (\u001b[39m\u001b[39m{\u001b[39;00mchunk_overlap\u001b[39m}\u001b[39;00m\u001b[39m) than chunk size \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00mchunk_size\u001b[39m}\u001b[39;00m\u001b[39m), should be smaller.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m     )\n\u001b[1;32m    127\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_chunk_size \u001b[39m=\u001b[39m chunk_size\n\u001b[1;32m    128\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_chunk_overlap \u001b[39m=\u001b[39m chunk_overlap\n",
      "\u001b[0;31mValueError\u001b[0m: Got a larger chunk overlap (30) than chunk size (10), should be smaller."
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size = 10,\n",
    "    chunk_overlap = 30,\n",
    "    # length_function = len,\n",
    "    is_separator_regex=False\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents([text])\n",
    "# texts = text_splitter.create_documents(text)\n",
    "\n",
    "print(texts[0])\n",
    "# print(len(texts[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MarkdownHeaderTextSplitter\n",
    "Motivation: Many chat or question-answerting application involving chunking input doc and embeding and vectore storage <br>\n",
    "\n",
    "This note is from pinecode:<br>\n",
    "When a full paragraph or document is embedded, the embedding process considers both the overall context and the relationships between the sentences and phrases within the text. This can result in a more comprehensive vector representation that captures the broader meaning and themes of the text.\n",
    "\n",
    "\n",
    "As mentioned, chunking often aims to keep text with common context together. With this in mind, we might want to specifically honor the structure of the document itself. For example, a markdown file is organized by headers. Creating chunks within specific header groups is an intuitive idea. To address this challenge, we can use MarkdownHeaderTextSplitter. This will split a markdown file by a specified set of headers.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_docs = '# Foo\\n\\n ## Bar\\n\\nHi this is Jim ### \\nHi this is Joe\\n\\n ### Baz\\n\\n Hi this is Molly' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Hi this is Jim ###\\nHi this is Joe', metadata={'header 1': 'Foo', 'header 2': 'Bar'}),\n",
       " Document(page_content='Hi this is Molly', metadata={'header 1': 'Foo', 'header 2': 'Bar', 'header 3': 'Baz'})]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_to_split = [\n",
    "    (\"#\", \"header 1\"),\n",
    "    (\"##\", \"header 2\"),\n",
    "    (\"###\", \"header 3\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=header_to_split)\n",
    "md_header_splitter = markdown_splitter.split_text(markdown_docs)\n",
    "md_header_splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# within each markdown group we can then apply any text splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='## History  \\nMarkdown[9] is a lightweight markup language for creating formatted text using a plain-text editor. John Gruber created Markdown in 2004 as a markup language that is appealing to human readers in its source code form.[9]', metadata={'header 1': 'Intro'}),\n",
       " Document(page_content='Markdown is widely used in blogging, instant messaging, online forums, collaborative software, documentation pages, and readme files.  \\n## Rise and divergence', metadata={'header 1': 'Intro'}),\n",
       " Document(page_content='## Rise and divergence  \\nAs Markdown popularity grew rapidly, many Markdown implementations appeared, driven mostly by the need for  \\nadditional features such as tables, footnotes, definition lists,[note 1] and Markdown inside HTML blocks.', metadata={'header 1': 'Intro'}),\n",
       " Document(page_content='#### Standardization  \\nFrom 2012, a group of people, including Jeff Atwood and John MacFarlane, launched what Atwood characterised as a standardisation effort.  \\n## Implementations', metadata={'header 1': 'Intro'}),\n",
       " Document(page_content='## Implementations  \\nImplementations of Markdown are available for over a dozen programming languages.', metadata={'header 1': 'Intro'})]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "markdown_document = \"# Intro \\n\\n    ## History \\n\\n Markdown[9] is a lightweight markup language for creating formatted text using a plain-text editor. John Gruber created Markdown in 2004 as a markup language that is appealing to human readers in its source code form.[9] \\n\\n Markdown is widely used in blogging, instant messaging, online forums, collaborative software, documentation pages, and readme files. \\n\\n ## Rise and divergence \\n\\n As Markdown popularity grew rapidly, many Markdown implementations appeared, driven mostly by the need for \\n\\n additional features such as tables, footnotes, definition lists,[note 1] and Markdown inside HTML blocks. \\n\\n #### Standardization \\n\\n From 2012, a group of people, including Jeff Atwood and John MacFarlane, launched what Atwood characterised as a standardisation effort. \\n\\n ## Implementations \\n\\n Implementations of Markdown are available for over a dozen programming languages.\"\n",
    "\n",
    "header_to_split_on = [\n",
    "    (\"#\", \"header 1\"),\n",
    "    (\"#@\", \"header 2\"),\n",
    "]\n",
    "\n",
    "\n",
    "# Markdown splitter ---> after that we can used any type of text splitter within each markdown\n",
    "markdown_header_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=header_to_split_on)\n",
    "md_splitter = markdown_header_splitter.split_text(markdown_document)\n",
    "# print(\"Markdown splitter: \",md_splitter)\n",
    "\n",
    "# character level splitting\n",
    "character_level_splitting = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 250,\n",
    "    chunk_overlap = 30,\n",
    ")\n",
    "\n",
    "# split\n",
    "splite = character_level_splitting.split_documents(md_splitter)\n",
    "splite\n",
    "# print(splits[0].page_content)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursively split by character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough. The default list is [\"\\n\\n\", \"\\n\", \" \", \"\"]. This has the effect of trying to keep all paragraphs (and then sentences, and then words) together as long as possible, as those would generically seem to be the strongest semantically related pieces of text.\n",
    "\n",
    "How the text is split: by list of characters.\n",
    "How the chunk size is measured: by number of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"There can be quite a bit of structural \\n\\n variation from one HTML document to another, \\n and while HTMLHeaderTextSplitter will attempt to attach all \\n \"relevant\" headers to any given chunk,\\n\\n it can\n",
    " sometimes miss certain headers. For example, the algorithm assumes \n",
    " an informational hierarchy in which headers are always at nodes \"above\" \n",
    " associated text, i.e. prior siblings, ancestors, and combinations thereof.\n",
    "   In the following news article (as of the writing of this document), \n",
    "   the document is structured such that the text of the top-level headline, while tagged \"h1\"\n",
    "   , is in a distinct subtree from the text elements that we'd \n",
    "   expect it to be \"above\"—so we can observe that the \"h1\" \n",
    "element and its associated text do not show up in the chunk metadata \n",
    "(but, where applicable, we do see \"h2\" and its associated text):\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='There can be quite a bit of structural'),\n",
       " Document(page_content='variation from one HTML document to another,'),\n",
       " Document(page_content='and while HTMLHeaderTextSplitter will attempt to attach all'),\n",
       " Document(page_content='\"relevant\" headers to any given chunk,'),\n",
       " Document(page_content='it can\\n sometimes miss certain headers. For example, the algorithm assumes'),\n",
       " Document(page_content='an informational hierarchy in which headers are always at nodes \"above\"'),\n",
       " Document(page_content='associated text, i.e. prior siblings, ancestors, and combinations thereof.'),\n",
       " Document(page_content='In the following news article (as of the writing of this document),'),\n",
       " Document(page_content='the document is structured such that the text of the top-level headline, while tagged \"h1\"'),\n",
       " Document(page_content=\", is in a distinct subtree from the text elements that we'd\"),\n",
       " Document(page_content='expect it to be \"above\"—so we can observe that the \"h1\"'),\n",
       " Document(page_content='element and its associated text do not show up in the chunk metadata'),\n",
       " Document(page_content='(but, where applicable, we do see \"h2\" and its associated text):')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitters = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \",\" ],      # by default\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap = 20,\n",
    "    length_function = len,\n",
    "    is_separator_regex=False,\n",
    "\n",
    ")\n",
    "\n",
    "recusively_splitter = text_splitters.create_documents([text])\n",
    "recusively_splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split by token:\n",
    "LLM have a token limit , you should not exceed that token limit.when you splits your text into chunks it is therefore a good idea to count the number of tokens. There are many tokenizer . when you count tokens in your text you should use the same tokenizer as used in the language\n",
    "\n",
    "\n",
    "***tiktoken is fast BPE tokenzier created by OpenAI**:\n",
    "used tiktoken to count number of token with OPENAI Language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_for_token_count = \"\"\"There can be quite a bit of structural variation \\n\\n from  one \n",
    "HTML document to another, \\n and while HTMLHeaderTextSplitter will attempt to attach all\n",
    " \\n \"relevant\" headers to any given chunk,\\n\\n it can\n",
    " sometimes miss certain headers. For example, the algorithm assumes \\n\\n\n",
    " an informational hierarchy in which headers are always at nodes \"above\" \n",
    " associated text, i.e. prior siblings, \\n\\n ancestors, and combinations thereof.\n",
    "   In the following news \\n\\n article (as of the \\n\\n writing of this document), \n",
    "   the document is structured such that the text \\n\\n of the top-level headline, while tagged \"h1\"\n",
    "   , is in a distinct subtree from the text \\n\\n elements that we'd \n",
    "   expect it to be \"above\"—so we can observe \\n\\n that the \"h1\" \n",
    "element and its associated text do not \\n\\n show up in the chunk metadata \n",
    "(but, where applicable, we do see \"h2\" and its associated text):\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "868\n"
     ]
    }
   ],
   "source": [
    "print(len(text_for_token_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitters = CharacterTextSplitter.from_tiktoken_encoder(chunk_size = 42, chunk_overlap=0)\n",
    "texts = text_splitters.split_text(text_for_token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There can be quite a bit of structural variation\n",
      "48\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(texts[0])\n",
    "print(len(texts[0]))\n",
    "\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note*** that if we use CharacterTextSplitter.from_tiktoken_encoder, text is only split by CharacterTextSplitter and tiktoken tokenizer is used to merge splits. It means that split can be larger than chunk size measured by tiktoken tokenizer. We can use RecursiveCharacterTextSplitter.from_tiktoken_encoder to make sure splits are not larger than chunk size of tokens allowed by the language model, where each split will be recursively split if it has a larger size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "text_splitters = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size = 8, chunk_overlap=0)\n",
    "texts_tokenzier = text_splitters.split_text(text_for_token_count)\n",
    "print(len(texts_tokenzier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There can be quite a bit of structural\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "print(texts_tokenzier[0])\n",
    "print(len(texts[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also load a tiktoken splitter directly, which ensure each split is smaller than chunk size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There can be quite a\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "text_splitter = TokenTextSplitter(chunk_size=5, chunk_overlap=0)\n",
    "\n",
    "texts = text_splitter.split_text(text_for_token_count)\n",
    "print(texts[0])\n",
    "print(len(texts[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lost in the middle: The problem with long context:\n",
    "No matter the architecture of your model, there is a substantial performance degradation when you include 10+ retrieved documents. In brief: When models must access relevant information in the middle of long contexts, they tend to ignore the provided documents.\n",
    "\n",
    "To Avoid/Address this issues we re-order the documents after retrieval to avoid performance degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hugging_face_api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chromadb\n",
    "from langchain.vectorstores import chroma\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.document_transformers import (LongContextReorder,)\n",
    "from langchain.chains import StuffDocumentsChain, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import sentence_transformers python package. Please install it with `pip install sentence_transformers`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/embeddings/huggingface.py:225\u001b[0m, in \u001b[0;36mHuggingFaceBgeEmbeddings.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39msentence_transformers\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb Cell 253\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y512sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Get Embeding of your text\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y512sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m embeding \u001b[39m=\u001b[39m HuggingFaceBgeEmbeddings(model_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mall-MiniLM-L6-v2\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/embeddings/huggingface.py:228\u001b[0m, in \u001b[0;36mHuggingFaceBgeEmbeddings.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39msentence_transformers\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m--> 228\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m    229\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCould not import sentence_transformers python package. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease install it with `pip install sentence_transformers`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient \u001b[39m=\u001b[39m sentence_transformers\u001b[39m.\u001b[39mSentenceTransformer(\n\u001b[1;32m    234\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name, cache_folder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache_folder, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_kwargs\n\u001b[1;32m    235\u001b[0m )\n\u001b[1;32m    236\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m-zh\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name:\n",
      "\u001b[0;31mImportError\u001b[0m: Could not import sentence_transformers python package. Please install it with `pip install sentence_transformers`."
     ]
    }
   ],
   "source": [
    "# Get Embeding of your text\n",
    "embeding = HuggingFaceBgeEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "texts = [\n",
    "    \"Basquetball is a great sport.\",\n",
    "    \"Fly me to the moon is one of my favourite songs.\",\n",
    "    \"The Celtics are my favourite team.\",\n",
    "    \"This is a document about the Boston Celtics\",\n",
    "    \"I simply love going to the movies\",\n",
    "    \"The Boston Celtics won the game by 20 points\",\n",
    "    \"This is just a random text.\",\n",
    "    \"Elden Ring is one of the best games in the last 15 years.\",\n",
    "    \"L. Kornet is one of the best Celtics players.\",\n",
    "    \"Larry Bird was an iconic NBA player.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Retriever\n",
    "retriever = chroma.from_texts(texts, embeding= embeding).as_retriever(search_kwargs={\"k\":10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Query =  \"What can you tell me about the Celtics?\"\n",
    "\n",
    "# Get relevant documents ordered by relevance score\n",
    "\n",
    "docs = retriever.get_relevant_documents(Query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the documents\n",
    "# Less relevant documents will be at the middle of the list and more\n",
    "# and relevant elemenst will be at the beginning / end\n",
    "\n",
    "reordering = LongContextReorder()\n",
    "\n",
    "reordering_docs = reordering.transform_documents(docs)\n",
    "reordering_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Embeding Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1: Cashing**:\n",
    "If you want to avoid recomputing the text embeding again and again then we can stored that embeding or temporarily cashed\n",
    "\n",
    "Cachsing Embeding can be done by using \"CacheBackedEmbeding\". The cache backed embedder is a wrapper around an embedder that caches embedding in a key-values store. The text is hashed and the hash is used as the key in the cache\n",
    "\n",
    "<br>\n",
    "The main *supported* way to initialized a CacheBackedEmbeddings is from_bytes_store. This takes in the following parameters:<br>\n",
    "a: underlying_embedder: The embedder to use for embedding <br>\n",
    "b: document_embedding_cache: The cache to use for storing document embedding<br>\n",
    "c: namespace: (optional default= \"\") the namespace is used for document cache. The namepace is used to avoid collision with other cache.\n",
    "For example : set it to the name of the embedding model used\n",
    "<br>\n",
    "Attention:  Be sure to set the namespace parameter to avoid collision of the same text embedded using different embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.storage import InMemoryStore, LocalFileStore, RedisStore\n",
    "# UpstashRedisStore -- I cannot import this name I facing some issue "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using CacheBackedEmbeddings with a vectore stores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use LocalFileStores for storing embedding and uses FAISS vector stores for retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "underlying_embedding = OpenAIEmbeddings(openai_api_key=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = LocalFileStore(\"documents_embedding\")\n",
    "\n",
    "cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "    underlying_embeddings=underlying_embedding,\n",
    "    document_embedding_cache=fs,\n",
    "    namespace=underlying_embedding.model\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cache is empty b/z Now we don,t do any embedding of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text-embedding-ada-00260589eb0-7a92-5f46-966b-8a7934df86a4',\n",
       " 'text-embedding-ada-0028ca6fa55-65af-52b2-8e87-186a0bc58ca1',\n",
       " 'text-embedding-ada-00288cf03ed-50ea-57af-a7fd-25dcf6ac78a3',\n",
       " 'text-embedding-ada-00241080c39-e226-57c2-9f98-44e07ecf2713']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(fs.yield_keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the documents , split into chunks, embedding each chunks and load it into vectores store(FAISS, Pinecone, Chromdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[Document(page_content='Hello,\\n\\nMy name is Israr dawar and I’d love to help you launch your new website. I am a web developer(Backend), who has worked on many different websites. I studied web development for 2 years and have worked with startups to build their web presence over the past 2 years.\\n\\nI’d be happy to tailor it to your needs. I understand you are a new company and I am happy to be flexible to make sure we work with your timeline. Could you tell me more about your target market and audience? If you are unsure, I can brainstorm with you on this point.\\n\\nDo let me know if you have any questions and I am excited to have the possibility to work on this project!\\nTo know about my experience please visit my Github profile https://github.com/israr96418\\nBest regards,\\n\\nIsrar Dawar', metadata={'source': 'webproposal.txt'})]\n"
     ]
    }
   ],
   "source": [
    "# text loading\n",
    "text_loading = TextLoader(\"webproposal.txt\").load()\n",
    "print(type(text_loading))\n",
    "print(text_loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# split into chunks we have different method but here i used simpleste method \"CharacterTextSplitter\"\n",
    "\n",
    "Text_splitting = CharacterTextSplitter(chunk_size = 268 , chunk_overlap = 20)\n",
    "document_chunking = Text_splitting.split_documents(text_loading)\n",
    "print(len(document_chunking))     # measure how many chunks are created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vecotores stores to stores this vectores of documenst in localfilestores by using \"LocalFileStores\"\n",
    "db = FAISS.from_documents(document_chunking, cached_embedder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try to re-create the vectore store again, it will be much faster since it does not to re-compute any embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db2 = FAISS.from_documents(document_chunking, cached_embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text-embedding-ada-00260589eb0-7a92-5f46-966b-8a7934df86a4',\n",
       " 'text-embedding-ada-0028ca6fa55-65af-52b2-8e87-186a0bc58ca1',\n",
       " 'text-embedding-ada-00288cf03ed-50ea-57af-a7fd-25dcf6ac78a3']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(fs.yield_keys())[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In Memory :** In this section we show how to set up an in memory cache for embedding. This type of cache is primarly used for unit testing  or protoyping. Don,t used this cache(In-Memory) if you need actually store the embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = InMemoryStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "    underlying_embedding, store, namespace=underlying_embedding.model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = embedder.embed_documents(['hello',\"HI\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we try the 2nd time to embed the embedding time is less then first time embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_for_cache = embedder.embed_documents(['hello',\"HI\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding == embedding_for_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Stores:\n",
    "One of the most common ways to store and search over unstructured data is to embed it and store the resulting embedding vectors, and then at query time to embed the unstructured query and retrieve the embedding vectors that are 'most similar' to the embedded query. A vector store takes care of storing embedded data and performing vector search for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have different vectore database to store the embedding vector <br>\n",
    "Here we used \"chromdb\" for storing embedding vectore, which run on your local machine as a library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Hello,\\n\\nMy name is Israr dawar and I’d love to help you launch your new website. I am a web developer(Backend), who has worked on many different websites. I studied web development for 2 years and have worked with startups to build their web presence over the past 2 years.\\n\\nI’d be happy to tailor it to your needs. I understand you are a new company and I am happy to be flexible to make sure we work with your timeline. Could you tell me more about your target market and audience? If you are unsure, I can brainstorm with you on this point.\\n\\nDo let me know if you have any questions and I am excited to have the possibility to work on this project!\\nTo know about my experience please visit my Github profile https://github.com/israr96418\\nBest regards,\\n\\nIsrar Dawar', metadata={'source': 'webproposal.txt'})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load documents\n",
    "raw_docs = TextLoader(\"webproposal.txt\").load()\n",
    "raw_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After loading documnets then split into chunks \n",
    "text_splitt= CharacterTextSplitter(\n",
    "    chunk_size = 268,\n",
    "    chunk_overlap= 0\n",
    ")\n",
    "splitted_docs = text_splitt.split_documents(raw_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(splitted_docs, underlying_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.chroma.Chroma at 0x7f23c580af20>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Similirity search***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do let me know if you have any questions and I am excited to have the possibility to work on this project!\n",
      "To know about my experience please visit my Github profile https://github.com/israr96418\n",
      "Best regards,\n",
      "\n",
      "Israr Dawar\n"
     ]
    }
   ],
   "source": [
    "query = \"Give me just github link ?\"\n",
    "searhing_in_vectores_stores = db.similarity_search(query)\n",
    "print(searhing_in_vectores_stores[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Similirity Search by vectore**:\n",
    "It is also possible to do a search for documents to a given embedding vectores using \"similirity_search_by_vectors\"<br>\n",
    "which accepts an embedding vectores as parameter instead of string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00041510710745331064, 0.007321627190760583, 0.003366072805378343, -0.021877798251237524, -0.006146013532534891, 0.014402102360403719, -0.012238437830523974, 0.00768335429111414, -0.013122659734868513, -0.009123564154625466, 0.020819411567449757, -0.014804022085158594, -0.0008515661828219249, -0.003607224360834483, -0.0015138954102577938, -0.017764826129661265, 0.027893188664851302, -0.02298977510089371, 0.007891012691394476, -0.007576175822022522, -0.0024165388759119404, -0.005409161790360673, -0.013745634470048214, 0.012285328061505577, -0.024436683502307936, 0.014522677905301136, 0.007281435032020573, -0.010141759610995834, -0.011206845298347807, -0.016572464962525058, 0.031135336889211433, -0.008996289606163842, -0.013303523517875945, -0.024208928556996287, -0.014603062222781156, 0.0017784921976200618, 0.0024600800707727465, 0.0030127189938187375, 0.00792450584657028, -0.005807731547672136, 0.0015783699435188044, 0.014643254381521167, 0.009726442810435162, -0.026432882256308663, -0.016585862969653472, 9.943311729435817e-05, -0.016974384687279933, -0.019452885620870324, -0.03405594970629671, 0.016358109886987052, -0.009692949655259358, -0.018206936150510923, -0.04614031883674746, -0.02194478456158913, -0.004434507994512418, 0.020872999870672954, 0.01738970055651799, 0.028697026251715822, -0.028911383189899057, 0.01836770478547096, -0.010503487177010698, 0.008091971622449299, -0.04131728586497944, -0.029286508763042333, -0.022775418162710476, 0.003374446094172294, -0.013122659734868513, 0.01812655369567613, 0.005449353483439376, -0.009036481764903853, 0.035020554065476044, 0.02127491959542783, 0.004970399874309199, 0.011682449405695879, 0.04793555493440291, 0.01107287267764459, 0.007288133569923473, -0.009398209330918717, -0.007803929836011556, 0.005251743588505349, 0.008071876474401907, 0.007442202735658, 0.018032771371067697, 0.03223391386909398, 0.0009411606406724515, 0.005308681859171954, 0.02514674062720925, 0.0015030101115425922, -0.00915705730980127, -0.03440427926518316, -0.001147981549091935, 0.018407896944210973, 0.006859420159218308, -0.010228842000717447, -0.0004429483858254589, 0.004843125791508883, -0.04756043308655009, 0.029206124445562313, 0.028321902541217775, -0.02564244081392733, 0.009210646544347079, -0.013893005097879843, -0.023579255749574993, -0.005134517079728729, -0.008105369629577712, -0.02380701069488664, 0.009920703669248392, 0.004082828468182556, 0.010436499935336477, 0.0030361641093095385, -0.03496696576225285, 0.01132072277100363, 0.006768988267714593, -0.04021870888509689, -0.006162760110122793, -0.0028301806927509077, 0.025307509262169292, -0.013450894145707572, -0.0075225865874767135, -0.02842908101030939, 0.03183199600698433, 0.01851507541330259, 0.02093998804366979, -0.01453607591242955, 0.01492459763005601, -0.0009503713049119283, -0.022319910134732408, -0.005392415212772771, 0.0036641628643317415, -0.012466191844513008, 0.038664622014591046, 0.0024935732259485505, 0.011689148409260086, 0.02596397622120218, -0.005975197789212462, 0.014026977718583057, -0.00464551543091355, 0.02257445923165565, -0.017818414432884462, -0.019466283627998737, 0.010972392280794566, 0.030143934653130047, 0.0031399933094497065, -0.01734951026042321, -0.017805018288401277, 0.012345616299615591, -0.008292931484826736, -0.00198112646164257, 0.01929211884855551, -0.011173352143172003, 0.020189738760028466, 0.016894000369799912, 0.0099140055970068, 0.020913192029412962, -0.02075242525709815, 0.00996759483155261, -0.020913192029412962, 0.014937994705861808, -0.009110167078819667, 0.0072479418768447695, -0.00919724946854128, 0.025441481882872506, -0.004223500092449978, 0.0006598172757222817, 0.0021351953945464436, 0.027464474788484832, 0.0028536258082417086, -0.024436683502307936, -0.012198245671783963, 0.01917154237233548, 0.015165748719850842, 0.026553456869883467, -0.03389518107133667, 0.002577306579549367, 0.0014276502795663802, 0.022507471058658815, 0.01819354000602774, 0.001723228328598528, -0.03494016974799602, 0.009840320283090986, -0.042415866570152436, 0.006424007744948938, 0.020685438946746543, 0.019077761910372276, -0.011809723954157502, 0.0039153622266422305, 0.012077670126886547, -0.00995419775574681, -0.019037569751632268, 0.0038215810661870646, 0.013383906904033351, -0.005271839202214047, 0.003714402597095447, -0.02391418916397826, -0.652073589886556, -0.019720832724921984, -0.0033057850329296346, -0.009753237893369375, 0.0222529238243808, 0.03796796289681814, 0.017711235963792843, 0.013544674607670778, -0.04453263993772797, 0.033359286863233355, -0.01804616937819611, 0.02707595307085837, -0.0022875898093899193, -0.01484421331257599, 0.015500681202931495, -0.031376486116361034, 0.02518693278594926, -0.01993518966310522, 0.00026020077000007936, -0.009759935965610965, -0.0304654700604049, 0.014750432850612784, -0.0043105829478328975, -0.008292931484826736, 0.009384812255112918, 0.011314023767439424, 0.030787005467679752, -0.025856797752110566, -0.010503487177010698, 0.01336381175598596, -0.02411514809503308, 0.0024768266483606487, -0.0022021819377287047, 0.0008565901444567628, 0.05846583719434782, -0.037700013930121255, -0.017027974853148355, 0.02440988935069634, 0.005911560514981651, 0.03823590813822458, -0.020846205719061355, -0.006457500900124742, 0.01990839551149362, 0.012345616299615591, -0.02186440024410911, -0.02578981144175896, 0.037485656991938024, -0.005707251616483417, -0.01847488325456258, 0.02356585960509181, -0.020390697691083287, -0.0049168106397633905, -0.0180059772194561, -0.0005224948621986464, -0.01713515332223997, -0.0235256674463518, 0.03298416501538053, -0.015862407837623743, -0.005234997010917447, 0.007321627190760583, -0.00017552563095753153, 0.016398300183081832, -0.028670232100104224, -0.025615646662315732, 0.008922605223570643, -0.013156152890044317, 0.014495883753689539, -0.0006585612707616564, 0.01866244604113422, -0.01089200889463716, 0.013933197256619852, 0.012968591034795293, -0.03081380148193658, -0.0020213183875519266, -0.0025622345200218633, 0.023391692963003356, 0.01962705040031355, -0.009425003482530314, 0.000835656864264222, -0.004313931983953694, -0.011347516922615227, 0.006819228000478298, -0.006273288080996514, -0.009565675106797736, 0.03984358331195361, 0.023150541873208523, -0.008286232481262529, -0.0050474346900071165, -0.007824025449720254, -0.006939804011037022, 0.010657555877083918, 0.014964788857473406, -0.010114965459384237, -0.009599169193296155, 0.004541686463604035, 0.04978438306057201, -0.0021000274884795883, 0.00011994774614392563, 0.006779036307399595, -0.004896715026054692, -0.004946954758818398, -0.010711145111629728, 0.020792617415838162, 0.0011019283443098782, 0.03989717161517681, -0.005362271093717763, -0.004973749376091302, 0.0015909298767097307, 0.032769808077197295, -0.005774238392496332, -0.03290378069790051, -0.008708248285387408, 0.004528288922136929, 0.016438492341821844, -0.005583326569803898, -0.03019752481899847, 0.005512990757670187, 0.01901077560002067, 0.03196596862768755, -0.014683445608938563, 0.009532181951621931, 0.026017566387070607, 0.016786821900708293, -0.012781028248223655, 0.02332470665265175, 0.01600977846545537, 5.714787646247169e-05, -0.021958182568717545, 0.007937902922376078, 0.0034179872890331, 0.008942701302940649, -0.002480175917312098, 0.02122133129220463, -0.017912196757492893, 0.014911199622927597, 0.004230199096014184, 0.016304519721118627, -0.020819411567449757, 0.0005095162412849571, -0.010469994021834895, -0.0068996118522970116, 0.0001983429040390944, 0.0112001462947836, -0.0037378479454169018, -0.018300718475119354, -0.0033225316105175364, -0.015473887051319897, 0.003721101367829, -0.006544583289846355, -0.0009729792777878573, -0.008031684315661897, 0.01002788213834001, -0.0067857348453024945, 0.0185552675720426, 0.014187745422220484, -0.01453607591242955, 0.011447996388142638, -0.024088353943421487, -0.015125556561110831, -0.009713045734629364, -0.010476692094076487, 0.00451489184633113, -0.012064273051080748, -0.0008335635420657343, 0.002255771172274514, 0.0035435870866036712, 0.014388705284597922, 0.01479062407803018, -0.017818414432884462, -0.02032371138073168, 0.013504483380253382, -0.01592939601062058, -0.02432950503321632, 0.015112159485305034, -0.007294832573487679, -0.007502490508106708, -0.010295828311069054, -0.0037612932937383567, 0.0020095955969758723, 0.0006677718767934697, 0.009163756313365476, 0.021998374727457554, -0.014576267139846945, 0.031939172613430725, 0.04257663520511248, 0.013933197256619852, -0.01886340497218904, 0.026848198125546723, -0.003751245254053354, -0.006779036307399595, -0.0002928566952495158, 0.01201068381653494, -0.013705442311308205, 0.01623753341076702, -0.000741457074293957, 0.024275916729993123, 0.013718840318436617, 0.00030416068168748027, 0.006906310390199911, 0.04005794025013685, 0.003289038222511079, 0.021542866699479486, 0.008714946357629, -0.010858515739461356, -0.0030562601886795437, -0.015915998003492166, 0.004360822680596603, -0.008031684315661897, 0.010336020469809064, 0.03697656252338199, -0.0059651497495274595, 0.005258442126408249, -0.0013187971759990376, -0.003948855381818034, 0.013759031545854013, 0.016518876659301865, -0.0378071942618581, 0.011796326878351703, -0.02260125338326725, 0.01479062407803018, 0.02155626284396267, 0.015741833224048943, -0.007254640414747669, -0.009351319099937114, 0.003258894336286725, 0.0022892643274503174, 0.01535331150642248, 0.046703005333817146, -0.005171359736686636, -0.03247506682153404, -0.04970399874309199, 0.020270121214863258, -0.019385899310518716, -0.012077670126886547, 0.010637459797713914, 0.03697656252338199, -0.01819354000602774, -0.017872004598752884, 0.012573370313604625, -0.0009135287061616847, 0.005760840851029226, 0.0055632309560952, 0.030411881757181704, -0.005479497602494383, 0.016384904038598647, 0.013129358738432718, 0.04453263993772797, 0.01156857286436267, -0.014683445608938563, -0.008909207216442231, -0.030840595633548178, 0.008781933599303222, 0.00407947943206176, 0.0022892643274503174, 0.016827014059448305, -0.008761837519933216, -0.018716034344357414, 0.0015984659064734825, 0.005308681859171954, 0.028589847782624203, -0.002294288347292819, -0.004779488517278072, -0.014951391781667607, 0.016398300183081832, -0.0026744370089559822, -0.015031776099147628, -0.001738300271710705, 0.014750432850612784, 0.00675894022802959, -0.027464474788484832, -0.01268724778626045, 0.011468092467512644, 0.000544265517836713, 0.014281526815506302, 0.006089074796206979, -0.004136417702728365, 0.006919707931667017, 0.006467548939809745, -0.01693419252853992, -0.017523675039866432, -0.055357663453336134, -0.020618452636394936, 0.007422106656287995, 0.0279199828164629, 0.011039378591146173, -0.01634471187985864, -0.007656559673841236, 0.018206936150510923, 0.001541527402976224, 0.03223391386909398, 0.004625419351543545, -0.004853173831193886, -0.0010223818679366908, -0.024356299184827915, -0.004256993713287089, -0.009069974920079656, 0.008641261043713187, 0.012037477968146536, 0.011314023767439424, -0.006353671932815227, 0.02494578169615443, 0.007663258211744134, -0.001233389304337823, 0.0092776337860213, 0.04029909320257691, 0.02719652768443317, -0.001534828748657998, -0.012225040754718175, 0.022413690596695613, -0.0304654700604049, -0.005332127440324063, -0.01646528649343344, 0.005178058274589535, 0.0031064999214432494, 0.014589665146975357, 0.0008766861074114411, -0.0005090975535621943, -0.01479062407803018, 0.007817327377478662, 0.013933197256619852, 0.0048498243294117825, -0.0032086543706923657, -0.032957369001123706, 0.0028067353444294527, 0.057394052503431645, 0.02136870005739103, -0.00024303547558558286, 0.016974384687279933, -0.00644745286043974, -0.002677786277907432, -0.011133159984431993, -0.0030512361688370426, 0.016063368631323793, -0.011360913998421027, 0.0004186657784738051, -0.013477688297319169, -0.008627863967907387, -0.005238346047038244, 0.0033309048993114872, -0.031028158420119814, 0.04064742276146336, -0.011180051146736208, -0.00888911206839484, -0.011374312005549439, -0.0006824251903905473, 0.013826018787528234, 0.019077761910372276, -0.013986786491165661, 0.02252086906578723, 0.035797597500728966, 0.003017742780830585, 0.01866244604113422, 0.0035368883158701184, -0.004618720813640645, 0.016559068818041874, -0.004374219756402402, 0.0014243008941996038, -0.01172264156443589, -0.005442654945536476, 0.02214574535528918, -0.006581425946804262, 0.02356585960509181, 0.0022340005748441106, 0.002870372618660264, 0.00508762638308582, 0.03164443508305793, 0.004407713377239513, -0.005734046233756322, 0.006467548939809745, -0.00329741151130503, -0.014804022085158594, 0.02449027366817636, -0.007254640414747669, -0.003540237817652222, 0.02950086570122557, 0.017912196757492893, -0.011374312005549439, -0.013524579459623386, 0.007013488859291529, 0.020779219408709748, -0.018568663716525786, -0.0031935825439955157, 0.010751337270369737, -0.029018561658990676, -0.022962980949282112, -0.008400109953918353, 0.009458496637706117, -0.014710240691872774, 0.006454151398342638, -0.030009962032426833, -0.011019283443098781, -0.007341722804469281, -0.017872004598752884, 0.007984793153357681, 0.01757726334308963, -0.017054769004759954, -0.04396995344065828, 0.019064363903243862, 0.008828823830284825, 0.011287229615827826, 0.010041280145468423, 0.002677786277907432, 0.010945598129182967, 0.0027079301641317857, -0.012131259361432356, -0.04825709220432299, 0.010751337270369737, -0.019184940379463895, 0.01701457684601994, -0.016679643431616677, -0.012975289107036886, 0.02067204093961813, -0.0039421568439151344, 0.040138324567616866, 0.018769624510225836, 0.005878067359805846, 0.014857610388381789, -0.027276912001913192, -0.009418305410288721, 0.020511274167303317, 0.020028970125068424, 0.022721827996842053, -0.018287320467990944, 0.0077570396050299535, 0.013176248969414321, -0.026901788291415145, -0.008259438329650932, -0.025133342620080837, -0.011528380705622659, 0.014241334656766294, 0.01453607591242955, 0.032796600366163664, -0.03510093838295606, 0.03199276464194437, 0.017818414432884462, -0.004119671125140463, 0.0056905050388955155, 0.012419301613531405, 0.016438492341821844, 0.00695320108684282, 0.014804022085158594, 0.012379109454791395, 0.006296733196487315, -0.008286232481262529, -0.003372771343281242, -0.008775234595739015, 0.014670048533132763, 0.0198280111940136, -0.012178149592413957, -0.00739531203901509, -0.010778131421981335, -0.0320731489594244, -0.004320630521856593, -0.010570473487362305, -0.014937994705861808, 0.00995419775574681, -0.030760211316068157, -0.0005275188820411477, -0.013812620780399822, -0.03778039824760128, 0.011856614185139105, -0.005248394086723246, -0.0020883049307341877, -0.01642509619733866, -0.011990587737164934, -0.007884313687830269, -0.020471082008563308, -0.009806827127915183, -0.039334485118107124, -0.03255545113901406, -0.0074355041977551, 0.003054585437788492, 0.015875805844752157, 0.03944166544984397, -0.0033124835708325338, 0.026258717476865437, -0.028027161285554516, 0.0004467163716035032, -0.006651761758937972, -0.009378113251548711, -0.01893039128254065, -0.024825205219934397, 0.04429149071057836, 0.01901077560002067, 0.021154343119207795, -0.0060957737997711856, 0.027129541374081564, -0.0013028878574413347, 0.0074355041977551, -0.01492459763005601, 0.016880604225316728, 0.021408892216131042, -0.001376573054941822, 0.007328325728663483, 0.018381102792599375, -0.007951299998181878, 0.01282791941052787, 0.020283519221991668, -0.017429892715258, 0.018649048034005807, -0.011253735529329408, -0.004099575045770458, -0.018823212813449033, -0.047292484119853206, 0.01662605512839348, -0.009960895827988403, -0.026406088104697068, 0.006025437987637475, -0.02085960372618977, -0.004159863283880474, 0.023204132039076945, -0.020471082008563308, 0.013377208831791759, 0.002501946747573155, 0.009960895827988403, -0.009652758427841962, 0.022333306279215592, -0.026674033346103496, 0.014643254381521167, -0.039522049767323986, -0.016371506031470234, 0.01100588543597037, 0.003788087911011261, 0.027866394513239703, 0.007857519536218672, 0.006795782884987497, 0.0019576811133211153, -0.008768535592174808, -0.01755046919147803, -0.002898841753993567, -0.026017566387070607, -0.004123020626922567, -0.01089200889463716, 0.003510093698597214, 0.01444229451914373, -0.025240521089172456, -0.018407896944210973, -0.012781028248223655, -0.023083555562856916, 0.015768627375660538, -0.0204040956982117, 0.013236537207524338, -0.01685381007370513, -0.008125465708947717, -0.004625419351543545, 0.001285303904407907, 0.019305516855683925, 0.006578076445022158, 0.008179054943493526, 0.02773242002989126, 0.021837606092497512, -0.010114965459384237, 0.02399457348145828, 0.005499593681864388, 0.0018103108347354675, -1.450938514490409e-05, 0.007957999001746083, -0.012814522334722073, -0.023592653756703406, 0.016987782694408343, 0.0007062891682271015, -0.019345707151778708, -0.024383095199084742, 0.01259346639297463, 0.004354124142693704, -0.005395764248893567, -0.01619734125202701, 0.002396442796541935, -0.012198245671783963, -0.004936906719133395, 0.006182856189492798, -0.01187671026450911, 0.002649316909743476, -0.016585862969653472, -0.02800036713394292, 0.022440484748307208, -0.018448089102950982, 0.031054952571731412, 0.022494074914175634, -0.0068058309246725, -0.011247037457087817, -0.013504483380253382, -0.017027974853148355, 0.01564805089944051, 0.0008176542235080314, 0.03981679102298724, -0.0007280597656575047, -0.0015917672521552565, 0.003302435531147531, 0.009284331858262893, 0.00157920731896433, -0.013986786491165661, -0.012077670126886547, 0.019345707151778708, -0.008386712878112554, -0.0033828193829662447, 0.0007741130286472251, 0.0033995659605541464, 0.02473142475797119, 0.018742828495969012, -0.0021201235678495935, -0.026312305780088634, -0.006631665679567967, -0.009217345547911286, 0.00644745286043974, 0.002533765151857907, 0.005512990757670187, 0.008634562971471594, -0.012238437830523974, -0.019050967758760678, -0.012620260544586228, -0.010965694208552973, 0.008842220906090622, -0.008473795267834167, -0.025776413434630545, -0.031028158420119814, -0.0011195122973433058, -0.006832625541945404, 0.023539063590834984, 0.007904409767200275, -0.00411632162335836, 0.042978553067222126, -0.04356803557854864, 0.002686159566701383, 0.03354685151245022, 0.0092776337860213, -0.020229930918768475, 0.02475821890958279, 0.004524939420354826, -0.029474069686968744, -0.008420206033288358, -0.0016277725336676376, -0.037083739129828375, -0.009217345547911286, 0.02116774112633621, 0.005332127440324063, 0.008058478467273495, -0.008286232481262529, 0.0005308682092002607, -0.002510320036367106, 0.0031667879267226113, -0.02619173116651383, -0.013377208831791759, 0.009411606406724516, -0.004012492656048846, 0.02257445923165565, 0.02301656925250531, 0.015594462596217313, -0.0010240565024124155, -0.02257445923165565, 0.004072780428497554, 0.018729432351485827, -0.000571478764624717, -0.021462482381999465, 0.0036440667849617363, -0.0006832625076284097, 0.008058478467273495, -0.017992579212327685, -0.005650313345816812, -0.014147553263480474, -0.037512453006194844, 0.021837606092497512, 0.006058931142813279, 0.012754234096612057, -0.00908337292720807, 0.022748624011098877, -0.01897058344128066, 0.01804616937819611, 0.009545579958750345, 0.007073776631740237, -0.03443107155414953, -0.013223140131718538, -0.02702236290498995, -0.017684441812181245, -0.029179330293950714, 0.02329791250104015, 0.01523273503020245, -0.04187997608733958, -0.02436969719195633, -0.010041280145468423, -0.0023763469500025836, 0.0037478959851019043, 0.007998191160486093, -0.014214540505154695, 0.004169910857904169, -0.012573370313604625, -0.028670232100104224, 0.037083739129828375, -0.003771341333423359, 0.019975381821845228, -0.005291935281584052, 0.012064273051080748, -0.002699556875337835, -0.002895492485042117, -0.009170455316929683, -0.027625241560799645, -0.034993758051219216, 0.023056761411245318, -0.0012610212970562533, 0.027263515857430008, -0.006913009393764117, 0.03244827080727721, -0.02155626284396267, 0.015835613686012145, -0.028938177341510656, -0.007448901273560899, 0.029366891217877125, 0.02332470665265175, 0.00011879641311399103, -0.020377299683954873, -0.011488188546882648, 0.014911199622927597, 0.010617363718343908, 0.009304427937632897, -0.014723637767678573, 0.0030813800550613963, -0.01220494467534817, 0.0447469968759112, -0.03311813763608375, -0.0167064394458735, 0.004863221405217581, -0.004082828468182556, 0.00639386362589393, -0.02190459240284912, 0.0033091343018810844, 0.029474069686968744, -0.026700827497715095, -0.006357020968936023, -0.02016294274577164, 0.019868203352753612, -0.004139767204510468, 0.012144656437238154, 0.016974384687279933, -0.0030562601886795437, -0.006514439170791347, 0.007120667328383147, 0.012667151706890445, 0.0025387891717004083, -0.012888206717315272, -0.015018378092019214, -0.005636915804349707, -0.0031718119465651124, -0.008004889232727685, 0.020082560290936847, 0.004337377565105802, -0.01592939601062058, 0.006119218915261987, -0.0065110901346705505, -0.010617363718343908, -0.003433059348560604, 0.004102924547552561, -0.011360913998421027, 0.006253192001626509, 0.014375308208792122, -0.00902978369266226, -0.0389593632702543, 0.013102563655498507, 0.019144748220723883, -0.004414411915142412, 0.0004412737222459024, 0.20631849153407167, -0.003292387724293182, 0.0021469179522918443, 0.03882539064955109, -0.0030730067662674454, -0.014268129739700505, 0.01324323527976593, 0.0003874751729425438, -0.02147587852648265, -0.0013296824747142393, -0.008447000184899956, 0.005060831765812915, -0.004488097229058226, -0.0051981543539595405, 0.008071876474401907, -0.006336924889566018, -0.021810811940885917, -0.0013866209782114978, -0.017563867198606444, -0.001967729153006118, 0.021917990409977533, 0.03459184018910957, -0.00552303879735519, -0.02114094697472461, 0.02197157871320073, 0.003546936355555121, -0.0130355773451469, 0.0056235187285439085, 0.02102037049850458, 0.016371506031470234, 0.0008992940802873701, 0.002103376757431038, -0.00028134339405400154, -0.01181642295772171, 0.002366298910317581, -0.016572464962525058, 0.023163939880336937, -0.011407805160725242, 0.028214724072126156, 0.003684258710871093, 0.0028536258082417086, -0.011501585622688448, -0.010570473487362305, 0.0004479723765641285, -0.015969586306715362, -0.005402463252457773, -0.01036951362498487, -0.02966163247354038, -0.008460398192028368, 0.031724815675247486, -0.024785013061194388, -0.01917154237233548, 0.024476875661047948, 0.016907398376928322, -0.011789627874787496, -0.023967777467201454, 0.007288133569923473, 0.003935458306012236, 0.010423102859530678, 0.0015365033831337227, 0.001595116637522033, 0.02136870005739103, -0.010362815552743277, 0.015982984313843776, -0.019225132538203904, 0.0204040956982117, -0.03609233875639222, -0.02278881430719366, 0.019305516855683925, 0.005368969631620662, -0.01139440715359683, -0.021382098064519444, 0.01627772556950703, 0.015125556561110831, -0.04396995344065828, -0.018742828495969012, 0.016947590535668335, 0.003510093698597214, 0.033144929925050116, 0.059269676643857565, -0.0015231060744972705, 0.017429892715258, -0.00507422930728002, -0.015822217541528964, 0.004712501741265157, -0.03590477783246581, 0.00511107149857662, 0.016572464962525058, -0.03370762014741026, 0.011896806343879116, 0.0020916541996856375, -0.015567668444605717, -0.016143752948803814, -0.024476875661047948, 0.004193356439056277, -0.0062397944601594035, -0.003546936355555121, 0.036655025253461905, 0.008386712878112554, 0.015192543802785055, 0.0010341044256820912, 0.0025806558485008168, 0.021006974354021397, 0.007040283476564433, -0.023364898811391758, -0.005288585779801949, -0.018823212813449033, -0.006574727408901362, 0.004856522867314682, -0.016331313872730225, 0.008915906220006436, -0.015152351644045044, 0.0044613026117853215, 0.0034062647312876997, -0.00631682927585732, 0.010456596014706481, 0.0070871741732073425, -0.04292496476399893, 0.007489093432300909, -0.007415408118385095, 0.0030445373981034893, -0.02155626284396267, 0.01099248836016457, -0.008252739326086726, 0.0044613026117853215, 0.002322757715456775, 0.0007548543829304092, -0.022346704286344006, -0.00347994981237286, -0.04088857198861296, 0.0005011429524910062, -0.028563053631012605, 0.004766090975810966, -0.015085365333693436, -0.0039522048836001375, -0.010403006780160673, -0.004390966799651611, -0.015085365333693436, -0.015996382320972186, 0.003121571980970753, -0.0180059772194561, -0.006330226351663119, 0.0019426091702089382, -0.025133342620080837, 0.013604962845780793, -0.008915906220006436, -0.001165565502125363, -0.003463203234784958, -0.005412511292142776, -0.002056486293618782, -0.030572648529496517, -0.009364716175742914, -0.013404002983403355, 0.0025923784062462174, 0.0279199828164629, -0.017818414432884462, -0.008306328560632533, -0.03941486943558714, 0.01859545973078261, -0.009565675106797736, -0.0003265593107020278, 0.011602066019538473, 0.0279199828164629, 0.03188558431020753, -0.010530281328622295, -0.016398300183081832, -0.1719142122688885, 0.03258224342798043, 0.015045173174953427, -0.007710148908387044, 0.0315640507655779, 0.03590477783246581, 0.0040560338509096515, 0.0029239616203754195, 0.005878067359805846, -0.005208202393644543, 0.029340097066265527, -0.0018638999528659496, -0.01114655706023779, -0.022239525817252387, -0.006735495112538789, 0.002445008011245243, -0.002148592703182896, 0.007991492156921888, 0.014053772801517268, 0.007308229649293478, 0.011836519037091714, -0.006497692593203445, 0.012017381888776532, -0.00463881689301065, 0.007529285125379612, 0.0009470219777528153, -0.017108357307983147, 0.016907398376928322, -0.029125740128082292, -0.025736221275890533, -0.009686251583017766, 0.003093102612806797, 0.02730370615352479, 0.006202952268862803, 0.020176340752900052, 0.014763829926418583, 0.014616459298586956, -0.010114965459384237, -0.008138862784753516, 0.0045852276584648416, 0.01738970055651799, 0.025361097565392485, 0.017309318101683197, -0.0018136601036869173, -0.012412602609967198, 0.01720213963259158, 0.0180059772194561, -0.014670048533132763, 0.0030277908205155876, -0.009820224203720982, 0.007629765056568331, 0.004250294709722882, 0.022279717975992396, -0.00511107149857662, 0.007100571249013142, 0.017295920094554783, 0.025428083875744092, 0.005697203576798415, -0.0034263605778270512, 0.0003809858624856991, -0.01662605512839348, -0.02560224865518732, -0.0028469272703388095, -0.027678831726668067, -0.004685707123992253, -0.008400109953918353, -0.025240521089172456, -0.0009855392109787836, -0.02968842662515198, -0.005107722462455824, 0.002148592703182896, -0.006638364217470867, 0.015179145795656641, 0.012626959548150435, 0.00639386362589393, 0.0015850685978370303, -0.041799591769859555, 0.005251743588505349, 0.005452702985221479, -0.023110349714468514, 0.0015063594969093688, 0.017563867198606444, -0.0031483665982436574, 0.03472581280981279, -0.021743825630534307, 0.0028686978677692127, -0.0130489744209527, -0.0017483483113957077, -0.011494887550446855, 0.009230742623717083, 0.021489276533611063, -0.0009805151911362823, 0.006926406469569916, 0.00739531203901509, -0.01448248667788374, -0.0048498243294117825, 0.03164443508305793, 0.012459493772271416, -0.024088353943421487, -0.01578202538278895, 0.018608855875265794, -0.024517067819787956, -0.0009553952665467662, 0.023043363404116904, 0.04249625088763246, 0.0179791830678445, -0.019801217042402005, 0.018742828495969012, 0.0411029289267962, 0.006514439170791347, -0.028777410569195843, 0.020256725070380073, 0.027049158919246773, 0.012961892031231086, 0.003429710079609154, 0.014013580642777258, 0.02036390353947169, -0.010141759610995834, -0.010469994021834895, -0.0050005439933642065, 0.029366891217877125, -0.002031366427236929, -0.009063276847838066, -0.002619173023519122, 0.0006581425830388934, -0.019037569751632268, -0.0897083544152961, -0.004977098877873405, 0.028670232100104224, -0.0031818597534194614, -0.02073902724996974, 0.02529411125504088, -0.008440302112658364, 0.021489276533611063, 0.0021753873204558003, 0.031028158420119814, -0.009786731048545178, -0.012546576161993029, 0.008567576661119986, -0.005382367173087768, -0.02198497672032914, 0.010610665646102316, 0.0005417535079154624, -0.009130263158189673, 0.007569477284119623, 0.014174348346414685, -0.004153164280316267, -0.015246133037330863, -0.005315380397074854, -0.018823212813449033, 0.0010985789589431018, 0.003146691847352606, -0.03638708001205548, 0.013571469690604989, 0.024985973854894438, -0.0018387800864840967, 0.003325880879468986, -0.0253744955725209, -0.007877614684266064, -0.044639820269464815, -0.034377483250926336, -0.004769440477593069, -0.006373767546523926, -0.024932383689026016, 0.015165748719850842, -0.04228189394944922, -0.009686251583017766, -0.002548837211385411, 0.03619951536283861, -0.04134408187923626, -0.016894000369799912, -0.006688604415895879, 0.0032789904156567302, 0.01681361791496512, 0.012653754631084646, -0.03713732743305157, -0.001716529674280302, 0.0006899611619466358, -0.01492459763005601, -0.012928398876055283, 0.052249489712324446, -0.007596271901392527, -0.013397304911161763, 0.008152259860559313, -0.024275916729993123, -0.027008966760506764, -0.005007242531267106, -0.019961983814716817, -0.007113968790480247, 0.0027799407271565484, 0.013497784376689175, 0.005449353483439376, -0.015473887051319897, -0.00836661679874255, 0.019894997504365207, -0.02783959849898288, -0.004752693900005167, 0.02506635630972923, -0.02742428262974482, -0.012975289107036886, -0.0484446531282494, -0.0123992055341614, -0.01535331150642248, -0.028134339754646135, 0.0044813982254940194, -5.6886211187660726e-05, -0.000700009143423975, -0.012285328061505577, -0.015433694892579886, -0.004518240882451926, -0.010396308707919081, 0.0012467866129742752, -0.027491268940096427, 0.01318964604522012, 0.014187745422220484, -0.026392690097568654, 0.0016914096914831223, 0.022855802480190496, 0.02071223309835814, -0.02229311412047558, -0.009438401489658728, 0.022306512127603994, -0.00042034044205336164, 0.0029959721834001817, -0.017644249653441236, 0.006628316643447171, -0.04351444727532544, 0.0018605506839145, -0.07984793525886727, 0.018180141998899325, -0.029795605094243595, -0.023673038074183427, 0.015085365333693436, -0.02147587852648265, 0.002103376757431038, -0.019265324696943916, 0.014897802547121797, 0.016130354941675404, -0.007529285125379612, -0.00940490740316031, -0.023163939880336937, 0.006892913314394112, -0.00671874806928958, -0.02548167404161252, 0.022413690596695613, 0.002791663284901949, 0.017322714246166382, 0.0011898481094770167, -0.010731241190999732, -0.029875989411723616, 0.007355120345936387, 0.021261521588299415, -0.02329791250104015, 0.03239468250405402, -0.015098762409499235, 0.027317104160653204, -0.008721645361193206, -0.03759283732367487, 0.005707251616483417, -0.025012768006506036, 0.0025521864803368607, 0.016894000369799912, 0.02178401778927432, -0.011528380705622659, 0.025119946475597652, 0.011736038640241689, 0.01947968163512715, 0.025856797752110566, -0.0024969227277306535, -0.0070603795559344385, -0.006564679369216359, -0.025508468193224113, -0.001934235881414987, -0.0024165388759119404, -0.002609124983834119, 0.003992396576678841, -0.004183308399371275, 0.002004571809964025, 0.04793555493440291, 0.00908337292720807, -0.04619390713997066, -0.024235724571253114, 0.010382910700790667, -0.023498871432094975, 0.012251834906329771, 0.003788087911011261, 0.0032722916449231775, -0.0035670324349251262, 0.04863221405217581, 0.009351319099937114, 0.01523273503020245, -0.0058881153994908494, 0.03550285624506571, -0.006072328218619077, -0.00637041851040313, 0.027491268940096427, 0.026352497938828642, -0.034216714615966294, -0.044077133772395125, 0.000406733789555528, -0.0013196345514445635, 0.015996382320972186, 0.029420481383745548, 0.013008783193535304, -0.005757491814908431, 0.003684258710871093, -0.017376304412034804, 0.005271839202214047, -0.004022540695733848, -0.006176157651589899, -0.02270843185235887, 0.020779219408709748, 0.02190459240284912, 0.011166653139607796, -0.001224178756513673, 0.001232552045307624, 0.00012518106619206082, 0.02083280957457817, -0.03429709893344631, -0.00637041851040313, 0.00020786755496681164, 0.002282565789547418, -0.008942701302940649, -0.004776139015495969, -0.002383045487905483, -0.007006790321388629, -0.001790214871780789, -0.0020296916763458774, 0.023619447908315005, -0.006243143961941506, 0.006129266954946989, -0.02578981144175896, -0.02229311412047558, 0.008393410950354147, -0.020538068318914915, -0.009733141813999369, 0.00236127489047508, 0.008031684315661897, 0.025052960165246045, 0.00017468829916775325, -0.023431885121743365, 0.014804022085158594, -0.010617363718343908, -0.008205849095105123, 0.002307685655929271, -0.01336381175598596, -0.008795330675109021, 0.03877179862103743, 0.00850728842300997, 0.004565131579094836, 0.019948585807588404, 0.005315380397074854, 0.005770888890714229, -0.00029034471443209687, 0.010476692094076487, -0.006068979182498281, 0.012432698689337204, 0.021395496071647858, -0.027786010195759686, 0.023257720342300142, -0.015112159485305034, -0.016063368631323793, -0.010550377407992301, 0.005131167577946625, -0.014281526815506302, 0.00850728842300997, -0.029715220776763578, 0.09126244128580194, 0.01190350534744332, -0.01713515332223997, 0.01962705040031355, -0.007348421808033488, 0.00451489184633113, 0.006979995704115725, 0.003014393511879135, -0.01921173453107549, -0.011669052329890081, 0.006926406469569916, 0.00739531203901509, 0.002870372618660264, 0.0011471441736464094, 0.012064273051080748, 0.003032814840358089, -0.02159645500270268, 0.02197157871320073, 0.013296824514311738, 0.0017650948889836096, 0.0001195290802490365, 0.014361910201663709, -0.01351788045605918, 0.0034280353287181025, -0.013625058925150799, 0.012077670126886547, 0.029393687232133953, -0.026138141000645407, -0.007911108770764482, -0.009706347662387772, 0.018381102792599375, 0.00547614810071228, -0.016049970624195383, 0.0016244231483008612, 0.001950982459002889, 0.0016202365039038858, -0.005191455350395334, -0.011521681702058452, 0.008755138516369011, 0.002753146109883644, -0.0030009962032426832, 0.027263515857430008, -0.013330317669487541, -0.016974384687279933, -0.0026660637201620313, -0.024985973854894438, -0.0179791830678445, -0.0075225865874767135, -0.009980991907358409]\n",
      "Do let me know if you have any questions and I am excited to have the possibility to work on this project!\n",
      "To know about my experience please visit my Github profile https://github.com/israr96418\n",
      "Best regards,\n",
      "\n",
      "Israr Dawar\n"
     ]
    }
   ],
   "source": [
    "search_by_vectores = underlying_embedding.embed_query(query)\n",
    "print(search_by_vectores)\n",
    "docs = db.similarity_search_by_vector(search_by_vectores)\n",
    "print(docs[0].page_content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asynchronous operations:\n",
    "Vector stores are usually run as a separate service that requires some IO operations, and therefore they might be called asynchronously. That gives performance benefits as you don't waste time waiting for responses from external services. That might also be important if you work with an asynchronous framework, such as FastAPI.\n",
    "\n",
    "LangChain supports async operation on vector stores. All the methods might be called using their async counterparts, with the prefix a, meaning async.\n",
    "\n",
    "\"Qdrant\" is a vector store, which supports all the async operations, thus it will be used in this walkthrough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Qdrant   # vectores stores which support asyn operatio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vectores stores Asynchronoulsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResponseHandlingException",
     "evalue": "[Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/httpcore/_exceptions.py:10\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:  \u001b[39m# noqa: PIE786\u001b[39;00m\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/httpcore/_backends/sync.py:212\u001b[0m, in \u001b[0;36mSyncBackend.connect_tcp\u001b[0;34m(self, host, port, timeout, local_address, socket_options)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[39mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m--> 212\u001b[0m     sock \u001b[39m=\u001b[39m socket\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[1;32m    213\u001b[0m         address,\n\u001b[1;32m    214\u001b[0m         timeout,\n\u001b[1;32m    215\u001b[0m         source_address\u001b[39m=\u001b[39;49msource_address,\n\u001b[1;32m    216\u001b[0m     )\n\u001b[1;32m    217\u001b[0m     \u001b[39mfor\u001b[39;00m option \u001b[39min\u001b[39;00m socket_options:\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:845\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 845\u001b[0m     \u001b[39mraise\u001b[39;00m err\n\u001b[1;32m    846\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    847\u001b[0m     \u001b[39m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:833\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    832\u001b[0m     sock\u001b[39m.\u001b[39mbind(source_address)\n\u001b[0;32m--> 833\u001b[0m sock\u001b[39m.\u001b[39;49mconnect(sa)\n\u001b[1;32m    834\u001b[0m \u001b[39m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mConnectError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/httpx/_transports/default.py:66\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 66\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:  \u001b[39m# noqa: PIE-786\u001b[39;00m\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/httpx/_transports/default.py:228\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 228\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pool\u001b[39m.\u001b[39;49mhandle_request(req)\n\u001b[1;32m    230\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(resp\u001b[39m.\u001b[39mstream, typing\u001b[39m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:262\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresponse_closed(status)\n\u001b[0;32m--> 262\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n\u001b[1;32m    263\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:245\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 245\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[1;32m    246\u001b[0m \u001b[39mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    247\u001b[0m     \u001b[39m# The ConnectionNotAvailable exception is a special case, that\u001b[39;00m\n\u001b[1;32m    248\u001b[0m     \u001b[39m# indicates we need to retry the request on a new connection.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[39m# might end up as an HTTP/2 connection, but which actually ends\u001b[39;00m\n\u001b[1;32m    253\u001b[0m     \u001b[39m# up as HTTP/1.1.\u001b[39;00m\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/httpcore/_sync/connection.py:99\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connect_failed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m         \u001b[39mraise\u001b[39;00m exc\n\u001b[1;32m    100\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connection\u001b[39m.\u001b[39mis_available():\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/httpcore/_sync/connection.py:76\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connect(request)\n\u001b[1;32m     78\u001b[0m     ssl_object \u001b[39m=\u001b[39m stream\u001b[39m.\u001b[39mget_extra_info(\u001b[39m\"\u001b[39m\u001b[39mssl_object\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/httpcore/_sync/connection.py:124\u001b[0m, in \u001b[0;36mHTTPConnection._connect\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39mwith\u001b[39;00m Trace(\u001b[39m\"\u001b[39m\u001b[39mconnect_tcp\u001b[39m\u001b[39m\"\u001b[39m, logger, request, kwargs) \u001b[39mas\u001b[39;00m trace:\n\u001b[0;32m--> 124\u001b[0m     stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_network_backend\u001b[39m.\u001b[39;49mconnect_tcp(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    125\u001b[0m     trace\u001b[39m.\u001b[39mreturn_value \u001b[39m=\u001b[39m stream\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/httpcore/_backends/sync.py:211\u001b[0m, in \u001b[0;36mSyncBackend.connect_tcp\u001b[0;34m(self, host, port, timeout, local_address, socket_options)\u001b[0m\n\u001b[1;32m    206\u001b[0m exc_map: ExceptionMapping \u001b[39m=\u001b[39m {\n\u001b[1;32m    207\u001b[0m     socket\u001b[39m.\u001b[39mtimeout: ConnectTimeout,\n\u001b[1;32m    208\u001b[0m     \u001b[39mOSError\u001b[39;00m: ConnectError,\n\u001b[1;32m    209\u001b[0m }\n\u001b[0;32m--> 211\u001b[0m \u001b[39mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    212\u001b[0m     sock \u001b[39m=\u001b[39m socket\u001b[39m.\u001b[39mcreate_connection(\n\u001b[1;32m    213\u001b[0m         address,\n\u001b[1;32m    214\u001b[0m         timeout,\n\u001b[1;32m    215\u001b[0m         source_address\u001b[39m=\u001b[39msource_address,\n\u001b[1;32m    216\u001b[0m     )\n",
      "File \u001b[0;32m/usr/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen\u001b[39m.\u001b[39;49mthrow(typ, value, traceback)\n\u001b[1;32m    154\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[39m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[39m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[39m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/httpcore/_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(exc, from_exc):\n\u001b[0;32m---> 14\u001b[0m         \u001b[39mraise\u001b[39;00m to_exc(exc) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mConnectError\u001b[0m: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mConnectError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/qdrant_client/http/api_client.py:101\u001b[0m, in \u001b[0;36mApiClient.send_inner\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49msend(request)\n\u001b[1;32m    102\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/httpx/_client.py:901\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    899\u001b[0m auth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 901\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_auth(\n\u001b[1;32m    902\u001b[0m     request,\n\u001b[1;32m    903\u001b[0m     auth\u001b[39m=\u001b[39;49mauth,\n\u001b[1;32m    904\u001b[0m     follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    905\u001b[0m     history\u001b[39m=\u001b[39;49m[],\n\u001b[1;32m    906\u001b[0m )\n\u001b[1;32m    907\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/httpx/_client.py:929\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 929\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_redirects(\n\u001b[1;32m    930\u001b[0m         request,\n\u001b[1;32m    931\u001b[0m         follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    932\u001b[0m         history\u001b[39m=\u001b[39;49mhistory,\n\u001b[1;32m    933\u001b[0m     )\n\u001b[1;32m    934\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/httpx/_client.py:966\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    964\u001b[0m     hook(request)\n\u001b[0;32m--> 966\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_single_request(request)\n\u001b[1;32m    967\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/httpx/_client.py:1002\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[39mwith\u001b[39;00m request_context(request\u001b[39m=\u001b[39mrequest):\n\u001b[0;32m-> 1002\u001b[0m     response \u001b[39m=\u001b[39m transport\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[1;32m   1004\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(response\u001b[39m.\u001b[39mstream, SyncByteStream)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/httpx/_transports/default.py:227\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    215\u001b[0m req \u001b[39m=\u001b[39m httpcore\u001b[39m.\u001b[39mRequest(\n\u001b[1;32m    216\u001b[0m     method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[1;32m    217\u001b[0m     url\u001b[39m=\u001b[39mhttpcore\u001b[39m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m     extensions\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    226\u001b[0m )\n\u001b[0;32m--> 227\u001b[0m \u001b[39mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m    228\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool\u001b[39m.\u001b[39mhandle_request(req)\n",
      "File \u001b[0;32m/usr/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen\u001b[39m.\u001b[39;49mthrow(typ, value, traceback)\n\u001b[1;32m    154\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[39m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[39m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[39m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/httpx/_transports/default.py:83\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m message \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(exc)\n\u001b[0;32m---> 83\u001b[0m \u001b[39mraise\u001b[39;00m mapped_exc(message) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[0;31mConnectError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResponseHandlingException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32m/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb Cell 296\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y551sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m vectore_db \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m Qdrant\u001b[39m.\u001b[39mafrom_documents(splitted_docs ,underlying_embedding, url\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttp://localhost:6333\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m# vectore database will be stored at the specified ulr\u001b[39;00m\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/schema/vectorstore.py:450\u001b[0m, in \u001b[0;36mVectorStore.afrom_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m texts \u001b[39m=\u001b[39m [d\u001b[39m.\u001b[39mpage_content \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    449\u001b[0m metadatas \u001b[39m=\u001b[39m [d\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m documents]\n\u001b[0;32m--> 450\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mawait\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mafrom_texts(texts, embedding, metadatas\u001b[39m=\u001b[39mmetadatas, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/vectorstores/qdrant.py:55\u001b[0m, in \u001b[0;36msync_call_fallback.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(method)\n\u001b[1;32m     53\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39mself\u001b[39m: Any, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m     54\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 55\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mawait\u001b[39;00m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     56\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m         \u001b[39m# If the async method is not implemented, call the synchronous method\u001b[39;00m\n\u001b[1;32m     58\u001b[0m         \u001b[39m# by removing the first letter from the method name. For example,\u001b[39;00m\n\u001b[1;32m     59\u001b[0m         \u001b[39m# if the async method is called ``aaad_texts``, the synchronous method\u001b[39;00m\n\u001b[1;32m     60\u001b[0m         \u001b[39m# will be called ``aad_texts``.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m         sync_method \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(\n\u001b[1;32m     62\u001b[0m             \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m[\u001b[39m1\u001b[39m:]), \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m     63\u001b[0m         )\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/vectorstores/qdrant.py:1477\u001b[0m, in \u001b[0;36mQdrant.afrom_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, location, url, port, grpc_port, prefer_grpc, https, api_key, prefix, timeout, host, path, collection_name, distance_func, content_payload_key, metadata_payload_key, vector_name, batch_size, shard_number, replication_factor, write_consistency_factor, on_disk_payload, hnsw_config, optimizers_config, wal_config, quantization_config, init_from, on_disk, force_recreate, **kwargs)\u001b[0m\n\u001b[1;32m   1336\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m   1337\u001b[0m \u001b[39m@sync_call_fallback\u001b[39m\n\u001b[1;32m   1338\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mafrom_texts\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1372\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1373\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Qdrant:\n\u001b[1;32m   1374\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Construct Qdrant wrapper from a list of texts.\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m \n\u001b[1;32m   1376\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1475\u001b[0m \u001b[39m            qdrant = await Qdrant.afrom_texts(texts, embeddings, \"localhost\")\u001b[39;00m\n\u001b[1;32m   1476\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1477\u001b[0m     qdrant \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39maconstruct_instance(\n\u001b[1;32m   1478\u001b[0m         texts,\n\u001b[1;32m   1479\u001b[0m         embedding,\n\u001b[1;32m   1480\u001b[0m         location,\n\u001b[1;32m   1481\u001b[0m         url,\n\u001b[1;32m   1482\u001b[0m         port,\n\u001b[1;32m   1483\u001b[0m         grpc_port,\n\u001b[1;32m   1484\u001b[0m         prefer_grpc,\n\u001b[1;32m   1485\u001b[0m         https,\n\u001b[1;32m   1486\u001b[0m         api_key,\n\u001b[1;32m   1487\u001b[0m         prefix,\n\u001b[1;32m   1488\u001b[0m         timeout,\n\u001b[1;32m   1489\u001b[0m         host,\n\u001b[1;32m   1490\u001b[0m         path,\n\u001b[1;32m   1491\u001b[0m         collection_name,\n\u001b[1;32m   1492\u001b[0m         distance_func,\n\u001b[1;32m   1493\u001b[0m         content_payload_key,\n\u001b[1;32m   1494\u001b[0m         metadata_payload_key,\n\u001b[1;32m   1495\u001b[0m         vector_name,\n\u001b[1;32m   1496\u001b[0m         shard_number,\n\u001b[1;32m   1497\u001b[0m         replication_factor,\n\u001b[1;32m   1498\u001b[0m         write_consistency_factor,\n\u001b[1;32m   1499\u001b[0m         on_disk_payload,\n\u001b[1;32m   1500\u001b[0m         hnsw_config,\n\u001b[1;32m   1501\u001b[0m         optimizers_config,\n\u001b[1;32m   1502\u001b[0m         wal_config,\n\u001b[1;32m   1503\u001b[0m         quantization_config,\n\u001b[1;32m   1504\u001b[0m         init_from,\n\u001b[1;32m   1505\u001b[0m         on_disk,\n\u001b[1;32m   1506\u001b[0m         force_recreate,\n\u001b[1;32m   1507\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   1508\u001b[0m     )\n\u001b[1;32m   1509\u001b[0m     \u001b[39mawait\u001b[39;00m qdrant\u001b[39m.\u001b[39maadd_texts(texts, metadatas, ids, batch_size)\n\u001b[1;32m   1510\u001b[0m     \u001b[39mreturn\u001b[39;00m qdrant\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/vectorstores/qdrant.py:1750\u001b[0m, in \u001b[0;36mQdrant.aconstruct_instance\u001b[0;34m(cls, texts, embedding, location, url, port, grpc_port, prefer_grpc, https, api_key, prefix, timeout, host, path, collection_name, distance_func, content_payload_key, metadata_payload_key, vector_name, shard_number, replication_factor, write_consistency_factor, on_disk_payload, hnsw_config, optimizers_config, wal_config, quantization_config, init_from, on_disk, force_recreate, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[39m# Get the vector configuration of the existing collection and vector, if it\u001b[39;00m\n\u001b[1;32m   1748\u001b[0m \u001b[39m# was specified. If the old configuration does not match the current one,\u001b[39;00m\n\u001b[1;32m   1749\u001b[0m \u001b[39m# an exception is being thrown.\u001b[39;00m\n\u001b[0;32m-> 1750\u001b[0m collection_info \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mget_collection(collection_name\u001b[39m=\u001b[39;49mcollection_name)\n\u001b[1;32m   1751\u001b[0m current_vector_config \u001b[39m=\u001b[39m collection_info\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mparams\u001b[39m.\u001b[39mvectors\n\u001b[1;32m   1752\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(current_vector_config, \u001b[39mdict\u001b[39m) \u001b[39mand\u001b[39;00m vector_name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/qdrant_client/qdrant_client.py:1286\u001b[0m, in \u001b[0;36mQdrantClient.get_collection\u001b[0;34m(self, collection_name, **kwargs)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Get detailed information about specified existing collection\u001b[39;00m\n\u001b[1;32m   1277\u001b[0m \n\u001b[1;32m   1278\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[39m    Detailed information about the collection\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(kwargs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown arguments: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1286\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49mget_collection(collection_name\u001b[39m=\u001b[39;49mcollection_name, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/qdrant_client/qdrant_remote.py:1626\u001b[0m, in \u001b[0;36mQdrantRemote.get_collection\u001b[0;34m(self, collection_name, **kwargs)\u001b[0m\n\u001b[1;32m   1619\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prefer_grpc:\n\u001b[1;32m   1620\u001b[0m     \u001b[39mreturn\u001b[39;00m GrpcToRest\u001b[39m.\u001b[39mconvert_collection_info(\n\u001b[1;32m   1621\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrpc_collections\u001b[39m.\u001b[39mGet(\n\u001b[1;32m   1622\u001b[0m             grpc\u001b[39m.\u001b[39mGetCollectionInfoRequest(collection_name\u001b[39m=\u001b[39mcollection_name),\n\u001b[1;32m   1623\u001b[0m             timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout,\n\u001b[1;32m   1624\u001b[0m         )\u001b[39m.\u001b[39mresult\n\u001b[1;32m   1625\u001b[0m     )\n\u001b[0;32m-> 1626\u001b[0m result: Optional[types\u001b[39m.\u001b[39mCollectionInfo] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhttp\u001b[39m.\u001b[39;49mcollections_api\u001b[39m.\u001b[39;49mget_collection(\n\u001b[1;32m   1627\u001b[0m     collection_name\u001b[39m=\u001b[39;49mcollection_name\n\u001b[1;32m   1628\u001b[0m )\u001b[39m.\u001b[39mresult\n\u001b[1;32m   1629\u001b[0m \u001b[39massert\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mGet collection returned None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1630\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/qdrant_client/http/api/collections_api.py:1144\u001b[0m, in \u001b[0;36mSyncCollectionsApi.get_collection\u001b[0;34m(self, collection_name)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_collection\u001b[39m(\n\u001b[1;32m   1138\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1139\u001b[0m     collection_name: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   1140\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m m\u001b[39m.\u001b[39mInlineResponse2005:\n\u001b[1;32m   1141\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m \u001b[39m    Get detailed information about specified existing collection\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1144\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_for_get_collection(\n\u001b[1;32m   1145\u001b[0m         collection_name\u001b[39m=\u001b[39;49mcollection_name,\n\u001b[1;32m   1146\u001b[0m     )\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/qdrant_client/http/api/collections_api.py:307\u001b[0m, in \u001b[0;36m_CollectionsApi._build_for_get_collection\u001b[0;34m(self, collection_name)\u001b[0m\n\u001b[1;32m    302\u001b[0m path_params \u001b[39m=\u001b[39m {\n\u001b[1;32m    303\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcollection_name\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mstr\u001b[39m(collection_name),\n\u001b[1;32m    304\u001b[0m }\n\u001b[1;32m    306\u001b[0m headers \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 307\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapi_client\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    308\u001b[0m     type_\u001b[39m=\u001b[39;49mm\u001b[39m.\u001b[39;49mInlineResponse2005,\n\u001b[1;32m    309\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    310\u001b[0m     url\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/collections/\u001b[39;49m\u001b[39m{collection_name}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    311\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders \u001b[39mif\u001b[39;49;00m headers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    312\u001b[0m     path_params\u001b[39m=\u001b[39;49mpath_params,\n\u001b[1;32m    313\u001b[0m )\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/qdrant_client/http/api_client.py:74\u001b[0m, in \u001b[0;36mApiClient.request\u001b[0;34m(self, type_, method, url, path_params, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m url \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m url\u001b[39m.\u001b[39mformat(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpath_params)\n\u001b[1;32m     73\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39mbuild_request(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 74\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(request, type_)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/qdrant_client/http/api_client.py:91\u001b[0m, in \u001b[0;36mApiClient.send\u001b[0;34m(self, request, type_)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msend\u001b[39m(\u001b[39mself\u001b[39m, request: Request, type_: Type[T]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[0;32m---> 91\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmiddleware(request, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend_inner)\n\u001b[1;32m     92\u001b[0m     \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39min\u001b[39;00m [\u001b[39m200\u001b[39m, \u001b[39m201\u001b[39m, \u001b[39m202\u001b[39m]:\n\u001b[1;32m     93\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/qdrant_client/http/api_client.py:200\u001b[0m, in \u001b[0;36mBaseMiddleware.__call__\u001b[0;34m(self, request, call_next)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, request: Request, call_next: Send) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Response:\n\u001b[0;32m--> 200\u001b[0m     \u001b[39mreturn\u001b[39;00m call_next(request)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/qdrant_client/http/api_client.py:103\u001b[0m, in \u001b[0;36mApiClient.send_inner\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39msend(request)\n\u001b[1;32m    102\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mraise\u001b[39;00m ResponseHandlingException(e)\n\u001b[1;32m    104\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "\u001b[0;31mResponseHandlingException\u001b[0m: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "vectore_db = await Qdrant.afrom_documents(splitted_docs ,underlying_embedding, url=\"http://localhost:6333\") # vectore database will be stored at the specified ulr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1346116529.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[90], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    qdrant status\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# similirity search\n",
    "\n",
    "query = \"Give me just github link ?\"\n",
    "searhing_in_vectores_stores = vectore_db.similarity_search(query)\n",
    "print(searhing_in_vectores_stores[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_by_vectores = underlying_embedding.embed_query(query)\n",
    "print(search_by_vectores)\n",
    "docs = db.similarity_search_by_vector(search_by_vectores)\n",
    "print(docs[0].page_content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum marginal relevance search (MMR):\n",
    "Maximal marginal relevance optimizes for similarity to query and diversity among selected documents. It is also supported in async API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "found_docs = await qdrant.amax_marginal_relevance_search(query, k=2, fetch_k=10)\n",
    "for i, doc in enumerate(found_docs):\n",
    "    print(f\"{i + 1}.\", doc.page_content, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrievers:\n",
    "A retriever is an interface that returns documents given an unstructured query. It is more general than a vector store. A retriever does not need to be able to store documents, only to return (or retrieve) them. Vector stores can be used as the backbone of a retriever, but there are other types of retrievers as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1: MultiQueryRetrievers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance-based vector database retrieval embeds (represents) queries in high-dimensional space and finds similar embedded documents based on \"distance\". But, retrieval may produce different results with subtle changes in query wording or if the embeddings do not capture the semantics of the data well. Prompt engineering / tuning is sometimes done to manually address these problems, but can be tedious.\n",
    "\n",
    "The MultiQueryRetriever automates the process of prompt tuning by using an LLM to generate multiple queries from different perspectives for a given user input query. For each query, it retrieves a set of relevant documents and takes the unique union across all queries to get a larger set of potentially relevant documents. By generating multiple perspectives on the same question, the MultiQueryRetriever might be able to overcome some of the limitations of the distance-based retrieval and get a richer set of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Iâ€™ve applied to 230 Data science jobs and this is what Iâ€™ve found. | by Virat Patel | MediumMember-only storyIâ€™ve applied to 230 Data science jobs and this is what Iâ€™ve found.A little bit about myself: I have been working as a Data Analyst for a little over 2 years. Additionally, for the past year, I have been teaching myself the concepts of data science while simultaneously working on my own project. Over the last year, I have acquired a substantial amount of knowledge and skills.Virat PatelÂ·Follow3 min readÂ·Aug 11--35Sharesource: https://unsplash.com/s/photos/data-scienceAlthough I am happy with my current role and compensation, which aligns with that of a Data Scientist, I remain interested in transitioning to a career in Data Science. For the past two months, I have been actively applying for Data Science positions, and during my job hunt, I have come across several noteworthy observations:Disclaimer: The following observations are intended to share my personal insights and are not meant to demotivate anyone.Data science alone is not sufficient: While I may not be fully aware of the past circumstances, I have observed a current trend where around 30% to 35% of jobs are oriented towards roles such as AI programmers, full-stack data scientists, and statistical programmers. These positions demand skills beyond traditional data science expertise.Most of the Jobs are niche specific: Many jobs in data science are focused on specific areas. For example, if you want to work with data in the insurance field, you might need to know about pricing models. On the other hand, if youâ€™re looking to work in a call center, they might want you to understand NLP (Natural Language Processing) models. So, having deep knowledge in one particular area can really help you stand out.Getting a higher qualification matters: I read articles last year about people entering data science jobs after attending boot camps or teaching themselves. Iâ€™m not sure if this still happens, but from what Iâ€™ve seen, around 40% of job ads ask for a masterâ€™s or Ph.D. in a quantitative field. And if not that, then about 90% of jobs prefer a bachelorâ€™s degree in engineering, math, or physics.----35FollowWritten by Virat Patel705 FollowersI am a data analyst | Python and finance enthusiast https://www.youtube.com/@anythingwithvirat177 https://www.linkedin.com/in/viratpatel007/FollowMore from Virat PatelVirat PatelSQL Interview Success: 10 Proven Tips to Master the Data Game ðŸš€Whether youâ€™re aiming for a data engineer, data scientist, or data analyst position, mastering SQL is a must. Hereâ€™s a step-by-step guideâ€¦Â·2 min readÂ·Aug 8--Virat PatelThe Future of Data Analyst Jobs: World Economic Forum ReportSince the launch of ChatGPT, debates have been raging, particularly within the tech field, about whether ChatGPT will replace dataâ€¦Â·2 min readÂ·Aug 5--3Virat PatelData Analyst: Why they are not calling you for an interview?â€œSome people never go crazy. What truly horrible lives they must lead. â€œâ€Šâ€”â€ŠCharles BukowskiÂ·2 min readÂ·Feb 24--3Virat PatelWhich syntax I use in SQL as a Full-Time Data Analyst working in Finance Industry, Part: I.When I was Learning SQL as Part of My Roadmap, I Used to watch tons of YouTube videos and try to learn different syntaxes every day in theâ€¦Â·4 min readÂ·Jan 20--2See all from Virat PatelRecommended from MediumVirat PatelThe Future of Data Analyst Jobs: World Economic Forum ReportSince the launch of ChatGPT, debates have been raging, particularly within the tech field, about whether ChatGPT will replace dataâ€¦Â·2 min readÂ·Aug 5--3AL AnanyThe ChatGPT Hype Is Overâ€Šâ€”â€ŠNow Watch How Google Will Kill ChatGPT.It never happens instantly. The business game is longer than you know.Â·6 min readÂ·Sep 1--423ListsPredictive Modeling w/ Python20 storiesÂ·490 savesNew_Reading_List174 storiesÂ·149 savesPractical Guides to Machine Learning10 storiesÂ·560 savesCoding & Development11 storiesÂ·216 savesKhouloud El AlamiinTowards Data ScienceDonâ€™t Start Your Data Science Journey Without These 5 Must-Do Steps From a Spotify Data ScientistA complete guide to everything I wish Iâ€™d done before starting my Data Science journey, hereâ€™s to acing your first year with data18 min readÂ·Sep 24--23MargaretEfroninLearning Data5 Things I Wish I Knew Before My First Job as a Data AnalystIâ€™m five months into my first Data Analyst job, and there are many surprises I wish someone had warned me about! I will list them below, soâ€¦5 min readÂ·Aug 23--24Alex Mathers14 habits that make you more focused than 98% of peopleWhatâ€™s the deal with staying focused?Â·3 min readÂ·May 18--124Zach QuinninPipeline: Your Data Engineering Resource3 Data Science Projects That Got Me 12 Interviews. And 1 That Got Me in Trouble.3 work samples that got my foot in the door, and 1 that almost got me tossed out.Â·7 min readÂ·Aug 29, 2022--49See more recommendationsHelpStatusAboutCareersBlogPrivacyTermsText to speechTeams\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://medium.com/@viratpatel75/i-applied-to-230-data-science-jobs-during-last-2-months-and-this-is-what-ive-found-29ebdea4504', 'title': 'Iâ€™ve applied to 230 Data science jobs and this is what Iâ€™ve found. | by Virat Patel | Medium', 'description': 'Although I am happy with my current role and compensation, which aligns with that of a Data Scientist, I remain interested in transitioning to a career in Data Science. For the past two months, Iâ€¦', 'language': 'en'})]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with the help WebBaseLoader load blog post\n",
    "loader = WebBaseLoader(\"https://medium.com/@viratpatel75/i-applied-to-230-data-science-jobs-during-last-2-months-and-this-is-what-ive-found-29ebdea4504\")\n",
    "data = loader.load()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text splits into chunks\n",
    "text_splitting = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap = 0)\n",
    "splites_data = text_splitting.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VectorDB ---> first we convert data into embedding(means vector)\n",
    "embedding = OpenAIEmbeddings(openai_api_key=\"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\")\n",
    "vectordb = Chroma.from_documents(documents = splites_data, embedding = embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simply usage:\n",
    "# specify LLM to use for the query generation, and use that queries for the retriever\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "question = \"How many year's of experince they have as a data anaylst\"\n",
    "llm = ChatOpenAI(openai_api_key=\"\", temperature=0)\n",
    "retriever_diff_query_from_llm = MultiQueryRetriever.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=vectordb.as_retriever()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_docs = retriever_diff_query_from_llm.get_relevant_documents(query=question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_docs)   # here we check how many queries they create from user question/query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='data scientist, or data analyst position, mastering SQL is a must. Hereâ€™s a step-by-step guideâ€¦Â·2 min readÂ·Aug 8--Virat PatelThe Future of Data Analyst Jobs: World Economic Forum ReportSince the launch of ChatGPT, debates have been raging, particularly within the tech field, about whether ChatGPT will replace dataâ€¦Â·2 min readÂ·Aug 5--3Virat PatelData Analyst: Why they are not calling you for an interview?â€œSome people never go crazy. What truly horrible lives they must lead. â€œâ€Šâ€”â€ŠCharles', metadata={'description': 'Although I am happy with my current role and compensation, which aligns with that of a Data Scientist, I remain interested in transitioning to a career in Data Science. For the past two months, Iâ€¦', 'language': 'en', 'source': 'https://medium.com/@viratpatel75/i-applied-to-230-data-science-jobs-during-last-2-months-and-this-is-what-ive-found-29ebdea4504', 'title': 'Iâ€™ve applied to 230 Data science jobs and this is what Iâ€™ve found. | by Virat Patel | Medium'}),\n",
       " Document(page_content='These 5 Must-Do Steps From a Spotify Data ScientistA complete guide to everything I wish Iâ€™d done before starting my Data Science journey, hereâ€™s to acing your first year with data18 min readÂ·Sep 24--23MargaretEfroninLearning Data5 Things I Wish I Knew Before My First Job as a Data AnalystIâ€™m five months into my first Data Analyst job, and there are many surprises I wish someone had warned me about! I will list them below, soâ€¦5 min readÂ·Aug 23--24Alex Mathers14 habits that make you more focused', metadata={'description': 'Although I am happy with my current role and compensation, which aligns with that of a Data Scientist, I remain interested in transitioning to a career in Data Science. For the past two months, Iâ€¦', 'language': 'en', 'source': 'https://medium.com/@viratpatel75/i-applied-to-230-data-science-jobs-during-last-2-months-and-this-is-what-ive-found-29ebdea4504', 'title': 'Iâ€™ve applied to 230 Data science jobs and this is what Iâ€™ve found. | by Virat Patel | Medium'}),\n",
       " Document(page_content='Iâ€™ve applied to 230 Data science jobs and this is what Iâ€™ve found. | by Virat Patel | MediumMember-only storyIâ€™ve applied to 230 Data science jobs and this is what Iâ€™ve found.A little bit about myself: I have been working as a Data Analyst for a little over 2 years. Additionally, for the past year, I have been teaching myself the concepts of data science while simultaneously working on my own project. Over the last year, I have acquired a substantial amount of knowledge and skills.Virat', metadata={'description': 'Although I am happy with my current role and compensation, which aligns with that of a Data Scientist, I remain interested in transitioning to a career in Data Science. For the past two months, Iâ€¦', 'language': 'en', 'source': 'https://medium.com/@viratpatel75/i-applied-to-230-data-science-jobs-during-last-2-months-and-this-is-what-ive-found-29ebdea4504', 'title': 'Iâ€™ve applied to 230 Data science jobs and this is what Iâ€™ve found. | by Virat Patel | Medium'})]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2: Contextual compression retriever**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Means that the information most relevant to a query may be buried in a document with a lot of irrelevant text. Passing that full document through your application can lead to more expensive LLM calls and poorer responses.\n",
    "\n",
    "Contextual compression is meant to fix this. The idea is simple: instead of immediately returning retrieved documents as-is, you can compress them using the context of the given query, so that only the relevant information is returned. “Compressing” here refers to both compressing the contents of an individual document and filtering out documents wholesale.\n",
    "\n",
    "To use the Contextual Compression Retriever, you'll need:\n",
    "\n",
    "**A:** base retriever<br>\n",
    "**B:** Document Compressor<br>\n",
    "The Contextual Compression Retriever passes queries to the base retriever, takes the initial documents and passes them through the Document Compressor. The Document Compressor takes a list of documents and shortens it by reducing the contents of documents or dropping documents altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for printing docs\n",
    "\n",
    "def pretty_print_docs(docs):\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_text = OpenAIEmbeddings(openai_api_key=\"\")\n",
    "# embedding_text = OpenAIEmbeddings(openai_api_key=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Incorrect API key provided: sk-N8qid***************************************PFbA. You can find your API key at https://platform.openai.com/account/api-keys.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb Cell 317\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y631sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m texts \u001b[39m=\u001b[39m text_splitter\u001b[39m.\u001b[39msplit_documents(load_docs)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y631sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# After splitting the documents into chunks -- we do embeding(vectors) of the chunks\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Y631sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m retriever \u001b[39m=\u001b[39m FAISS\u001b[39m.\u001b[39;49mfrom_documents(texts, embedding_text)\u001b[39m.\u001b[39mas_retriever()\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/schema/vectorstore.py:438\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    436\u001b[0m texts \u001b[39m=\u001b[39m [d\u001b[39m.\u001b[39mpage_content \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    437\u001b[0m metadatas \u001b[39m=\u001b[39m [d\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m documents]\n\u001b[0;32m--> 438\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_texts(texts, embedding, metadatas\u001b[39m=\u001b[39;49mmetadatas, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/vectorstores/faiss.py:602\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    576\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_texts\u001b[39m(\n\u001b[1;32m    577\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    583\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m FAISS:\n\u001b[1;32m    584\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \n\u001b[1;32m    586\u001b[0m \u001b[39m    This is a user friendly interface that:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[39m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m     embeddings \u001b[39m=\u001b[39m embedding\u001b[39m.\u001b[39;49membed_documents(texts)\n\u001b[1;32m    603\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m__from(\n\u001b[1;32m    604\u001b[0m         texts,\n\u001b[1;32m    605\u001b[0m         embeddings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    610\u001b[0m     )\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/embeddings/openai.py:490\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[0;34m(self, texts, chunk_size)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call out to OpenAI's embedding endpoint for embedding search docs.\u001b[39;00m\n\u001b[1;32m    479\u001b[0m \n\u001b[1;32m    480\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[39m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[39m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[39m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_len_safe_embeddings(texts, engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeployment)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/embeddings/openai.py:374\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    371\u001b[0m     _iter \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(tokens), _chunk_size)\n\u001b[1;32m    373\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m _iter:\n\u001b[0;32m--> 374\u001b[0m     response \u001b[39m=\u001b[39m embed_with_retry(\n\u001b[1;32m    375\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    376\u001b[0m         \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mtokens[i : i \u001b[39m+\u001b[39;49m _chunk_size],\n\u001b[1;32m    377\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invocation_params,\n\u001b[1;32m    378\u001b[0m     )\n\u001b[1;32m    379\u001b[0m     batched_embeddings\u001b[39m.\u001b[39mextend(r[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m response[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    381\u001b[0m results: List[List[List[\u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m [[] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(texts))]\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/embeddings/openai.py:107\u001b[0m, in \u001b[0;36membed_with_retry\u001b[0;34m(embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m     response \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m _check_response(response, skip_empty\u001b[39m=\u001b[39membeddings\u001b[39m.\u001b[39mskip_empty)\n\u001b[0;32m--> 107\u001b[0m \u001b[39mreturn\u001b[39;00m _embed_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/embeddings/openai.py:104\u001b[0m, in \u001b[0;36membed_with_retry.<locals>._embed_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_embed_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 104\u001b[0m     response \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m _check_response(response, skip_empty\u001b[39m=\u001b[39membeddings\u001b[39m.\u001b[39mskip_empty)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/openai/api_resources/embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     35\u001b[0m         \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m         \u001b[39m# This is only for the default case.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m user_provided_encoding_format:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    131\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    139\u001b[0m ):\n\u001b[1;32m    140\u001b[0m     (\n\u001b[1;32m    141\u001b[0m         deployment_id,\n\u001b[1;32m    142\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    153\u001b[0m     )\n\u001b[0;32m--> 155\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    156\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    157\u001b[0m         url,\n\u001b[1;32m    158\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    159\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    160\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    161\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    162\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    166\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    167\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/openai/api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    279\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    280\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    288\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    290\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    291\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    298\u001b[0m     )\n\u001b[0;32m--> 299\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/openai/api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    703\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    704\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    707\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    709\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 710\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    711\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    712\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    713\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    714\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    715\u001b[0m         ),\n\u001b[1;32m    716\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    717\u001b[0m     )\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/openai/api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    773\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    774\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 775\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    776\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    777\u001b[0m     )\n\u001b[1;32m    778\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Incorrect API key provided: sk-N8qid***************************************PFbA. You can find your API key at https://platform.openai.com/account/api-keys."
     ]
    }
   ],
   "source": [
    "# docuemnts load\n",
    "load_docs = TextLoader(\"webproposal.txt\").load()\n",
    "\n",
    "# After loading docs split into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=268, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(load_docs)\n",
    "\n",
    "# After splitting the documents into chunks -- we do embeding(vectors) of the chunks\n",
    "retriever = FAISS.from_documents(texts, embedding_text).as_retriever()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I want to get Github link of israr dawar\"\n",
    "docs = retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Do let me know if you have any questions and I am excited to have the possibility to work on this project!\n",
      "To know about my experience please visit my Github profile https://github.com/israr96418\n",
      "Best regards,\n",
      "\n",
      "Israr Dawar\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "My name is Israr dawar and I’d love to help you launch your new website. I am a web developer(Backend), who has worked on many different websites. I studied web development for 2 years and have worked with startups to build their web presence over the past 2 years.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "Hello,\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "I’d be happy to tailor it to your needs. I understand you are a new company and I am happy to be flexible to make sure we work with your timeline. Could you tell me more about your target market and audience? If you are unsure, I can brainstorm with you on this point.\n"
     ]
    }
   ],
   "source": [
    "pretty_print_docs(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see that we get alot of irrelevant docs which we don,t need <br>\n",
    "con\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Contextual compression with an **LLMChainExtractor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's wrap over base_retriver with **ContextualCompressionRetriever**, we will add an **LLMChainExtractor(document_compressor)** which will iterate over the intially returned documents by base_retriver and extract from each only the content that is relevant to the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key=\"\", temperature=0)\n",
    "documents_compressor = LLMChainExtractor.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(base_compressor=documents_compressor , base_retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isrardawar/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "https://github.com/israr96418\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "My name is Israr dawar\n"
     ]
    }
   ],
   "source": [
    "query = \"I want to get Github link of israr dawar\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(query)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More Built-in Compressor: LLMChainFilter(Document compressor)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLMChainFilter is slightly simpler then but more robust that uses an LLM chain to decide which of the intially retreived documents to filter out and which ones to return , without manipulting and documents contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.document_compressors import LLMChainFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_filter = LLMChainFilter.from_llm(llm)\n",
    "compression_retreiver_with_LLMChainFilter = ContextualCompressionRetriever(base_compressor=_filter, base_retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "My name is Israr dawar and I’d love to help you launch your new website. I am a web developer(Backend), who has worked on many different websites. I studied web development for 2 years and have worked with startups to build their web presence over the past 2 years.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Hello,\n"
     ]
    }
   ],
   "source": [
    "query = \"I want to get Github link of israr dawar\"\n",
    "compressed_docs = compression_retreiver_with_LLMChainFilter.get_relevant_documents(query)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3: Ensemble Retriever**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EnsembleRetriever takes a list of retrievers as input and ensemble the results of their get_relevant_documents() methods and rerank the results based on the \"\"**Reciprocal Rank Fusion**\"\" algorithm.\n",
    "\n",
    "By leveraging the strengths of different algorithms, the EnsembleRetriever can achieve better performance than any single algorithm.\n",
    "\n",
    "The most common pattern is to combine a sparse retriever (like BM25) with a dense retriever (like embedding similarity), because their strengths are complementary. It is also known as \"hybrid search\". The sparse retriever is good at finding relevant documents based on keywords, while the dense retriever is good at finding relevant documents based on semantic similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "#BM25Retriever ---> sparse retriever\n",
    "from langchain.retrievers import BM25Retriever ,EnsembleRetriever             # sparse retriever---> are trying to find relevant documents base on the key word\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list =[\n",
    "\n",
    "    'I like python programming language',\n",
    "    \"I like  tea\",\n",
    "    \"I like my vill\"\n",
    "]\n",
    "\n",
    "# Initialize bm25(sparse retriever) and FAISS vectores stores\n",
    "bm25_retriever = BM25Retriever.from_texts(doc_list)\n",
    "bm25_retriever.k= 2\n",
    "\n",
    "\n",
    "faiss_vectore_store = FAISS.from_texts(doc_list,embedding_text)\n",
    "faiss_retriever = faiss_vectore_store.as_retriever(search_kwargs = {\"k\" : 2})\n",
    "\n",
    "\n",
    "# initialize the ensamble-retriever\n",
    "ensamble_retreiver = EnsembleRetriever(retrievers=[bm25_retriever, faiss_retriever], weights=[0.5 , 0.5])\n",
    "\n",
    "\n",
    "\n",
    "# useer na jo query poju kea voo current event or recent event jis keleye web search ki zarort ho\n",
    "# recent data or realtime data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='I like my vill'), Document(page_content='I like  tea')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensamble_retreiver.get_relevant_documents(\"village\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4: MultiVectore Retriever**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5: Parent Document Retrievers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When spliting documenst for retrieval , there are often conflicting desires:\n",
    "1:you may want to have a small documents , so that their embedding can most accuratly reflect their meaning.if too long then embedding can loss meaning <br>\n",
    "2:you want to have long enough documents that the context of each chunk is retain\n",
    "\n",
    "\n",
    "The ParentDocumentRetriever strikes that balance by splitting and storing small chunks of data. During retrieval, it first fetches the small chunks but then looks up the parent ids for those chunks and returns those larger documents.\n",
    "\n",
    "Note that \"parent document\" refers to the document that a small chunk originated from. This can either be the whole raw document OR a larger chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.retrievers import ParentDocumentRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = [\n",
    "    TextLoader(\"webproposal.txt\"),\n",
    "    TextLoader(\"Email_Cover_letter.txt\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for i in loaders:\n",
    "    docs.extend(i.load())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Hello,\\n\\nMy name is Israr dawar and I’d love to help you launch your new website. I am a web developer(Backend), who has worked on many different websites. I studied web development for 2 years and have worked with startups to build their web presence over the past 2 years.\\n\\nI’d be happy to tailor it to your needs. I understand you are a new company and I am happy to be flexible to make sure we work with your timeline. Could you tell me more about your target market and audience? If you are unsure, I can brainstorm with you on this point.\\n\\nDo let me know if you have any questions and I am excited to have the possibility to work on this project!\\nTo know about my experience please visit my Github profile https://github.com/israr96418\\nBest regards,\\n\\nIsrar Dawar', metadata={'source': 'webproposal.txt'}),\n",
       " Document(page_content='Dear HR,\\n\\nI am writing to express my keen interest in the Junior Software Engineer role at NoTell. As a recent software engineer graduate from UETMardan, I am excited about the chance to contribute my coding skills and knowledge to your team.\\n\\nMy academic background equips me with a strong foundation in software engineering principles, algorithms, and data structures. I have hands-on experience with python,c++,javascripts etc through projects like Human Fall detection,Hospital management system, Investops and ML related project. This experience has developed my problem-solving abilities and teamwork skills.\\n\\nThank you for considering my application,\\nSincerely,\\nM.Israr', metadata={'source': 'Email_Cover_letter.txt'})]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Retrieveing Full Documents***:\n",
    "In this section i want to retreive full docuements, therefore we only specify a child splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This text splitter is used to create the child documents\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size = 400)\n",
    "\n",
    "\n",
    "# the vectorestore to use to index the child chunks\n",
    "vector_stores = Chroma(\n",
    "    collection_name = \"full_documenst\",\n",
    "    embedding_function = embedding_text,\n",
    "    persist_directory=\"chroma1_db_ao\"\n",
    ")\n",
    "\n",
    "# the storage layer for the parent documents\n",
    "store = InMemoryStore()\n",
    "\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore= vector_stores,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.add_documents(docs, ids=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['93c59cac-117d-4dd2-a6f7-77ce65eeeb19',\n",
       " '3a7ce316-75b6-42b3-b2c7-1b148a2191d9']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this should yield two key b/z we added 2 documents\n",
    "list(store.yield_keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets Now call the vectore store search functionality, we should see that it returns small chunks(since we are storing small chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Do let me know if you have any questions and I am excited to have the possibility to work on this project!\\nTo know about my experience please visit my Github profile https://github.com/israr96418\\nBest regards,\\n\\nIsrar Dawar', metadata={'doc_id': '93c59cac-117d-4dd2-a6f7-77ce65eeeb19', 'source': 'webproposal.txt'}),\n",
       " Document(page_content='My academic background equips me with a strong foundation in software engineering principles, algorithms, and data structures. I have hands-on experience with python,c++,javascripts etc through projects like Human Fall detection,Hospital management system, Investops and ML related project. This experience has developed my problem-solving abilities and teamwork skills.', metadata={'doc_id': '3a7ce316-75b6-42b3-b2c7-1b148a2191d9', 'source': 'Email_Cover_letter.txt'}),\n",
       " Document(page_content='Hello,\\n\\nMy name is Israr dawar and I’d love to help you launch your new website. I am a web developer(Backend), who has worked on many different websites. I studied web development for 2 years and have worked with startups to build their web presence over the past 2 years.', metadata={'doc_id': '93c59cac-117d-4dd2-a6f7-77ce65eeeb19', 'source': 'webproposal.txt'}),\n",
       " Document(page_content='Thank you for considering my application,\\nSincerely,\\nM.Israr', metadata={'doc_id': '3a7ce316-75b6-42b3-b2c7-1b148a2191d9', 'source': 'Email_Cover_letter.txt'})]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_docs = vector_stores.similarity_search(\"Github links\")\n",
    "sub_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do let me know if you have any questions and I am excited to have the possibility to work on this project!\n",
      "To know about my experience please visit my Github profile https://github.com/israr96418\n",
      "Best regards,\n",
      "\n",
      "Israr Dawar\n"
     ]
    }
   ],
   "source": [
    "print(sub_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to retrieve from the overall retriever, this should return large documents ,since it return documents where the smaller chunks are located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello,\n",
      "\n",
      "My name is Israr dawar and I’d love to help you launch your new website. I am a web developer(Backend), who has worked on many different websites. I studied web development for 2 years and have worked with startups to build their web presence over the past 2 years.\n",
      "\n",
      "I’d be happy to tailor it to your needs. I understand you are a new company and I am happy to be flexible to make sure we work with your timeline. Could you tell me more about your target market and audience? If you are unsure, I can brainstorm with you on this point.\n",
      "\n",
      "Do let me know if you have any questions and I am excited to have the possibility to work on this project!\n",
      "To know about my experience please visit my Github profile https://github.com/israr96418\n",
      "Best regards,\n",
      "\n",
      "Israr Dawar\n"
     ]
    }
   ],
   "source": [
    "retriever_docs = retriever.get_relevant_documents(\"israr dawar github links\")\n",
    "print(retriever_docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Retreiveing Larger chunks:**\n",
    "Sometimes the full documets are so big to retrieve as is. In that case , what we really want to do is to first split the raw documents into larger chunks, and then split into smaller chunks, we then index the smaller chunks, but on the retrieval we retrieve the large chunks(but still not the full documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This text splitter is used to create the parent documents\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)\n",
    "\n",
    "# This text splitter is used to create the child documents\n",
    "# It should create documents smaller than the parent\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=400)\n",
    "\n",
    "# The vectorstore to use to index the child chunks\n",
    "vectorstore = Chroma(collection_name=\"split_parents\", embedding_function=embedding_text)\n",
    "\n",
    "# The storage layer for the parent documents\n",
    "stores = InMemoryStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_retreiver = ParentDocumentRetriever(\n",
    "    vectorstore=vector_stores,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Incorrect API key provided: sk-N8qid***************************************PFbA. You can find your API key at https://platform.openai.com/account/api-keys.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb Cell 358\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Z1044sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m parent_retreiver\u001b[39m.\u001b[39;49madd_documents(docs)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/retrievers/parent_document_retriever.py:112\u001b[0m, in \u001b[0;36mParentDocumentRetriever.add_documents\u001b[0;34m(self, documents, ids, add_to_docstore)\u001b[0m\n\u001b[1;32m    110\u001b[0m     docs\u001b[39m.\u001b[39mextend(sub_docs)\n\u001b[1;32m    111\u001b[0m     full_docs\u001b[39m.\u001b[39mappend((_id, doc))\n\u001b[0;32m--> 112\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvectorstore\u001b[39m.\u001b[39;49madd_documents(docs)\n\u001b[1;32m    113\u001b[0m \u001b[39mif\u001b[39;00m add_to_docstore:\n\u001b[1;32m    114\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdocstore\u001b[39m.\u001b[39mmset(full_docs)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/schema/vectorstore.py:122\u001b[0m, in \u001b[0;36mVectorStore.add_documents\u001b[0;34m(self, documents, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m texts \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mpage_content \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    121\u001b[0m metadatas \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[0;32m--> 122\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_texts(texts, metadatas, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:188\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m texts \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(texts)\n\u001b[1;32m    187\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding_function \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 188\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embedding_function\u001b[39m.\u001b[39;49membed_documents(texts)\n\u001b[1;32m    189\u001b[0m \u001b[39mif\u001b[39;00m metadatas:\n\u001b[1;32m    190\u001b[0m     \u001b[39m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[1;32m    191\u001b[0m     \u001b[39m# did not specify metadata for all texts\u001b[39;00m\n\u001b[1;32m    192\u001b[0m     length_diff \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(texts) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(metadatas)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/embeddings/openai.py:490\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[0;34m(self, texts, chunk_size)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call out to OpenAI's embedding endpoint for embedding search docs.\u001b[39;00m\n\u001b[1;32m    479\u001b[0m \n\u001b[1;32m    480\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[39m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[39m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[39m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_len_safe_embeddings(texts, engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeployment)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/embeddings/openai.py:374\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    371\u001b[0m     _iter \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(tokens), _chunk_size)\n\u001b[1;32m    373\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m _iter:\n\u001b[0;32m--> 374\u001b[0m     response \u001b[39m=\u001b[39m embed_with_retry(\n\u001b[1;32m    375\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    376\u001b[0m         \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mtokens[i : i \u001b[39m+\u001b[39;49m _chunk_size],\n\u001b[1;32m    377\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invocation_params,\n\u001b[1;32m    378\u001b[0m     )\n\u001b[1;32m    379\u001b[0m     batched_embeddings\u001b[39m.\u001b[39mextend(r[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m response[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    381\u001b[0m results: List[List[List[\u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m [[] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(texts))]\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/embeddings/openai.py:107\u001b[0m, in \u001b[0;36membed_with_retry\u001b[0;34m(embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m     response \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m _check_response(response, skip_empty\u001b[39m=\u001b[39membeddings\u001b[39m.\u001b[39mskip_empty)\n\u001b[0;32m--> 107\u001b[0m \u001b[39mreturn\u001b[39;00m _embed_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/embeddings/openai.py:104\u001b[0m, in \u001b[0;36membed_with_retry.<locals>._embed_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_embed_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 104\u001b[0m     response \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m _check_response(response, skip_empty\u001b[39m=\u001b[39membeddings\u001b[39m.\u001b[39mskip_empty)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/openai/api_resources/embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     35\u001b[0m         \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m         \u001b[39m# This is only for the default case.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m user_provided_encoding_format:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    131\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    139\u001b[0m ):\n\u001b[1;32m    140\u001b[0m     (\n\u001b[1;32m    141\u001b[0m         deployment_id,\n\u001b[1;32m    142\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    153\u001b[0m     )\n\u001b[0;32m--> 155\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    156\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    157\u001b[0m         url,\n\u001b[1;32m    158\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    159\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    160\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    161\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    162\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    166\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    167\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/openai/api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    279\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    280\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    288\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    290\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    291\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    298\u001b[0m     )\n\u001b[0;32m--> 299\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/openai/api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    703\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    704\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    707\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    709\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 710\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    711\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    712\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    713\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    714\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    715\u001b[0m         ),\n\u001b[1;32m    716\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    717\u001b[0m     )\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/openai/api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    773\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    774\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 775\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    776\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    777\u001b[0m     )\n\u001b[1;32m    778\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Incorrect API key provided: sk-N8qid***************************************PFbA. You can find your API key at https://platform.openai.com/account/api-keys."
     ]
    }
   ],
   "source": [
    "parent_retreiver.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(stores.yield_keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Incorrect API key provided: sk-N8qid***************************************PFbA. You can find your API key at https://platform.openai.com/account/api-keys.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb Cell 360\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Z1046sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m sub_docs \u001b[39m=\u001b[39m vectorstore\u001b[39m.\u001b[39;49msimilarity_search(\u001b[39m\"\u001b[39;49m\u001b[39mjustice breyer\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:261\u001b[0m, in \u001b[0;36mChroma.similarity_search\u001b[0;34m(self, query, k, filter, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msimilarity_search\u001b[39m(\n\u001b[1;32m    245\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    246\u001b[0m     query: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    250\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Document]:\n\u001b[1;32m    251\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Run similarity search with Chroma.\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \n\u001b[1;32m    253\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[39m        List[Document]: List of documents most similar to the query text.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m     docs_and_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msimilarity_search_with_score(query, k, \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mfilter\u001b[39;49m)\n\u001b[1;32m    262\u001b[0m     \u001b[39mreturn\u001b[39;00m [doc \u001b[39mfor\u001b[39;00m doc, _ \u001b[39min\u001b[39;00m docs_and_scores]\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:345\u001b[0m, in \u001b[0;36mChroma.similarity_search_with_score\u001b[0;34m(self, query, k, filter, where_document, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__query_collection(\n\u001b[1;32m    339\u001b[0m         query_texts\u001b[39m=\u001b[39m[query],\n\u001b[1;32m    340\u001b[0m         n_results\u001b[39m=\u001b[39mk,\n\u001b[1;32m    341\u001b[0m         where\u001b[39m=\u001b[39m\u001b[39mfilter\u001b[39m,\n\u001b[1;32m    342\u001b[0m         where_document\u001b[39m=\u001b[39mwhere_document,\n\u001b[1;32m    343\u001b[0m     )\n\u001b[1;32m    344\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 345\u001b[0m     query_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embedding_function\u001b[39m.\u001b[39;49membed_query(query)\n\u001b[1;32m    346\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__query_collection(\n\u001b[1;32m    347\u001b[0m         query_embeddings\u001b[39m=\u001b[39m[query_embedding],\n\u001b[1;32m    348\u001b[0m         n_results\u001b[39m=\u001b[39mk,\n\u001b[1;32m    349\u001b[0m         where\u001b[39m=\u001b[39m\u001b[39mfilter\u001b[39m,\n\u001b[1;32m    350\u001b[0m         where_document\u001b[39m=\u001b[39mwhere_document,\n\u001b[1;32m    351\u001b[0m     )\n\u001b[1;32m    353\u001b[0m \u001b[39mreturn\u001b[39;00m _results_to_docs_and_scores(results)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/embeddings/openai.py:518\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39membed_query\u001b[39m(\u001b[39mself\u001b[39m, text: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mfloat\u001b[39m]:\n\u001b[1;32m    510\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call out to OpenAI's embedding endpoint for embedding query text.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \n\u001b[1;32m    512\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[39m        Embedding for the text.\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_documents([text])[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/embeddings/openai.py:490\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[0;34m(self, texts, chunk_size)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call out to OpenAI's embedding endpoint for embedding search docs.\u001b[39;00m\n\u001b[1;32m    479\u001b[0m \n\u001b[1;32m    480\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[39m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[39m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[39m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_len_safe_embeddings(texts, engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeployment)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/embeddings/openai.py:374\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    371\u001b[0m     _iter \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(tokens), _chunk_size)\n\u001b[1;32m    373\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m _iter:\n\u001b[0;32m--> 374\u001b[0m     response \u001b[39m=\u001b[39m embed_with_retry(\n\u001b[1;32m    375\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    376\u001b[0m         \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mtokens[i : i \u001b[39m+\u001b[39;49m _chunk_size],\n\u001b[1;32m    377\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invocation_params,\n\u001b[1;32m    378\u001b[0m     )\n\u001b[1;32m    379\u001b[0m     batched_embeddings\u001b[39m.\u001b[39mextend(r[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m response[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    381\u001b[0m results: List[List[List[\u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m [[] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(texts))]\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/embeddings/openai.py:107\u001b[0m, in \u001b[0;36membed_with_retry\u001b[0;34m(embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m     response \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m _check_response(response, skip_empty\u001b[39m=\u001b[39membeddings\u001b[39m.\u001b[39mskip_empty)\n\u001b[0;32m--> 107\u001b[0m \u001b[39mreturn\u001b[39;00m _embed_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/embeddings/openai.py:104\u001b[0m, in \u001b[0;36membed_with_retry.<locals>._embed_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_embed_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 104\u001b[0m     response \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m _check_response(response, skip_empty\u001b[39m=\u001b[39membeddings\u001b[39m.\u001b[39mskip_empty)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/openai/api_resources/embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     35\u001b[0m         \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m         \u001b[39m# This is only for the default case.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m user_provided_encoding_format:\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    131\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    139\u001b[0m ):\n\u001b[1;32m    140\u001b[0m     (\n\u001b[1;32m    141\u001b[0m         deployment_id,\n\u001b[1;32m    142\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    153\u001b[0m     )\n\u001b[0;32m--> 155\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    156\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    157\u001b[0m         url,\n\u001b[1;32m    158\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    159\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    160\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    161\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    162\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    166\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    167\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/openai/api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    279\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    280\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    288\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    290\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    291\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    298\u001b[0m     )\n\u001b[0;32m--> 299\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/openai/api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    703\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    704\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    707\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    709\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 710\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    711\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    712\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    713\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    714\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    715\u001b[0m         ),\n\u001b[1;32m    716\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    717\u001b[0m     )\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/openai/api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    773\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    774\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 775\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    776\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    777\u001b[0m     )\n\u001b[1;32m    778\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Incorrect API key provided: sk-N8qid***************************************PFbA. You can find your API key at https://platform.openai.com/account/api-keys."
     ]
    }
   ],
   "source": [
    "sub_docs = vectorstore.similarity_search(\"justice breyer\")\n",
    "print(sub_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.get_relevant_documents(\"justice breyer\")\n",
    "retrieved_docs = retriever.get_relevant_documents(\"justice breyer\")\n",
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6: Self Quering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A self-querying retriever is one that, as the name suggests, has the ability to query itself. Specifically, given any natural language query, the retriever uses a query-constructing LLM chain to write a structured query and then applies that structured query to its underlying VectorStore. This allows the retriever to not only use the user-input query for semantic similarity comparison with the contents of stored documents but to also extract filters from the user query on the metadata of stored documents and to execute those filters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get started\n",
    "For demonstration purposes we'll use a Pinecone vector store.\n",
    "\n",
    "First we'll want to create a Pinecone vector store and seed it with some data. We've created a small demo set of documents that contain summaries of movies.\n",
    "\n",
    "To use Pinecone, you need to have pinecone package installed and you must have an API key and an environment. Here are the installation instructions.\n",
    "\n",
    "Note: The self-query retriever requires you to have lark package installed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pinecone\n",
    "\n",
    "\n",
    "pinecone.init(api_key=os.environ[\"PINECONE_API_KEY\"], environment=os.environ[\"PINECONE_ENV\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "# create new index\n",
    "pinecone.create_index(\"langchain-self-retriever-demo\", dimension=1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    Document(page_content=\"A bunch of scientists bring back dinosaurs and mayhem breaks loose\", metadata={\"year\": 1993, \"rating\": 7.7, \"genre\": [\"action\", \"science fiction\"]}),\n",
    "    Document(page_content=\"Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\", metadata={\"year\": 2010, \"director\": \"Christopher Nolan\", \"rating\": 8.2}),\n",
    "    Document(page_content=\"A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\", metadata={\"year\": 2006, \"director\": \"Satoshi Kon\", \"rating\": 8.6}),\n",
    "    Document(page_content=\"A bunch of normal-sized women are supremely wholesome and some men pine after them\", metadata={\"year\": 2019, \"director\": \"Greta Gerwig\", \"rating\": 8.3}),\n",
    "    Document(page_content=\"Toys come alive and have a blast doing so\", metadata={\"year\": 1995, \"genre\": \"animated\"}),\n",
    "    Document(page_content=\"Three men walk into the Zone, three men walk out of the Zone\", metadata={\"year\": 1979, \"rating\": 9.9, \"director\": \"Andrei Tarkovsky\", \"genre\": [\"science fiction\", \"thriller\"], \"rating\": 9.9})\n",
    "]\n",
    "vectorstore = Pinecone.from_documents(\n",
    "    docs, embeddings, index_name=\"langchain-self-retriever-demo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating our self-querying retriever**\n",
    "Now we can instantiate our retriever. To do this we'll need to provide some information upfront about the metadata fields that our documents support and a short description of the document contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "\n",
    "metadata_field_info=[\n",
    "    AttributeInfo(\n",
    "        name=\"genre\",\n",
    "        description=\"The genre of the movie\",\n",
    "        type=\"string or list[string]\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"year\",\n",
    "        description=\"The year the movie was released\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"director\",\n",
    "        description=\"The name of the movie director\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"rating\",\n",
    "        description=\"A 1-10 rating for the movie\",\n",
    "        type=\"float\"\n",
    "    ),\n",
    "]\n",
    "document_content_description = \"Brief summary of a movie\"\n",
    "llm = OpenAI(temperature=0)\n",
    "retriever = SelfQueryRetriever.from_llm(llm, vectorstore, document_content_description, metadata_field_info, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing it out**\n",
    "#### This example only specifies a relevant query\n",
    "retriever.get_relevant_documents(\"What are some movies about dinosaurs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output:\n",
    "    query='dinosaur' filter=None\n",
    "\n",
    "\n",
    "    [Document(page_content='A bunch of scientists bring back dinosaurs and mayhem breaks loose', metadata={'genre': ['action', 'science fiction'], 'rating': 7.7, 'year': 1993.0}),\n",
    "     Document(page_content='Toys come alive and have a blast doing so', metadata={'genre': 'animated', 'year': 1995.0}),\n",
    "     Document(page_content='A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea', metadata={'director': 'Satoshi Kon', 'rating': 8.6, 'year': 2006.0}),\n",
    "     Document(page_content='Leo DiCaprio gets lost in a dream within a dream within a dream within a ...', metadata={'director': 'Christopher Nolan', 'rating': 8.2, 'year': 2010.0})]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This example specifies a query and a filter\n",
    "retriever.get_relevant_documents(\"Has Greta Gerwig directed any movies about women\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example specifies a composite filter\n",
    "retriever.get_relevant_documents(\"What's a highly rated (above 8.5) science fiction film?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example specifies a query and composite filter\n",
    "retriever.get_relevant_documents(\"What's a movie after 1990 but before 2005 that's all about toys, and preferably is animated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter k\n",
    "We can also use the self query retriever to specify k: the number of documents to fetch.\n",
    "\n",
    "We can do this by passing enable_limit=True to the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectorstore,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    enable_limit=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example only specifies a relevant query\n",
    "retriever.get_relevant_documents(\"What are two movies about dinosaurs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7: Time-weighted vectore store Retriever**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8: Vectore store backed Retriever**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vector store retriever is a retriever that uses a vector store to retrieve documents. It is a lightweight wrapper around the vector store class to make it conform to the retriever interface. It uses the search methods implemented by a vector store, like similarity search and MMR, to query the texts in the vector store.\n",
    "\n",
    "Once you construct a vector store, it's very easy to construct a retriever. Let's walk through an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "loader = TextLoader('../../../state_of_the_union.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = FAISS.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum marginal relevance retrieval:\n",
    "By default, the vector store retriever uses similarity search. If the underlying vector store supports maximum marginal relevance search, you can specify that as the search type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_type=\"mmr\")\n",
    "docs = retriever.get_relevant_documents(\"what did he say about ketanji brown jackson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity score threshold retrieval:\n",
    "You can also a retrieval method that sets a similarity score threshold and only returns documents with a score above that threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": .5})\n",
    "docs = retriever.get_relevant_documents(\"what did he say about ketanji brown jackson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying top k:\n",
    "You can also specify search kwargs like k to use when doing retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_kwargs={\"k\": 1})\n",
    "docs = retriever.get_relevant_documents(\"what did he say about ketanji brown jackson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9: WebSearch Retriever**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a query, this retriever will:\n",
    "\n",
    "Formulate a set of relate Google searchesm <br>\n",
    "Search for each<br>\n",
    "Load all the resulting URLs<br>\n",
    "Then embed and perform similarity search with the query on the consolidate page content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.web_research import WebResearchRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple usage , specify LLM to use for a google seach query generation\n",
    "import os\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models.openai import ChatOpenAI\n",
    "from langchain.utilities import DuckDuckGoSearchAPIWrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = DuckDuckGoSearchAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectores stores\n",
    "vectores_stores = Chroma(embedding_function=embedding_text, persist_directory=\"chroma_db_ao\")\n",
    "\n",
    "llm_model = ChatOpenAI(temperature=0, openai_api_key=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "5 validation errors for WebResearchRetriever\nsearch -> max_results\n  extra fields not permitted (type=value_error.extra)\nsearch -> region\n  extra fields not permitted (type=value_error.extra)\nsearch -> safesearch\n  extra fields not permitted (type=value_error.extra)\nsearch -> time\n  extra fields not permitted (type=value_error.extra)\nsearch -> __root__\n  Did not find google_api_key, please add an environment variable `GOOGLE_API_KEY` which contains it, or pass  `google_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb Cell 358\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Z1016sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# initialize \u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Z1016sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m web_search \u001b[39m=\u001b[39m WebResearchRetriever\u001b[39m.\u001b[39;49mfrom_llm(vectorstore\u001b[39m=\u001b[39;49mvectores_stores,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Z1016sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m                               llm\u001b[39m=\u001b[39;49mllm_model,search\u001b[39m=\u001b[39;49msearch)\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/retrievers/web_research.py:128\u001b[0m, in \u001b[0;36mWebResearchRetriever.from_llm\u001b[0;34m(cls, vectorstore, llm, search, prompt, num_search_results, text_splitter)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39m# Use chat model prompt\u001b[39;00m\n\u001b[1;32m    122\u001b[0m llm_chain \u001b[39m=\u001b[39m LLMChain(\n\u001b[1;32m    123\u001b[0m     llm\u001b[39m=\u001b[39mllm,\n\u001b[1;32m    124\u001b[0m     prompt\u001b[39m=\u001b[39mprompt,\n\u001b[1;32m    125\u001b[0m     output_parser\u001b[39m=\u001b[39mQuestionListOutputParser(),\n\u001b[1;32m    126\u001b[0m )\n\u001b[0;32m--> 128\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\n\u001b[1;32m    129\u001b[0m     vectorstore\u001b[39m=\u001b[39;49mvectorstore,\n\u001b[1;32m    130\u001b[0m     llm_chain\u001b[39m=\u001b[39;49mllm_chain,\n\u001b[1;32m    131\u001b[0m     search\u001b[39m=\u001b[39;49msearch,\n\u001b[1;32m    132\u001b[0m     num_search_results\u001b[39m=\u001b[39;49mnum_search_results,\n\u001b[1;32m    133\u001b[0m     text_splitter\u001b[39m=\u001b[39;49mtext_splitter,\n\u001b[1;32m    134\u001b[0m )\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/langchain/load/serializable.py:97\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     98\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lc_kwargs \u001b[39m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/stallionsProject/Langchain_AI_handbook/.venv/lib/python3.10/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[39m=\u001b[39m validate_model(__pydantic_self__\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[39mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[39mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[39m'\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 5 validation errors for WebResearchRetriever\nsearch -> max_results\n  extra fields not permitted (type=value_error.extra)\nsearch -> region\n  extra fields not permitted (type=value_error.extra)\nsearch -> safesearch\n  extra fields not permitted (type=value_error.extra)\nsearch -> time\n  extra fields not permitted (type=value_error.extra)\nsearch -> __root__\n  Did not find google_api_key, please add an environment variable `GOOGLE_API_KEY` which contains it, or pass  `google_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "# initialize \n",
    "web_search = WebResearchRetriever.from_llm(vectorstore=vectores_stores,\n",
    "                              llm=llm_model,search=search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run with citations:<br>\n",
    "we can use \"RetrievalQAWithSourcesChain\" to retrieve docs and provide citation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'web_search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb Cell 359\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Z1020sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchains\u001b[39;00m \u001b[39mimport\u001b[39;00m RetrievalQAWithSourcesChain\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Z1020sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m user_input \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mHow do LLM Powered Autonomous Agents work?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Z1020sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m qa_chain\u001b[39m=\u001b[39mRetrievalQAWithSourcesChain\u001b[39m.\u001b[39mfrom_chain_type(llm_model, retriever\u001b[39m=\u001b[39mweb_search)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Z1020sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m resutl \u001b[39m=\u001b[39m qa_chain({\u001b[39m'\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m'\u001b[39m:user_input})\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/isrardawar/stallionsProject/Langchain_AI_handbook/Handbook.ipynb#Z1020sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m resutl\n",
      "\u001b[0;31mNameError\u001b[0m: name 'web_search' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "user_input = \"How do LLM Powered Autonomous Agents work?\"\n",
    "qa_chain=RetrievalQAWithSourcesChain.from_chain_type(llm_model, retriever=web_search)\n",
    "resutl = qa_chain({'question':user_input})\n",
    "resutl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain\n",
    "**Foundational**<br>\n",
    "    ****1: LLM****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An LLMChain is a simple chain that adds some functionality around language models. It is used widely throughout LangChain, including in other chains and agents.\n",
    "\n",
    "An LLMChain consists of a PromptTemplate and a language model (either an LLM or chat model). It formats the prompt template using the input key values provided (and also memory key values, if available), passes the formatted string to LLM and returns the LLM output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "prompt_template = \"What is a good name for a company that makes {product}?\"\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=PromptTemplate.from_template(prompt_template)\n",
    ")\n",
    "llm_chain(\"colorful socks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additional ways of running LLMChain :**\n",
    "Aside from __call__ and run methods shared by all Chain object, LLMChain offers a few more ways of calling the chain logic:\n",
    "\n",
    "apply allows you run the chain against a list of inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2857676298.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    generate is similar to apply, except it return an LLMResult instead of string. LLMResult often contains useful generation such as token usages and finish reason.\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "input_list = [\n",
    "    {\"product\": \"socks\"},\n",
    "    {\"product\": \"computer\"},\n",
    "    {\"product\": \"shoes\"}\n",
    "]\n",
    "\n",
    "llm_chain.apply(input_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**generate** is similar to apply, except it return an LLMResult instead of string. LLMResult often contains useful generation such as token usages and finish reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain.generate(input_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ouput:\n",
    "    LLMResult(generations=[[Generation(text='\\n\\nSocktastic!', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nTechCore Solutions.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nFootwear Factory.', generation_info={'finish_reason': 'stop', 'logprobs': None})]], llm_output={'token_usage': {'prompt_tokens': 36, 'total_tokens': 55, 'completion_tokens': 19}, 'model_name': 'text-davinci-003'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict is similar to run method except that the input keys are specified as keyword arguments instead of a Python dict.\n",
    "# Single input example\n",
    "llm_chain.predict(product=\"colorful socks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple inputs example\n",
    "\n",
    "template = \"\"\"Tell me a {adjective} joke about {subject}.\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"adjective\", \"subject\"])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=OpenAI(temperature=0))\n",
    "\n",
    "llm_chain.predict(adjective=\"sad\", subject=\"ducks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parsing the outputs**\n",
    "By default, LLMChain does not parse the output even if the underlying prompt object has an output parser. If you would like to apply that output parser on the LLM output, use predict_and_parse instead of predict and apply_and_parse instead of apply.\n",
    "\n",
    "With predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "template = \"\"\"List all the colors in a rainbow\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[], output_parser=output_parser)\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "llm_chain.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output:\n",
    "'\\n\\nRed, orange, yellow, green, blue, indigo, violet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with predict_and_parse\n",
    "    # output: ['Red', 'orange', 'yellow', 'green', 'blue', 'indigo', 'violet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize from string**\n",
    "You can also construct an LLMChain from a string template directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Tell me a {adjective} joke about {subject}.\"\"\"\n",
    "llm_chain = LLMChain.from_string(llm=llm, template=template)\n",
    "\n",
    "llm_chain.predict(adjective=\"sad\", subject=\"ducks\")\n",
    "\n",
    "# output:     '\\n\\nQ: What did the duck say when his friend died?\\nA: Quack, quack, goodbye.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2: Router :**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use the RouterChain paradigm to create a chain that dynamically selects the next chain to use for a given input.\n",
    "\n",
    "Router chains are made up of two components:\n",
    "\n",
    "The RouterChain itself (responsible for selecting the next chain to call)\n",
    "destination_chains: chains that the router chain can route to\n",
    "In this notebook, we will focus on the different types of routing chains. We will show these routing chains used in a MultiPromptChain to create a question-answering chain that selects the prompt which is most relevant for a given question, and then answers the question using that prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. You are great at answering math questions. \\\n",
    "You are so good because you are able to break down hard problems into their component parts, \\\n",
    "answer the component parts, and then put them together to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\",\n",
    "        \"description\": \"Good for answering questions about physics\",\n",
    "        \"prompt_template\": physics_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\",\n",
    "        \"description\": \"Good for answering math questions\",\n",
    "        \"prompt_template\": math_template,\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "llm = OpenAI()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\"])\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain\n",
    "default_chain = ConversationChain(llm=llm, output_key=\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***LLMRouterChain***\n",
    "This chain uses an LLM to determine how to route things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "\n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)\n",
    "\n",
    "\n",
    "\n",
    "chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=default_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "\n",
    "print(chain.run(\"What is black body radiation?\"))\n",
    "\n",
    "\n",
    "print(\n",
    "    chain.run(\n",
    "        \"What is the first prime number greater than 40 such that one plus the prime number is divisible by 3?\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "print(chain.run(\"What is the name of the type of cloud that rains?\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***EmbeddingRouterChain***:\n",
    "The EmbeddingRouterChain uses embeddings and similarity to route between destination chains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router.embedding_router import EmbeddingRouterChain\n",
    "from langchain.embeddings import CohereEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "\n",
    "names_and_descriptions = [\n",
    "    (\"physics\", [\"for questions about physics\"]),\n",
    "    (\"math\", [\"for questions about math\"]),\n",
    "]\n",
    "\n",
    "\n",
    "router_chain = EmbeddingRouterChain.from_names_and_descriptions(\n",
    "    names_and_descriptions, Chroma, CohereEmbeddings(), routing_keys=[\"input\"]\n",
    ")\n",
    "\n",
    "\n",
    "chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=default_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "\n",
    "print(chain.run(\"What is black body radiation?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3: Sequential**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step after calling a language model is to make a series of calls to a language model. This is particularly useful when you want to take the output from one call and use it as the input to another.\n",
    "\n",
    "In this notebook we will walk through some examples of how to do this, using sequential chains. Sequential chains allow you to connect multiple chains and compose them into pipelines that execute some specific scenario. There are two types of sequential chains:\n",
    "\n",
    "SimpleSequentialChain: The simplest form of sequential chains, where each step has a singular input/output, and the output of one step is the input to the next.\n",
    "SequentialChain: A more general form of sequential chains, allowing for multiple inputs/outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# This is an LLMChain to write a synopsis given a title of a play.\n",
    "llm = OpenAI(temperature=.7)\n",
    "synopsis_template = \"\"\"You are a playwright. Given the title of play, it is your job to write a synopsis for that title.\n",
    "\n",
    "Title: {title}\n",
    "Playwright: This is a synopsis for the above play:\"\"\"\n",
    "synopsis_prompt_template = PromptTemplate(input_variables=[\"title\"], template=synopsis_template)\n",
    "synopsis_chain = LLMChain(llm=llm, prompt=synopsis_prompt_template)\n",
    "\n",
    "# This is an LLMChain to write a review of a play given a synopsis.\n",
    "llm = OpenAI(temperature=.7)\n",
    "template = \"\"\"You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.\n",
    "\n",
    "Play Synopsis:\n",
    "{synopsis}\n",
    "Review from a New York Times play critic of the above play:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"synopsis\"], template=template)\n",
    "review_chain = LLMChain(llm=llm, prompt=prompt_template)    \n",
    "\n",
    "# This is the overall chain where we run these two chains in sequence.\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "overall_chain = SimpleSequentialChain(chains=[synopsis_chain, review_chain], verbose=True)\n",
    "\n",
    "review = overall_chain.run(\"Tragedy at sunset on the beach\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Sequential Chain**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, not all sequential chains will be as simple as passing a single string as an argument and getting a single string as output for all steps in the chain. In this next example, we will experiment with more complex chains that involve multiple inputs, and where there also multiple final outputs.\n",
    "\n",
    "Of particular importance is how we name the input/output variables. In the above example we didn't have to think about that because we were just passing the output of one chain directly as input to the next, but here we do have worry about that because we have multiple inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an LLMChain to write a synopsis given a title of a play and the era it is set in.\n",
    "llm = OpenAI(temperature=.7)\n",
    "synopsis_template = \"\"\"You are a playwright. Given the title of play and the era it is set in, it is your job to write a synopsis for that title.\n",
    "\n",
    "Title: {title}\n",
    "Era: {era}\n",
    "Playwright: This is a synopsis for the above play:\"\"\"\n",
    "synopsis_prompt_template = PromptTemplate(input_variables=[\"title\", \"era\"], template=synopsis_template)\n",
    "synopsis_chain = LLMChain(llm=llm, prompt=synopsis_prompt_template, output_key=\"synopsis\")\n",
    "\n",
    "# This is an LLMChain to write a review of a play given a synopsis.\n",
    "llm = OpenAI(temperature=.7)\n",
    "template = \"\"\"You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.\n",
    "\n",
    "Play Synopsis:\n",
    "{synopsis}\n",
    "Review from a New York Times play critic of the above play:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"synopsis\"], template=template)\n",
    "review_chain = LLMChain(llm=llm, prompt=prompt_template, output_key=\"review\")\n",
    "\n",
    "# This is the overall chain where we run these two chains in sequence.\n",
    "from langchain.chains import SequentialChain\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[synopsis_chain, review_chain],\n",
    "    input_variables=[\"era\", \"title\"],\n",
    "    # Here we return multiple variables\n",
    "    output_variables=[\"synopsis\", \"review\"],\n",
    "    verbose=True)\n",
    "\n",
    "\n",
    "overall_chain({\"title\":\"Tragedy at sunset on the beach\", \"era\": \"Victorian England\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Memory in Sequential Chains**<br>\n",
    "Sometimes you may want to pass along some context to use in each step of the chain or in a later part of the chain, but maintaining and chaining together the input/output variables can quickly get messy. Using SimpleMemory is a convenient way to do manage this and clean up your chains.\n",
    "\n",
    "For example, using the previous playwright SequentialChain, lets say you wanted to include some context about date, time and location of the play, and using the generated synopsis and review, create some social media post text. You could add these new context variables as input_variables, or we can add a SimpleMemory to the chain to manage this context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "from langchain.memory import SimpleMemory\n",
    "\n",
    "llm = OpenAI(temperature=.7)\n",
    "template = \"\"\"You are a social media manager for a theater company.  Given the title of play, the era it is set in, the date,time and location, the synopsis of the play, and the review of the play, it is your job to write a social media post for that play.\n",
    "\n",
    "Here is some context about the time and location of the play:\n",
    "Date and Time: {time}\n",
    "Location: {location}\n",
    "\n",
    "Play Synopsis:\n",
    "{synopsis}\n",
    "Review from a New York Times play critic of the above play:\n",
    "{review}\n",
    "\n",
    "Social Media Post:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"synopsis\", \"review\", \"time\", \"location\"], template=template)\n",
    "social_chain = LLMChain(llm=llm, prompt=prompt_template, output_key=\"social_post_text\")\n",
    "\n",
    "overall_chain = SequentialChain(\n",
    "    memory=SimpleMemory(memories={\"time\": \"December 25th, 8pm PST\", \"location\": \"Theater in the Park\"}),\n",
    "    chains=[synopsis_chain, review_chain, social_chain],\n",
    "    input_variables=[\"era\", \"title\"],\n",
    "    # Here we return multiple variables\n",
    "    output_variables=[\"social_post_text\"],\n",
    "    verbose=True)\n",
    "\n",
    "overall_chain({\"title\":\"Tragedy at sunset on the beach\", \"era\": \"Victorian England\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformation**\n",
    "This notebook showcases using a generic transformation chain.\n",
    "\n",
    "As an example, we will create a dummy transformation that takes in a super long text, filters the text to only the first 3 paragraphs, and then passes that into an LLMChain to summarize those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import TransformChain, LLMChain, SimpleSequentialChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "with open(\"../../state_of_the_union.txt\") as f:\n",
    "    state_of_the_union = f.read()\n",
    "\n",
    "def transform_func(inputs: dict) -> dict:\n",
    "    text = inputs[\"text\"]\n",
    "    shortened_text = \"\\n\\n\".join(text.split(\"\\n\\n\")[:3])\n",
    "    return {\"output_text\": shortened_text}\n",
    "\n",
    "\n",
    "transform_chain = TransformChain(\n",
    "    input_variables=[\"text\"], output_variables=[\"output_text\"], transform=transform_func\n",
    ")\n",
    "\n",
    "template = \"\"\"Summarize this text:\n",
    "\n",
    "{output_text}\n",
    "\n",
    "Summary:\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"output_text\"], template=template)\n",
    "llm_chain = LLMChain(llm=OpenAI(), prompt=prompt)\n",
    "\n",
    "sequential_chain = SimpleSequentialChain(chains=[transform_chain, llm_chain])\n",
    "\n",
    "sequential_chain.run(state_of_the_union)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the core chain working with documents. They are useful for summarizing your documents, Answering-Question from your documents and extract information from your document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseCombineDocumentsChain(Chain, ABC):\n",
    "    \"\"\"Base interface for chains combining documents.\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def combine_docs(self, docs: List[Document], **kwargs: Any) -> Tuple[str, dict]:\n",
    "        \"\"\"Combine documents into a single string.\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stuff**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stuff documents chain (\"stuff\" as in \"to stuff\" or \"to fill\") is the most straightforward of the document chains. It takes a list of documents, inserts them all into a prompt and passes that prompt to an LLM.\n",
    "\n",
    "This chain is well-suited for applications where documents are small and only a few are passed in for most calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Refine**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Refine documents chain constructs a response by looping over the input documents and iteratively updating its answer. For each document, it passes all non-document inputs, the current document, and the latest intermediate answer to an LLM chain to get a new answer.\n",
    "\n",
    "Since the Refine chain only passes a single document to the LLM at a time, it is well-suited for tasks that require analyzing more documents than can fit in the model's context. The obvious tradeoff is that this chain will make far more LLM calls than, for example, the Stuff documents chain. There are also certain tasks which are difficult to accomplish iteratively. For example, the Refine chain can perform poorly when documents frequently cross-reference one another or when a task requires detailed information from many documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Map reduce**<br>\n",
    "The map reduce documents chain first applies an LLM chain to each document individually (the Map step), treating the chain output as a new document. It then passes all the new documents to a separate combine documents chain to get a single output (the Reduce step). It can optionally first compress, or collapse, the mapped documents to make sure that they fit in the combine documents chain (which will often pass them to an LLM). This compression step is performed recursively if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Map re-rank***<br>\n",
    "The map re-rank documents chain runs an initial prompt on each document, that not only tries to complete a task but also gives a score for how certain it is in its answer. The highest scoring response is returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain: Memory\n",
    "Outline<br>\n",
    "ConversationBufferMemory<br>\n",
    "ConversationBufferWindowMemory<br>\n",
    "ConversationTokenBufferMemory<br>\n",
    "ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0, model=llm_model)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(memory.buffer)\n",
    "memory.load_memory_variables({})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "memory.save_context({\"input\": \"Hi\"}, \n",
    "                    {\"output\": \"What's up\"})    \n",
    "print(memory.buffer)\n",
    "memory.load_memory_variables({})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"}, \n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "memory = ConversationBufferWindowMemory(k=1)               \n",
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "\n",
    "memory.load_memory_variables({})\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.0, model=llm_model)\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "conversation.predict(input=\"Hi, my name is Andrew\")\n",
    "memory.load_memory_variables({})\n",
    "conversation.predict(input=\"What is 1+1?\")\n",
    "\n",
    "memory.load_memory_variables({})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "llm = ChatOpenAI(temperature=0.0, model=llm_model)\n",
    "\n",
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=50)\n",
    "memory.save_context({\"input\": \"AI is what?!\"},\n",
    "                    {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "                    {\"output\": \"Beautiful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "                    {\"output\": \"Charming!\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "# create a long string\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})\n",
    "memory.load_memory_variables({})\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "conversation.predict(input=\"What would be a good demo to show?\")\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
